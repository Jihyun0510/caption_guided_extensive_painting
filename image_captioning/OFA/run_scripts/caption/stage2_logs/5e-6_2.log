2022-05-19 21:23:20 - utils.py[line:258] - INFO: distributed init (rank 0): env://
2022-05-19 21:23:20 - utils.py[line:261] - INFO: Start init
2022-05-19 21:23:20 - utils.py[line:258] - INFO: distributed init (rank 1): env://
2022-05-19 21:23:20 - utils.py[line:261] - INFO: Start init
2022-05-19 21:23:20 - distributed_c10d.py[line:187] - INFO: Added key: store_based_barrier_key:1 to store for rank: 1
2022-05-19 21:23:20 - distributed_c10d.py[line:187] - INFO: Added key: store_based_barrier_key:1 to store for rank: 0
2022-05-19 21:23:20 - utils.py[line:274] - INFO: initialized host vdsl as rank 0
single-machine distributed training is initialized.
2022-05-19 21:23:20 - utils.py[line:274] - INFO: initialized host vdsl as rank 1
single-machine distributed training is initialized.
2022-05-19 21:23:23 - train.py[line:77] - INFO: {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 10, 'log_format': 'simple', 'log_file': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': True, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': 512, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': '../../ofa_module', 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 2, 'distributed_num_procs': 2, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': 'env://', 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': True, 'ddp_backend': 'pytorch_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': True, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_algorithm': 'LocalSGD', 'localsgd_frequency': 3, 'nprocs_per_node': 2, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': True, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False}, 'dataset': {'_name': None, 'num_workers': 0, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': None, 'batch_size': 1, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 500, 'validate_after_updates': 0, 'fixed_validation_seed': 7, 'disable_validation': False, 'max_tokens_valid': None, 'batch_size_valid': 1, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0}, 'optimization': {'_name': None, 'max_epoch': 2, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 1.0, 'sentence_avg': False, 'update_freq': [8], 'lr': [5e-06], 'stop_min_lr': -1.0, 'use_bmuf': False}, 'checkpoint': {'_name': None, 'save_dir': '/database/jhkim/stage2_checkpoints//5e-6_2', 'restore_file': '../../checkpoints/checkpoint_last.pt', 'finetune_from_model': None, 'reset_dataloader': True, 'reset_lr_scheduler': False, 'reset_meters': True, 'reset_optimizer': True, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 500, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': 1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'cider', 'maximize_best_checkpoint_metric': True, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1, 'use_ema_weights_to_init_param': False, 'use_latest_weights_to_init_ema': False}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 2}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(_name='ofa_large', activation_fn='gelu', adam_betas='(0.9,0.999)', adam_eps=1e-08, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, add_type_embedding=True, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, arch='ofa_large', attention_dropout=0.0, attn_scale_factor=2, azureml_logging=False, batch_size=1, batch_size_valid=1, best_checkpoint_metric='cider', bf16=False, bpe=None, bpe_dir='../../utils/BPE', broadcast_buffers=False, bucket_cap_mb=25, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=1.0, code_dict_size=8192, code_image_size=128, code_layernorm_embedding=True, combine_valid_subsets=None, constraint_range=None, cpu=False, cpu_offload=False, criterion='scst_reward_criterion', cross_self_attention=False, curriculum=0, data='../../dataset/caption_data/caption_stage1_train_ct2.tsv,../../dataset/caption_data/caption_val_ct.tsv', data_buffer_size=10, dataset_impl=None, ddp_backend='pytorch_ddp', ddp_comm_hook='none', decoder_attention_heads=16, decoder_drop_path_rate=0.0, decoder_embed_dim=1024, decoder_embed_path=None, decoder_ffn_embed_dim=4096, decoder_input_dim=1024, decoder_layerdrop=0, decoder_layers=12, decoder_layers_to_keep=None, decoder_learned_pos=True, decoder_normalize_before=True, decoder_output_dim=1024, device_id=0, disable_entangle=True, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=2, distributed_port=-1, distributed_rank=0, distributed_world_size=2, dropout=0.0, ema_decay=0.9999, ema_fp32=False, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, empty_cache_freq=0, encoder_attention_heads=16, encoder_drop_path_rate=0.0, encoder_embed_dim=1024, encoder_embed_path=None, encoder_ffn_embed_dim=4096, encoder_layerdrop=0, encoder_layers=12, encoder_layers_to_keep=None, encoder_learned_pos=True, encoder_normalize_before=True, end_learning_rate=2e-07, entangle_position_embedding=False, eos=2, eval_args='{"beam":5,"max_len_b":16,"no_repeat_ngram_size":3}', eval_bleu=False, eval_cider=True, eval_cider_cached_tokens='../../dataset/caption_data/cider_cached_tokens/coco-valid-words.p', eval_print_samples=False, fast_stat_sync=False, find_unused_parameters=True, finetune_from_model=None, fix_batches_to_gpus=False, fixed_validation_seed=7, force_anneal=None, fp16=True, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=512, fp32_reduce_scatter=False, freeze_decoder_embedding=True, freeze_encoder_embedding=True, freeze_resnet=True, gen_subset='test', gradient_as_bucket_view=False, heartbeat_timeout=-1, ignore_prefix_size=0, ignore_unused_valid_subsets=False, image_bucket_size=42, imagenet_default_mean_and_std=False, keep_best_checkpoints=1, keep_interval_updates=-1, keep_interval_updates_pattern=-1, keep_last_epochs=-1, layernorm_embedding=True, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format='simple', log_interval=10, lr=[5e-06], lr_scheduler='polynomial_decay', max_epoch=2, max_source_positions=1024, max_src_length=80, max_target_positions=1024, max_tgt_length=20, max_tokens=None, max_tokens_valid=None, max_update=0, max_valid_steps=None, maximize_best_checkpoint_metric=True, memory_efficient_bf16=False, memory_efficient_fp16=True, min_loss_scale=0.0001, min_params_to_wrap=100000000, model_parallel_size=1, no_cross_attention=False, no_epoch_checkpoints=True, no_last_checkpoints=False, no_progress_bar=False, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=True, no_seed_provided=False, no_token_positional_embeddings=False, nprocs_per_node=2, num_bins=1000, num_shards=1, num_workers=0, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', pad=1, patch_image_size=480, patch_layernorm_embedding=True, patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', pooler_activation_fn='tanh', pooler_classifier='mlp', pooler_dropout=0.0, power=1.0, profile=False, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, quantization_config_path=None, relu_dropout=0.0, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=True, reset_logging=False, reset_lr_scheduler=False, reset_meters=True, reset_optimizer=True, resnet_drop_path_rate=0.0, resnet_type='resnet152', restore_file='../../checkpoints/checkpoint_last.pt', save_dir='/database/jhkim/stage2_checkpoints//5e-6_2', save_interval=1, save_interval_updates=500, scale_attn=True, scale_fc=True, scale_heads=True, scale_resids=False, scoring='bleu', scst=True, scst_args='{"beam":5,"max_len_b":16,"no_repeat_ngram_size":3}', scst_cider_cached_tokens='../../dataset/caption_data/cider_cached_tokens/coco-train-words.p', seed=1, selected_cols='1,4,2', sentence_avg=False, shard_id=0, share_all_embeddings=True, share_decoder_input_output_embed=True, simul_type=None, skip_invalid_size_inputs_valid_test=False, slowmo_algorithm='LocalSGD', slowmo_momentum=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=False, suppress_crashes=False, sync_bn=False, task='caption', tensorboard_logdir=None, threshold_loss_scale=None, token_bucket_size=256, tokenizer=None, total_num_update=1000000, tpu=False, train_subset='train', unk=3, update_freq=[8], use_bmuf=False, use_ema_weights_to_init_param=False, use_latest_weights_to_init_ema=False, use_old_adam=False, use_plasma_view=False, use_sharded_state=False, user_dir='../../ofa_module', valid_subset='valid', validate_after_updates=0, validate_interval=1, validate_interval_updates=500, wandb_project=None, warmup_ratio=0.06, warmup_updates=0, weight_decay=0.01, write_checkpoints_asynchronously=False, zero_sharding='none'), 'task': {'_name': 'caption', 'data': '../../dataset/caption_data/caption_stage1_train_ct2.tsv,../../dataset/caption_data/caption_val_ct.tsv', 'selected_cols': '1,4,2', 'bpe_dir': '../../utils/BPE', 'max_source_positions': 1024, 'max_target_positions': 1024, 'max_src_length': 80, 'max_tgt_length': 20, 'code_dict_size': 8192, 'patch_image_size': 480, 'num_bins': 1000, 'imagenet_default_mean_and_std': False, 'constraint_range': None, 'eval_bleu': False, 'eval_cider': True, 'eval_args': '{"beam":5,"max_len_b":16,"no_repeat_ngram_size":3}', 'eval_print_samples': False, 'eval_cider_cached_tokens': '../../dataset/caption_data/cider_cached_tokens/coco-valid-words.p', 'scst': True, 'scst_args': '{"beam":5,"max_len_b":16,"no_repeat_ngram_size":3}'}, 'criterion': {'_name': 'scst_reward_criterion', 'scst_cider_cached_tokens': '../../dataset/caption_data/cider_cached_tokens/coco-train-words.p', 'ignore_prefix_size': 0, 'sentence_avg': False, 'constraint_range': None}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9,0.999)', 'adam_eps': 1e-08, 'weight_decay': 0.01, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [5e-06]}, 'lr_scheduler': {'_name': 'polynomial_decay', 'warmup_updates': 0, 'warmup_ratio': 0.06, 'force_anneal': None, 'end_learning_rate': 2e-07, 'power': 1.0, 'total_num_update': 1000000.0, 'lr': [5e-06]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}, 'simul_type': None}
2022-05-19 21:23:23 - ofa_task.py[line:102] - INFO: source dictionary: 59457 types
2022-05-19 21:23:23 - ofa_task.py[line:103] - INFO: target dictionary: 59457 types
2022-05-19 21:23:35 - train.py[line:101] - INFO: OFAModel(
  (encoder): TransformerEncoder(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(59457, 1024, padding_idx=1)
    (layernorm_embedding): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (type_embedding): Embedding(2, 1024)
    (embed_images): ResNet(
      (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
      (layer1): Sequential(
        (0): Bottleneck(
          (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (downsample): Sequential(
            (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (drop_path): Identity()
        )
        (1): Bottleneck(
          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (2): Bottleneck(
          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
      )
      (layer2): Sequential(
        (0): Bottleneck(
          (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (downsample): Sequential(
            (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (drop_path): Identity()
        )
        (1): Bottleneck(
          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (2): Bottleneck(
          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (3): Bottleneck(
          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (4): Bottleneck(
          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (5): Bottleneck(
          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (6): Bottleneck(
          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (7): Bottleneck(
          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
      )
      (layer3): Sequential(
        (0): Bottleneck(
          (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (downsample): Sequential(
            (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)
            (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (drop_path): Identity()
        )
        (1): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (2): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (3): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (4): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (5): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (6): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (7): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (8): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (9): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (10): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (11): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (12): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (13): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (14): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (15): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (16): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (17): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (18): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (19): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (20): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (21): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (22): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (23): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (24): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (25): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (26): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (27): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (28): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (29): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (30): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (31): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (32): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (33): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (34): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
        (35): Bottleneck(
          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
          (drop_path): Identity()
        )
      )
    )
    (image_proj): Linear(in_features=1024, out_features=1024, bias=True)
    (patch_layernorm_embedding): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (embed_positions): Embedding(1026, 1024)
    (embed_image_positions): Embedding(1765, 1024)
    (pos_ln): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (image_pos_ln): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (pos_q_linear): Linear(in_features=1024, out_features=1024, bias=True)
    (pos_k_linear): Linear(in_features=1024, out_features=1024, bias=True)
    (layers): ModuleList(
      (0): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=1024, out_features=4096, bias=True)
        (fc2): Linear(in_features=4096, out_features=1024, bias=True)
        (attn_ln): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)
        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (drop_path): Identity()
      )
      (1): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=1024, out_features=4096, bias=True)
        (fc2): Linear(in_features=4096, out_features=1024, bias=True)
        (attn_ln): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)
        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (drop_path): Identity()
      )
      (2): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=1024, out_features=4096, bias=True)
        (fc2): Linear(in_features=4096, out_features=1024, bias=True)
        (attn_ln): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)
        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (drop_path): Identity()
      )
      (3): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=1024, out_features=4096, bias=True)
        (fc2): Linear(in_features=4096, out_features=1024, bias=True)
        (attn_ln): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)
        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (drop_path): Identity()
      )
      (4): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=1024, out_features=4096, bias=True)
        (fc2): Linear(in_features=4096, out_features=1024, bias=True)
        (attn_ln): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)
        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (drop_path): Identity()
      )
      (5): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=1024, out_features=4096, bias=True)
        (fc2): Linear(in_features=4096, out_features=1024, bias=True)
        (attn_ln): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)
        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (drop_path): Identity()
      )
      (6): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=1024, out_features=4096, bias=True)
        (fc2): Linear(in_features=4096, out_features=1024, bias=True)
        (attn_ln): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)
        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (drop_path): Identity()
      )
      (7): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=1024, out_features=4096, bias=True)
        (fc2): Linear(in_features=4096, out_features=1024, bias=True)
        (attn_ln): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)
        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (drop_path): Identity()
      )
      (8): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=1024, out_features=4096, bias=True)
        (fc2): Linear(in_features=4096, out_features=1024, bias=True)
        (attn_ln): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)
        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (drop_path): Identity()
      )
      (9): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=1024, out_features=4096, bias=True)
        (fc2): Linear(in_features=4096, out_features=1024, bias=True)
        (attn_ln): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)
        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (drop_path): Identity()
      )
      (10): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=1024, out_features=4096, bias=True)
        (fc2): Linear(in_features=4096, out_features=1024, bias=True)
        (attn_ln): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)
        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (drop_path): Identity()
      )
      (11): TransformerEncoderLayer(
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (dropout_module): FairseqDropout()
        (activation_dropout_module): FairseqDropout()
        (fc1): Linear(in_features=1024, out_features=4096, bias=True)
        (fc2): Linear(in_features=4096, out_features=1024, bias=True)
        (attn_ln): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)
        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (drop_path): Identity()
      )
    )
    (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (token_rel_pos_table_list): ModuleList(
      (0): Embedding(511, 16)
      (1): Embedding(511, 16)
      (2): Embedding(511, 16)
      (3): Embedding(511, 16)
      (4): Embedding(511, 16)
      (5): Embedding(511, 16)
      (6): Embedding(511, 16)
      (7): Embedding(511, 16)
      (8): Embedding(511, 16)
      (9): Embedding(511, 16)
      (10): Embedding(511, 16)
      (11): Embedding(511, 16)
    )
    (image_rel_pos_table_list): ModuleList(
      (0): Embedding(6892, 16)
      (1): Embedding(6892, 16)
      (2): Embedding(6892, 16)
      (3): Embedding(6892, 16)
      (4): Embedding(6892, 16)
      (5): Embedding(6892, 16)
      (6): Embedding(6892, 16)
      (7): Embedding(6892, 16)
      (8): Embedding(6892, 16)
      (9): Embedding(6892, 16)
      (10): Embedding(6892, 16)
      (11): Embedding(6892, 16)
    )
  )
  (decoder): TransformerDecoder(
    (dropout_module): FairseqDropout()
    (embed_tokens): Embedding(59457, 1024, padding_idx=1)
    (layernorm_embedding): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (embed_positions): Embedding(1026, 1024)
    (embed_image_positions): Embedding(1765, 1024)
    (pos_ln): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (image_pos_ln): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (self_pos_q_linear): Linear(in_features=1024, out_features=1024, bias=True)
    (self_pos_k_linear): Linear(in_features=1024, out_features=1024, bias=True)
    (cross_pos_q_linear): Linear(in_features=1024, out_features=1024, bias=True)
    (cross_pos_k_linear): Linear(in_features=1024, out_features=1024, bias=True)
    (code_layernorm_embedding): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (layers): ModuleList(
      (0): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (self_attn_ln): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (cross_attn_ln): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=1024, out_features=4096, bias=True)
        (fc2): Linear(in_features=4096, out_features=1024, bias=True)
        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (drop_path): Identity()
      )
      (1): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (self_attn_ln): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (cross_attn_ln): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=1024, out_features=4096, bias=True)
        (fc2): Linear(in_features=4096, out_features=1024, bias=True)
        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (drop_path): Identity()
      )
      (2): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (self_attn_ln): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (cross_attn_ln): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=1024, out_features=4096, bias=True)
        (fc2): Linear(in_features=4096, out_features=1024, bias=True)
        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (drop_path): Identity()
      )
      (3): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (self_attn_ln): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (cross_attn_ln): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=1024, out_features=4096, bias=True)
        (fc2): Linear(in_features=4096, out_features=1024, bias=True)
        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (drop_path): Identity()
      )
      (4): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (self_attn_ln): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (cross_attn_ln): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=1024, out_features=4096, bias=True)
        (fc2): Linear(in_features=4096, out_features=1024, bias=True)
        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (drop_path): Identity()
      )
      (5): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (self_attn_ln): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (cross_attn_ln): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=1024, out_features=4096, bias=True)
        (fc2): Linear(in_features=4096, out_features=1024, bias=True)
        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (drop_path): Identity()
      )
      (6): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (self_attn_ln): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (cross_attn_ln): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=1024, out_features=4096, bias=True)
        (fc2): Linear(in_features=4096, out_features=1024, bias=True)
        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (drop_path): Identity()
      )
      (7): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (self_attn_ln): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (cross_attn_ln): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=1024, out_features=4096, bias=True)
        (fc2): Linear(in_features=4096, out_features=1024, bias=True)
        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (drop_path): Identity()
      )
      (8): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (self_attn_ln): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (cross_attn_ln): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=1024, out_features=4096, bias=True)
        (fc2): Linear(in_features=4096, out_features=1024, bias=True)
        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (drop_path): Identity()
      )
      (9): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (self_attn_ln): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (cross_attn_ln): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=1024, out_features=4096, bias=True)
        (fc2): Linear(in_features=4096, out_features=1024, bias=True)
        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (drop_path): Identity()
      )
      (10): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (self_attn_ln): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (cross_attn_ln): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=1024, out_features=4096, bias=True)
        (fc2): Linear(in_features=4096, out_features=1024, bias=True)
        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (drop_path): Identity()
      )
      (11): TransformerDecoderLayer(
        (dropout_module): FairseqDropout()
        (self_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (self_attn_ln): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (cross_attn_ln): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (activation_dropout_module): FairseqDropout()
        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (encoder_attn): MultiheadAttention(
          (dropout_module): FairseqDropout()
          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)
          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)
        )
        (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (ffn_layernorm): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)
        (fc1): Linear(in_features=1024, out_features=4096, bias=True)
        (fc2): Linear(in_features=4096, out_features=1024, bias=True)
        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
        (drop_path): Identity()
      )
    )
    (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)
    (output_projection): Linear(in_features=1024, out_features=59457, bias=False)
    (token_rel_pos_table_list): ModuleList(
      (0): Embedding(511, 16)
      (1): Embedding(511, 16)
      (2): Embedding(511, 16)
      (3): Embedding(511, 16)
      (4): Embedding(511, 16)
      (5): Embedding(511, 16)
      (6): Embedding(511, 16)
      (7): Embedding(511, 16)
      (8): Embedding(511, 16)
      (9): Embedding(511, 16)
      (10): Embedding(511, 16)
      (11): Embedding(511, 16)
    )
    (image_rel_pos_table_list): ModuleList(
      (0): Embedding(6892, 16)
      (1): Embedding(6892, 16)
      (2): Embedding(6892, 16)
      (3): Embedding(6892, 16)
      (4): Embedding(6892, 16)
      (5): Embedding(6892, 16)
      (6): Embedding(6892, 16)
      (7): Embedding(6892, 16)
      (8): Embedding(6892, 16)
      (9): Embedding(6892, 16)
      (10): Embedding(6892, 16)
      (11): Embedding(6892, 16)
    )
  )
  (classification_heads): ModuleDict()
)
2022-05-19 21:23:35 - train.py[line:102] - INFO: task: CaptionTask
2022-05-19 21:23:35 - train.py[line:103] - INFO: model: OFAModel
2022-05-19 21:23:35 - train.py[line:104] - INFO: criterion: ScstRewardCriterion
2022-05-19 21:23:35 - train.py[line:108] - INFO: num. shared model params: 472,977,152 (num. trained: 411,964,288)
2022-05-19 21:23:35 - train.py[line:115] - INFO: num. expert model params: 0 (num. trained: 0)
local datafile ../../dataset/caption_data/caption_val_ct.tsv slice_id 0 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../dataset/caption_data/caption_val_ct.tsv slice_id 1 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../dataset/caption_data/caption_val_ct.tsv slice_id 0 finished initializing row_count and line_idx-to-offset mapping
file ../../dataset/caption_data/caption_val_ct.tsv slice_id 0 row count 2500 total row count 5000
/home/wgus5950/miniconda3/envs/ofa2/lib/python3.7/site-packages/torchvision/transforms/transforms.py:258: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.
  "Argument interpolation should be of type InterpolationMode instead of int. "
local datafile ../../dataset/caption_data/caption_val_ct.tsv slice_id 1 finished initializing row_count and line_idx-to-offset mapping
file ../../dataset/caption_data/caption_val_ct.tsv slice_id 1 row count 2500 total row count 5000
/home/wgus5950/miniconda3/envs/ofa2/lib/python3.7/site-packages/torchvision/transforms/transforms.py:258: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.
  "Argument interpolation should be of type InterpolationMode instead of int. "
2022-05-19 21:23:35 - distributed_c10d.py[line:187] - INFO: Added key: store_based_barrier_key:2 to store for rank: 0
2022-05-19 21:23:35 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_tokens.weight <- decoder.embed_tokens.weight
2022-05-19 21:23:35 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_tokens.weight <- decoder.output_projection.weight
2022-05-19 21:23:35 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.0.conv1.bias
2022-05-19 21:23:35 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.0.conv2.bias
2022-05-19 21:23:35 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.0.conv3.bias
2022-05-19 21:23:35 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.0.downsample.0.bias
2022-05-19 21:23:35 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.1.conv1.bias
2022-05-19 21:23:35 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.1.conv2.bias
2022-05-19 21:23:35 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.1.conv3.bias
2022-05-19 21:23:35 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.2.conv1.bias
2022-05-19 21:23:35 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.2.conv2.bias
2022-05-19 21:23:35 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer1.2.conv3.bias
2022-05-19 21:23:35 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.0.conv1.bias
2022-05-19 21:23:35 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.0.conv2.bias
2022-05-19 21:23:35 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.0.conv3.bias
2022-05-19 21:23:35 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.0.downsample.0.bias
2022-05-19 21:23:35 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.1.conv1.bias
2022-05-19 21:23:35 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.1.conv2.bias
2022-05-19 21:23:35 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.1.conv3.bias
2022-05-19 21:23:35 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.2.conv1.bias
2022-05-19 21:23:35 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.2.conv2.bias
2022-05-19 21:23:35 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.2.conv3.bias
2022-05-19 21:23:35 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.3.conv1.bias
2022-05-19 21:23:35 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.3.conv2.bias
2022-05-19 21:23:35 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.3.conv3.bias
2022-05-19 21:23:35 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.4.conv1.bias
2022-05-19 21:23:35 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.4.conv2.bias
2022-05-19 21:23:35 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.4.conv3.bias
2022-05-19 21:23:35 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.5.conv1.bias
2022-05-19 21:23:35 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.5.conv2.bias
2022-05-19 21:23:35 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.5.conv3.bias
2022-05-19 21:23:35 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.6.conv1.bias
2022-05-19 21:23:35 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.6.conv2.bias
2022-05-19 21:23:35 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.6.conv3.bias
2022-05-19 21:23:35 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.7.conv1.bias
2022-05-19 21:23:35 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.7.conv2.bias
2022-05-19 21:23:35 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer2.7.conv3.bias
2022-05-19 21:23:35 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.0.conv1.bias
2022-05-19 21:23:35 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.0.conv2.bias
2022-05-19 21:23:35 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.0.conv3.bias
2022-05-19 21:23:35 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.0.downsample.0.bias
2022-05-19 21:23:35 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.1.conv1.bias
2022-05-19 21:23:35 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.1.conv2.bias
2022-05-19 21:23:35 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.1.conv3.bias
2022-05-19 21:23:35 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.2.conv1.bias
2022-05-19 21:23:35 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.2.conv2.bias
2022-05-19 21:23:35 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.2.conv3.bias
2022-05-19 21:23:35 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.3.conv1.bias
2022-05-19 21:23:35 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.3.conv2.bias
2022-05-19 21:23:35 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.3.conv3.bias
2022-05-19 21:23:35 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.4.conv1.bias
2022-05-19 21:23:35 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.4.conv2.bias
2022-05-19 21:23:35 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.4.conv3.bias
2022-05-19 21:23:35 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.5.conv1.bias
2022-05-19 21:23:35 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.5.conv2.bias
2022-05-19 21:23:35 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.5.conv3.bias
2022-05-19 21:23:35 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.6.conv1.bias
2022-05-19 21:23:35 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.6.conv2.bias
2022-05-19 21:23:35 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.6.conv3.bias
2022-05-19 21:23:35 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.7.conv1.bias
2022-05-19 21:23:35 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.7.conv2.bias
2022-05-19 21:23:35 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.7.conv3.bias
2022-05-19 21:23:35 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.8.conv1.bias
2022-05-19 21:23:35 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.8.conv2.bias
2022-05-19 21:23:35 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.8.conv3.bias
2022-05-19 21:23:35 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.9.conv1.bias
2022-05-19 21:23:35 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.9.conv2.bias
2022-05-19 21:23:35 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.9.conv3.bias
2022-05-19 21:23:35 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.10.conv1.bias
2022-05-19 21:23:35 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.10.conv2.bias
2022-05-19 21:23:35 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.10.conv3.bias
2022-05-19 21:23:35 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.11.conv1.bias
2022-05-19 21:23:35 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.11.conv2.bias
2022-05-19 21:23:35 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.11.conv3.bias
2022-05-19 21:23:35 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.12.conv1.bias
2022-05-19 21:23:35 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.12.conv2.bias
2022-05-19 21:23:35 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.12.conv3.bias
2022-05-19 21:23:35 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.13.conv1.bias
2022-05-19 21:23:35 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.13.conv2.bias
2022-05-19 21:23:35 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.13.conv3.bias
2022-05-19 21:23:35 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.14.conv1.bias
2022-05-19 21:23:35 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.14.conv2.bias
2022-05-19 21:23:35 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.14.conv3.bias
2022-05-19 21:23:35 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.15.conv1.bias
2022-05-19 21:23:35 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.15.conv2.bias
2022-05-19 21:23:35 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.15.conv3.bias
2022-05-19 21:23:35 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.16.conv1.bias
2022-05-19 21:23:35 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.16.conv2.bias
2022-05-19 21:23:35 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.16.conv3.bias
2022-05-19 21:23:35 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.17.conv1.bias
2022-05-19 21:23:35 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.17.conv2.bias
2022-05-19 21:23:35 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.17.conv3.bias
2022-05-19 21:23:35 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.18.conv1.bias
2022-05-19 21:23:35 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.18.conv2.bias
2022-05-19 21:23:35 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.18.conv3.bias
2022-05-19 21:23:35 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.19.conv1.bias
2022-05-19 21:23:35 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.19.conv2.bias
2022-05-19 21:23:35 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.19.conv3.bias
2022-05-19 21:23:35 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.20.conv1.bias
2022-05-19 21:23:35 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.20.conv2.bias
2022-05-19 21:23:35 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.20.conv3.bias
2022-05-19 21:23:35 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.21.conv1.bias
2022-05-19 21:23:35 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.21.conv2.bias
2022-05-19 21:23:35 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.21.conv3.bias
2022-05-19 21:23:35 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.22.conv1.bias
2022-05-19 21:23:35 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.22.conv2.bias
2022-05-19 21:23:35 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.22.conv3.bias
2022-05-19 21:23:35 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.23.conv1.bias
2022-05-19 21:23:35 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.23.conv2.bias
2022-05-19 21:23:35 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.23.conv3.bias
2022-05-19 21:23:35 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.24.conv1.bias
2022-05-19 21:23:35 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.24.conv2.bias
2022-05-19 21:23:35 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.24.conv3.bias
2022-05-19 21:23:35 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.25.conv1.bias
2022-05-19 21:23:35 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.25.conv2.bias
2022-05-19 21:23:35 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.25.conv3.bias
2022-05-19 21:23:35 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.26.conv1.bias
2022-05-19 21:23:35 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.26.conv2.bias
2022-05-19 21:23:35 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.26.conv3.bias
2022-05-19 21:23:35 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.27.conv1.bias
2022-05-19 21:23:35 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.27.conv2.bias
2022-05-19 21:23:35 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.27.conv3.bias
2022-05-19 21:23:35 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.28.conv1.bias
2022-05-19 21:23:35 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.28.conv2.bias
2022-05-19 21:23:35 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.28.conv3.bias
2022-05-19 21:23:35 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.29.conv1.bias
2022-05-19 21:23:35 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.29.conv2.bias
2022-05-19 21:23:35 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.29.conv3.bias
2022-05-19 21:23:35 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.30.conv1.bias
2022-05-19 21:23:35 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.30.conv2.bias
2022-05-19 21:23:35 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.30.conv3.bias
2022-05-19 21:23:35 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.31.conv1.bias
2022-05-19 21:23:35 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.31.conv2.bias
2022-05-19 21:23:35 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.31.conv3.bias
2022-05-19 21:23:35 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.32.conv1.bias
2022-05-19 21:23:35 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.32.conv2.bias
2022-05-19 21:23:35 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.32.conv3.bias
2022-05-19 21:23:35 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.33.conv1.bias
2022-05-19 21:23:35 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.33.conv2.bias
2022-05-19 21:23:35 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.33.conv3.bias
2022-05-19 21:23:35 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.34.conv1.bias
2022-05-19 21:23:35 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.34.conv2.bias
2022-05-19 21:23:35 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.34.conv3.bias
2022-05-19 21:23:35 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.35.conv1.bias
2022-05-19 21:23:35 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.35.conv2.bias
2022-05-19 21:23:35 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- encoder.embed_images.layer3.35.conv3.bias
2022-05-19 21:23:35 - trainer.py[line:124] - INFO: detected shared parameter: encoder.embed_images.conv1.bias <- decoder.output_projection.bias
2022-05-19 21:23:35 - utils.py[line:759] - INFO: ***********************CUDA enviroments for all 2 workers***********************
2022-05-19 21:23:35 - utils.py[line:765] - INFO: rank   0: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2022-05-19 21:23:35 - utils.py[line:765] - INFO: rank   1: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
2022-05-19 21:23:35 - utils.py[line:767] - INFO: ***********************CUDA enviroments for all 2 workers***********************
2022-05-19 21:23:35 - train.py[line:145] - INFO: training on 2 devices (GPUs/TPUs)
2022-05-19 21:23:35 - train.py[line:151] - INFO: max tokens per device = None and max sentences per device = 1
2022-05-19 21:23:35 - trainer.py[line:458] - INFO: Preparing to load checkpoint ../../checkpoints/checkpoint_last.pt
2022-05-19 21:23:43 - trainer.py[line:619] - INFO: Loaded checkpoint ../../checkpoints/checkpoint_last.pt (epoch 2 @ 0 updates)
local datafile ../../dataset/caption_data/caption_stage1_train_ct2.tsv slice_id 1 begin to initialize row_count and line_idx-to-offset mapping
2022-05-19 21:23:44 - trainer.py[line:639] - INFO: loading train data for epoch 1
local datafile ../../dataset/caption_data/caption_stage1_train_ct2.tsv slice_id 0 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../dataset/caption_data/caption_stage1_train_ct2.tsv slice_id 1 finished initializing row_count and line_idx-to-offset mapping
file ../../dataset/caption_data/caption_stage1_train_ct2.tsv slice_id 1 row count 56643 total row count 113287
slice_id 1 seek offset 56644
Total steps 14162, warmup steps 849, warmup_factor 0.001177856301531213
local datafile ../../dataset/caption_data/caption_stage1_train_ct2.tsv slice_id 0 finished initializing row_count and line_idx-to-offset mapping
file ../../dataset/caption_data/caption_stage1_train_ct2.tsv slice_id 0 row count 56644 total row count 113287
slice_id 0 seek offset 0
Total steps 14162, warmup steps 849, warmup_factor 0.001177856301531213
2022-05-19 21:23:47 - trainer.py[line:703] - INFO: begin training epoch 1
2022-05-19 21:23:47 - train.py[line:296] - INFO: Start iterating over samples
/home/wgus5950/OFA/fairseq/fairseq/utils.py:373: UserWarning: amp_C fused kernels unavailable, disabling multi_tensor_l2norm; you may get better performance by installing NVIDIA's apex library
  "amp_C fused kernels unavailable, disabling multi_tensor_l2norm; "
/home/wgus5950/OFA/fairseq/fairseq/utils.py:373: UserWarning: amp_C fused kernels unavailable, disabling multi_tensor_l2norm; you may get better performance by installing NVIDIA's apex library
  "amp_C fused kernels unavailable, disabling multi_tensor_l2norm; "
2022-05-19 21:25:10 - progress_bar.py[line:274] - INFO: epoch 001:     10 / 7081 loss=-0.003, score=1.31, ntokens=898.8, nsentences=80, sample_size=898.8, wps=110.2, ups=0.12, wpb=898.8, bsz=80, num_updates=10, lr=5.88928e-08, gnorm=1.799, clip=90, loss_scale=128, train_wall=83, gb_free=6.8, wall=95
2022-05-19 21:26:29 - progress_bar.py[line:274] - INFO: epoch 001:     20 / 7081 loss=-0.005, score=1.414, ntokens=882.3, nsentences=80, sample_size=882.3, wps=111.4, ups=0.13, wpb=882.3, bsz=80, num_updates=20, lr=1.17786e-07, gnorm=1.461, clip=80, loss_scale=128, train_wall=79, gb_free=6.8, wall=174
2022-05-19 21:27:45 - progress_bar.py[line:274] - INFO: epoch 001:     30 / 7081 loss=-0.008, score=1.413, ntokens=871.5, nsentences=80, sample_size=871.5, wps=114.2, ups=0.13, wpb=871.5, bsz=80, num_updates=30, lr=1.76678e-07, gnorm=1.767, clip=80, loss_scale=128, train_wall=76, gb_free=6.8, wall=250
2022-05-19 21:29:03 - progress_bar.py[line:274] - INFO: epoch 001:     40 / 7081 loss=-0.003, score=1.316, ntokens=879.9, nsentences=80, sample_size=879.9, wps=113.2, ups=0.13, wpb=879.9, bsz=80, num_updates=40, lr=2.35571e-07, gnorm=1.601, clip=80, loss_scale=128, train_wall=78, gb_free=6.8, wall=328
2022-05-19 21:30:25 - progress_bar.py[line:274] - INFO: epoch 001:     50 / 7081 loss=-0.008, score=1.389, ntokens=883, nsentences=80, sample_size=883, wps=108, ups=0.12, wpb=883, bsz=80, num_updates=50, lr=2.94464e-07, gnorm=1.394, clip=80, loss_scale=128, train_wall=82, gb_free=6.8, wall=410
2022-05-19 21:31:46 - progress_bar.py[line:274] - INFO: epoch 001:     60 / 7081 loss=-0.003, score=1.414, ntokens=879.5, nsentences=80, sample_size=879.5, wps=109, ups=0.12, wpb=879.5, bsz=80, num_updates=60, lr=3.53357e-07, gnorm=1.663, clip=90, loss_scale=128, train_wall=81, gb_free=6.8, wall=490
2022-05-19 21:33:07 - progress_bar.py[line:274] - INFO: epoch 001:     70 / 7081 loss=-0.004, score=1.408, ntokens=888.8, nsentences=80, sample_size=888.8, wps=108.8, ups=0.12, wpb=888.8, bsz=80, num_updates=70, lr=4.1225e-07, gnorm=1.447, clip=60, loss_scale=128, train_wall=82, gb_free=6.8, wall=572
2022-05-19 21:34:29 - progress_bar.py[line:274] - INFO: epoch 001:     80 / 7081 loss=-0.005, score=1.497, ntokens=881.4, nsentences=80, sample_size=881.4, wps=107.7, ups=0.12, wpb=881.4, bsz=80, num_updates=80, lr=4.71143e-07, gnorm=1.581, clip=90, loss_scale=128, train_wall=82, gb_free=6.8, wall=654
2022-05-19 21:35:50 - progress_bar.py[line:274] - INFO: epoch 001:     90 / 7081 loss=-0.004, score=1.506, ntokens=888, nsentences=80, sample_size=888, wps=109.6, ups=0.12, wpb=888, bsz=80, num_updates=90, lr=5.30035e-07, gnorm=2.042, clip=90, loss_scale=128, train_wall=81, gb_free=6.8, wall=735
2022-05-19 21:36:39 - trainer.py[line:922] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-05-19 21:37:20 - progress_bar.py[line:274] - INFO: epoch 001:    101 / 7081 loss=-0.007, score=1.464, ntokens=884, nsentences=80, sample_size=884, wps=98.5, ups=0.11, wpb=884, bsz=80, num_updates=100, lr=5.88928e-07, gnorm=2.143, clip=70, loss_scale=64, train_wall=90, gb_free=6.8, wall=825
2022-05-19 21:38:42 - progress_bar.py[line:274] - INFO: epoch 001:    111 / 7081 loss=-0.005, score=1.411, ntokens=889.5, nsentences=80, sample_size=889.5, wps=108.9, ups=0.12, wpb=889.5, bsz=80, num_updates=110, lr=6.47821e-07, gnorm=2.014, clip=90, loss_scale=64, train_wall=82, gb_free=6.8, wall=906
2022-05-19 21:40:03 - progress_bar.py[line:274] - INFO: epoch 001:    121 / 7081 loss=-0.005, score=1.406, ntokens=893, nsentences=80, sample_size=893, wps=109.4, ups=0.12, wpb=893, bsz=80, num_updates=120, lr=7.06714e-07, gnorm=1.263, clip=60, loss_scale=64, train_wall=82, gb_free=6.8, wall=988
2022-05-19 21:41:25 - progress_bar.py[line:274] - INFO: epoch 001:    131 / 7081 loss=-0.006, score=1.387, ntokens=878.3, nsentences=80, sample_size=878.3, wps=107.8, ups=0.12, wpb=878.3, bsz=80, num_updates=130, lr=7.65607e-07, gnorm=1.653, clip=80, loss_scale=64, train_wall=81, gb_free=6.8, wall=1069
2022-05-19 21:42:46 - progress_bar.py[line:274] - INFO: epoch 001:    141 / 7081 loss=-0.005, score=1.392, ntokens=884.2, nsentences=80, sample_size=884.2, wps=108.8, ups=0.12, wpb=884.2, bsz=80, num_updates=140, lr=8.24499e-07, gnorm=1.72, clip=90, loss_scale=64, train_wall=81, gb_free=6.8, wall=1151
2022-05-19 21:44:08 - progress_bar.py[line:274] - INFO: epoch 001:    151 / 7081 loss=-0.003, score=1.432, ntokens=880.8, nsentences=80, sample_size=880.8, wps=107.9, ups=0.12, wpb=880.8, bsz=80, num_updates=150, lr=8.83392e-07, gnorm=1.597, clip=90, loss_scale=64, train_wall=82, gb_free=6.8, wall=1232
2022-05-19 21:45:29 - progress_bar.py[line:274] - INFO: epoch 001:    161 / 7081 loss=-0.005, score=1.345, ntokens=876.4, nsentences=80, sample_size=876.4, wps=107.7, ups=0.12, wpb=876.4, bsz=80, num_updates=160, lr=9.42285e-07, gnorm=1.566, clip=70, loss_scale=64, train_wall=81, gb_free=6.7, wall=1314
2022-05-19 21:46:51 - progress_bar.py[line:274] - INFO: epoch 001:    171 / 7081 loss=-0.004, score=1.353, ntokens=897.2, nsentences=80, sample_size=897.2, wps=109.8, ups=0.12, wpb=897.2, bsz=80, num_updates=170, lr=1.00118e-06, gnorm=1.561, clip=80, loss_scale=64, train_wall=82, gb_free=6.8, wall=1395
2022-05-19 21:48:12 - progress_bar.py[line:274] - INFO: epoch 001:    181 / 7081 loss=-0.005, score=1.41, ntokens=883.9, nsentences=80, sample_size=883.9, wps=108.4, ups=0.12, wpb=883.9, bsz=80, num_updates=180, lr=1.06007e-06, gnorm=1.612, clip=100, loss_scale=64, train_wall=81, gb_free=6.8, wall=1477
2022-05-19 21:49:34 - progress_bar.py[line:274] - INFO: epoch 001:    191 / 7081 loss=-0.004, score=1.418, ntokens=895.1, nsentences=80, sample_size=895.1, wps=109.3, ups=0.12, wpb=895.1, bsz=80, num_updates=190, lr=1.11896e-06, gnorm=1.514, clip=70, loss_scale=64, train_wall=82, gb_free=6.8, wall=1559
2022-05-19 21:50:55 - progress_bar.py[line:274] - INFO: epoch 001:    201 / 7081 loss=-0.006, score=1.415, ntokens=879.8, nsentences=80, sample_size=879.8, wps=108.1, ups=0.12, wpb=879.8, bsz=80, num_updates=200, lr=1.17786e-06, gnorm=1.77, clip=90, loss_scale=64, train_wall=81, gb_free=6.8, wall=1640
2022-05-19 21:52:16 - progress_bar.py[line:274] - INFO: epoch 001:    211 / 7081 loss=-0.006, score=1.406, ntokens=899.7, nsentences=80, sample_size=899.7, wps=111.3, ups=0.12, wpb=899.7, bsz=80, num_updates=210, lr=1.23675e-06, gnorm=1.312, clip=70, loss_scale=64, train_wall=81, gb_free=6.8, wall=1721
2022-05-19 21:53:34 - progress_bar.py[line:274] - INFO: epoch 001:    221 / 7081 loss=-0.006, score=1.393, ntokens=890, nsentences=80, sample_size=890, wps=115.1, ups=0.13, wpb=890, bsz=80, num_updates=220, lr=1.29564e-06, gnorm=1.792, clip=70, loss_scale=64, train_wall=77, gb_free=6.8, wall=1798
2022-05-19 21:54:51 - progress_bar.py[line:274] - INFO: epoch 001:    231 / 7081 loss=-0.003, score=1.467, ntokens=897, nsentences=80, sample_size=897, wps=116.4, ups=0.13, wpb=897, bsz=80, num_updates=230, lr=1.35453e-06, gnorm=1.459, clip=90, loss_scale=64, train_wall=77, gb_free=6.8, wall=1875
2022-05-19 21:56:11 - progress_bar.py[line:274] - INFO: epoch 001:    241 / 7081 loss=-0.003, score=1.455, ntokens=876.6, nsentences=80, sample_size=876.6, wps=108.4, ups=0.12, wpb=876.6, bsz=80, num_updates=240, lr=1.41343e-06, gnorm=1.412, clip=80, loss_scale=64, train_wall=81, gb_free=6.8, wall=1956
2022-05-19 21:57:33 - progress_bar.py[line:274] - INFO: epoch 001:    251 / 7081 loss=-0.005, score=1.385, ntokens=880.7, nsentences=80, sample_size=880.7, wps=108.3, ups=0.12, wpb=880.7, bsz=80, num_updates=250, lr=1.47232e-06, gnorm=1.335, clip=80, loss_scale=64, train_wall=81, gb_free=6.8, wall=2037
2022-05-19 21:58:54 - progress_bar.py[line:274] - INFO: epoch 001:    261 / 7081 loss=-0.01, score=1.435, ntokens=892.9, nsentences=80, sample_size=892.9, wps=109.5, ups=0.12, wpb=892.9, bsz=80, num_updates=260, lr=1.53121e-06, gnorm=1.639, clip=90, loss_scale=64, train_wall=81, gb_free=6.7, wall=2119
2022-05-19 22:00:15 - progress_bar.py[line:274] - INFO: epoch 001:    271 / 7081 loss=-0.006, score=1.499, ntokens=872.7, nsentences=80, sample_size=872.7, wps=107.8, ups=0.12, wpb=872.7, bsz=80, num_updates=270, lr=1.59011e-06, gnorm=1.519, clip=70, loss_scale=64, train_wall=81, gb_free=6.7, wall=2200
2022-05-19 22:01:37 - progress_bar.py[line:274] - INFO: epoch 001:    281 / 7081 loss=-0.005, score=1.367, ntokens=894.9, nsentences=80, sample_size=894.9, wps=109.8, ups=0.12, wpb=894.9, bsz=80, num_updates=280, lr=1.649e-06, gnorm=1.629, clip=90, loss_scale=64, train_wall=81, gb_free=6.8, wall=2281
2022-05-19 22:02:59 - progress_bar.py[line:274] - INFO: epoch 001:    291 / 7081 loss=-0.003, score=1.424, ntokens=883.1, nsentences=80, sample_size=883.1, wps=107.8, ups=0.12, wpb=883.1, bsz=80, num_updates=290, lr=1.70789e-06, gnorm=1.817, clip=80, loss_scale=64, train_wall=82, gb_free=6.8, wall=2363
2022-05-19 22:04:20 - progress_bar.py[line:274] - INFO: epoch 001:    301 / 7081 loss=-0.009, score=1.397, ntokens=896, nsentences=80, sample_size=896, wps=109.6, ups=0.12, wpb=896, bsz=80, num_updates=300, lr=1.76678e-06, gnorm=1.834, clip=60, loss_scale=64, train_wall=82, gb_free=6.8, wall=2445
2022-05-19 22:05:43 - progress_bar.py[line:274] - INFO: epoch 001:    311 / 7081 loss=-0.007, score=1.501, ntokens=886.7, nsentences=80, sample_size=886.7, wps=108, ups=0.12, wpb=886.7, bsz=80, num_updates=310, lr=1.82568e-06, gnorm=1.322, clip=60, loss_scale=64, train_wall=82, gb_free=6.8, wall=2527
2022-05-19 22:07:04 - progress_bar.py[line:274] - INFO: epoch 001:    321 / 7081 loss=-0.006, score=1.345, ntokens=894.3, nsentences=80, sample_size=894.3, wps=109.6, ups=0.12, wpb=894.3, bsz=80, num_updates=320, lr=1.88457e-06, gnorm=1.588, clip=80, loss_scale=64, train_wall=82, gb_free=6.8, wall=2609
2022-05-19 22:08:26 - progress_bar.py[line:274] - INFO: epoch 001:    331 / 7081 loss=-0.006, score=1.436, ntokens=888.9, nsentences=80, sample_size=888.9, wps=108.7, ups=0.12, wpb=888.9, bsz=80, num_updates=330, lr=1.94346e-06, gnorm=1.505, clip=90, loss_scale=64, train_wall=82, gb_free=6.8, wall=2691
2022-05-19 22:09:48 - progress_bar.py[line:274] - INFO: epoch 001:    341 / 7081 loss=-0.005, score=1.394, ntokens=889.5, nsentences=80, sample_size=889.5, wps=109, ups=0.12, wpb=889.5, bsz=80, num_updates=340, lr=2.00236e-06, gnorm=1.342, clip=90, loss_scale=64, train_wall=82, gb_free=6.8, wall=2772
2022-05-19 22:11:08 - progress_bar.py[line:274] - INFO: epoch 001:    351 / 7081 loss=-0.003, score=1.398, ntokens=882.5, nsentences=80, sample_size=882.5, wps=109, ups=0.12, wpb=882.5, bsz=80, num_updates=350, lr=2.06125e-06, gnorm=1.547, clip=90, loss_scale=64, train_wall=81, gb_free=6.8, wall=2853
2022-05-19 22:12:30 - progress_bar.py[line:274] - INFO: epoch 001:    361 / 7081 loss=-0.004, score=1.372, ntokens=890.6, nsentences=80, sample_size=890.6, wps=108.6, ups=0.12, wpb=890.6, bsz=80, num_updates=360, lr=2.12014e-06, gnorm=1.453, clip=80, loss_scale=64, train_wall=82, gb_free=6.8, wall=2935
2022-05-19 22:13:52 - progress_bar.py[line:274] - INFO: epoch 001:    371 / 7081 loss=-0.005, score=1.467, ntokens=874.6, nsentences=80, sample_size=874.6, wps=107.5, ups=0.12, wpb=874.6, bsz=80, num_updates=370, lr=2.17903e-06, gnorm=1.538, clip=100, loss_scale=64, train_wall=81, gb_free=6.8, wall=3016
2022-05-19 22:15:14 - progress_bar.py[line:274] - INFO: epoch 001:    381 / 7081 loss=-0.004, score=1.444, ntokens=890.9, nsentences=80, sample_size=890.9, wps=109, ups=0.12, wpb=890.9, bsz=80, num_updates=380, lr=2.23793e-06, gnorm=1.506, clip=80, loss_scale=64, train_wall=82, gb_free=6.8, wall=3098
2022-05-19 22:16:36 - progress_bar.py[line:274] - INFO: epoch 001:    391 / 7081 loss=-0.006, score=1.565, ntokens=893.9, nsentences=80, sample_size=893.9, wps=108.8, ups=0.12, wpb=893.9, bsz=80, num_updates=390, lr=2.29682e-06, gnorm=1.494, clip=70, loss_scale=64, train_wall=82, gb_free=6.8, wall=3180
2022-05-19 22:17:58 - progress_bar.py[line:274] - INFO: epoch 001:    401 / 7081 loss=-0.007, score=1.593, ntokens=903.3, nsentences=80, sample_size=903.3, wps=110.1, ups=0.12, wpb=903.3, bsz=80, num_updates=400, lr=2.35571e-06, gnorm=1.669, clip=90, loss_scale=64, train_wall=82, gb_free=6.8, wall=3262
2022-05-19 22:19:16 - progress_bar.py[line:274] - INFO: epoch 001:    411 / 7081 loss=-0.006, score=1.401, ntokens=888.6, nsentences=80, sample_size=888.6, wps=113.8, ups=0.13, wpb=888.6, bsz=80, num_updates=410, lr=2.41461e-06, gnorm=1.558, clip=80, loss_scale=64, train_wall=78, gb_free=6.8, wall=3341
2022-05-19 22:20:32 - progress_bar.py[line:274] - INFO: epoch 001:    421 / 7081 loss=-0.005, score=1.304, ntokens=879.2, nsentences=80, sample_size=879.2, wps=115.1, ups=0.13, wpb=879.2, bsz=80, num_updates=420, lr=2.4735e-06, gnorm=1.246, clip=60, loss_scale=64, train_wall=76, gb_free=6.8, wall=3417
2022-05-19 22:21:52 - progress_bar.py[line:274] - INFO: epoch 001:    431 / 7081 loss=-0.004, score=1.377, ntokens=887.6, nsentences=80, sample_size=887.6, wps=111.7, ups=0.13, wpb=887.6, bsz=80, num_updates=430, lr=2.53239e-06, gnorm=1.356, clip=70, loss_scale=64, train_wall=79, gb_free=6.7, wall=3496
2022-05-19 22:23:13 - progress_bar.py[line:274] - INFO: epoch 001:    441 / 7081 loss=-0.007, score=1.272, ntokens=881.9, nsentences=80, sample_size=881.9, wps=109, ups=0.12, wpb=881.9, bsz=80, num_updates=440, lr=2.59128e-06, gnorm=1.404, clip=70, loss_scale=64, train_wall=81, gb_free=6.8, wall=3577
2022-05-19 22:24:35 - progress_bar.py[line:274] - INFO: epoch 001:    451 / 7081 loss=-0.006, score=1.539, ntokens=892.8, nsentences=80, sample_size=892.8, wps=108.7, ups=0.12, wpb=892.8, bsz=80, num_updates=450, lr=2.65018e-06, gnorm=1.412, clip=90, loss_scale=64, train_wall=82, gb_free=6.8, wall=3659
2022-05-19 22:25:57 - progress_bar.py[line:274] - INFO: epoch 001:    461 / 7081 loss=-0.007, score=1.369, ntokens=893.1, nsentences=80, sample_size=893.1, wps=109.1, ups=0.12, wpb=893.1, bsz=80, num_updates=460, lr=2.70907e-06, gnorm=1.441, clip=80, loss_scale=64, train_wall=82, gb_free=6.8, wall=3741
2022-05-19 22:27:17 - progress_bar.py[line:274] - INFO: epoch 001:    471 / 7081 loss=-0.006, score=1.307, ntokens=874.9, nsentences=80, sample_size=874.9, wps=108.2, ups=0.12, wpb=874.9, bsz=80, num_updates=470, lr=2.76796e-06, gnorm=1.141, clip=50, loss_scale=64, train_wall=81, gb_free=6.8, wall=3822
2022-05-19 22:28:38 - progress_bar.py[line:274] - INFO: epoch 001:    481 / 7081 loss=-0.005, score=1.482, ntokens=871.6, nsentences=80, sample_size=871.6, wps=107.8, ups=0.12, wpb=871.6, bsz=80, num_updates=480, lr=2.82686e-06, gnorm=1.512, clip=80, loss_scale=64, train_wall=81, gb_free=6.8, wall=3903
2022-05-19 22:30:01 - progress_bar.py[line:274] - INFO: epoch 001:    491 / 7081 loss=-0.007, score=1.418, ntokens=900.4, nsentences=80, sample_size=900.4, wps=109.5, ups=0.12, wpb=900.4, bsz=80, num_updates=490, lr=2.88575e-06, gnorm=1.921, clip=100, loss_scale=64, train_wall=82, gb_free=6.8, wall=3985
2022-05-19 22:31:22 - progress_bar.py[line:274] - INFO: epoch 001:    501 / 7081 loss=-0.006, score=1.428, ntokens=884.8, nsentences=80, sample_size=884.8, wps=108.8, ups=0.12, wpb=884.8, bsz=80, num_updates=500, lr=2.94464e-06, gnorm=2.437, clip=90, loss_scale=64, train_wall=81, gb_free=6.8, wall=4067
2022-05-19 22:31:22 - train.py[line:436] - INFO: begin validation on "valid" subset
slice_id 0 seek offset 0
slice_id 0 seek offset 0
slice_id 1 seek offset 2500
slice_id 1 seek offset 2500
2022-05-19 23:11:48 - progress_bar.py[line:282] - INFO: epoch 001 | valid on 'valid' subset | loss -0.004 | score 1.285 | ntokens 111.229 | nsentences 10 | sample_size 111.229 | cider 1.374 | wps 114.6 | wpb 111.2 | bsz 10 | num_updates 500
2022-05-19 23:11:48 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 1 @ 500 updates
2022-05-19 23:11:48 - trainer.py[line:431] - INFO: Saving checkpoint to /database/jhkim/stage2_checkpoints//5e-6_2/checkpoint_1_500.pt
2022-05-19 23:11:56 - trainer.py[line:441] - INFO: Finished saving checkpoint to /database/jhkim/stage2_checkpoints//5e-6_2/checkpoint_1_500.pt
2022-05-19 23:12:08 - checkpoint_utils.py[line:135] - INFO: Saved checkpoint /database/jhkim/stage2_checkpoints//5e-6_2/checkpoint_1_500.pt (epoch 1 @ 500 updates, score 1.374) (writing took 20.651403927011415 seconds)
2022-05-19 23:13:25 - progress_bar.py[line:274] - INFO: epoch 001:    511 / 7081 loss=-0.003, score=1.439, ntokens=880.9, nsentences=80, sample_size=880.9, wps=3.5, ups=0, wpb=880.9, bsz=80, num_updates=510, lr=3.00353e-06, gnorm=1.331, clip=90, loss_scale=64, train_wall=77, gb_free=6.7, wall=6589
2022-05-19 23:14:46 - progress_bar.py[line:274] - INFO: epoch 001:    521 / 7081 loss=-0.006, score=1.349, ntokens=894.8, nsentences=80, sample_size=894.8, wps=110.1, ups=0.12, wpb=894.8, bsz=80, num_updates=520, lr=3.06243e-06, gnorm=1.54, clip=80, loss_scale=64, train_wall=81, gb_free=6.8, wall=6671
2022-05-19 23:16:07 - progress_bar.py[line:274] - INFO: epoch 001:    531 / 7081 loss=-0.005, score=1.346, ntokens=888, nsentences=80, sample_size=888, wps=109.8, ups=0.12, wpb=888, bsz=80, num_updates=530, lr=3.12132e-06, gnorm=1.289, clip=70, loss_scale=64, train_wall=81, gb_free=6.8, wall=6752
2022-05-19 23:17:28 - progress_bar.py[line:274] - INFO: epoch 001:    541 / 7081 loss=-0.005, score=1.401, ntokens=883.5, nsentences=80, sample_size=883.5, wps=109.2, ups=0.12, wpb=883.5, bsz=80, num_updates=540, lr=3.18021e-06, gnorm=1.342, clip=90, loss_scale=64, train_wall=81, gb_free=6.8, wall=6833
2022-05-19 23:18:49 - progress_bar.py[line:274] - INFO: epoch 001:    551 / 7081 loss=-0.005, score=1.422, ntokens=878.9, nsentences=80, sample_size=878.9, wps=108.4, ups=0.12, wpb=878.9, bsz=80, num_updates=550, lr=3.2391e-06, gnorm=1.01, clip=60, loss_scale=64, train_wall=81, gb_free=6.8, wall=6914
2022-05-19 23:20:10 - progress_bar.py[line:274] - INFO: epoch 001:    561 / 7081 loss=-0.007, score=1.457, ntokens=894.1, nsentences=80, sample_size=894.1, wps=109.9, ups=0.12, wpb=894.1, bsz=80, num_updates=560, lr=3.298e-06, gnorm=1.466, clip=80, loss_scale=64, train_wall=81, gb_free=6.8, wall=6995
2022-05-19 23:21:31 - progress_bar.py[line:274] - INFO: epoch 001:    571 / 7081 loss=-0.006, score=1.451, ntokens=897, nsentences=80, sample_size=897, wps=110.5, ups=0.12, wpb=897, bsz=80, num_updates=570, lr=3.35689e-06, gnorm=1.345, clip=100, loss_scale=64, train_wall=81, gb_free=6.8, wall=7076
2022-05-19 23:22:53 - progress_bar.py[line:274] - INFO: epoch 001:    581 / 7081 loss=-0.004, score=1.44, ntokens=894.4, nsentences=80, sample_size=894.4, wps=109.5, ups=0.12, wpb=894.4, bsz=80, num_updates=580, lr=3.41578e-06, gnorm=1.579, clip=80, loss_scale=64, train_wall=82, gb_free=6.8, wall=7158
2022-05-19 23:24:15 - progress_bar.py[line:274] - INFO: epoch 001:    591 / 7081 loss=-0.007, score=1.463, ntokens=894, nsentences=80, sample_size=894, wps=108.9, ups=0.12, wpb=894, bsz=80, num_updates=590, lr=3.47468e-06, gnorm=1.656, clip=100, loss_scale=64, train_wall=82, gb_free=6.8, wall=7240
2022-05-19 23:25:36 - progress_bar.py[line:274] - INFO: epoch 001:    601 / 7081 loss=-0.005, score=1.472, ntokens=887.9, nsentences=80, sample_size=887.9, wps=109.3, ups=0.12, wpb=887.9, bsz=80, num_updates=600, lr=3.53357e-06, gnorm=1.692, clip=90, loss_scale=64, train_wall=81, gb_free=6.8, wall=7321
2022-05-19 23:26:58 - progress_bar.py[line:274] - INFO: epoch 001:    611 / 7081 loss=-0.006, score=1.436, ntokens=895.6, nsentences=80, sample_size=895.6, wps=110.2, ups=0.12, wpb=895.6, bsz=80, num_updates=610, lr=3.59246e-06, gnorm=1.602, clip=90, loss_scale=128, train_wall=81, gb_free=6.8, wall=7402
2022-05-19 23:28:19 - progress_bar.py[line:274] - INFO: epoch 001:    621 / 7081 loss=-0.004, score=1.552, ntokens=889, nsentences=80, sample_size=889, wps=109.5, ups=0.12, wpb=889, bsz=80, num_updates=620, lr=3.65135e-06, gnorm=1.532, clip=90, loss_scale=128, train_wall=81, gb_free=6.8, wall=7483
2022-05-19 23:29:40 - progress_bar.py[line:274] - INFO: epoch 001:    631 / 7081 loss=-0.004, score=1.409, ntokens=896.9, nsentences=80, sample_size=896.9, wps=110.3, ups=0.12, wpb=896.9, bsz=80, num_updates=630, lr=3.71025e-06, gnorm=1.653, clip=90, loss_scale=128, train_wall=81, gb_free=6.8, wall=7565
2022-05-19 23:31:01 - progress_bar.py[line:274] - INFO: epoch 001:    641 / 7081 loss=-0.005, score=1.45, ntokens=892.2, nsentences=80, sample_size=892.2, wps=109.6, ups=0.12, wpb=892.2, bsz=80, num_updates=640, lr=3.76914e-06, gnorm=1.561, clip=60, loss_scale=128, train_wall=81, gb_free=6.7, wall=7646
2022-05-19 23:32:23 - progress_bar.py[line:274] - INFO: epoch 001:    651 / 7081 loss=-0.005, score=1.423, ntokens=889.9, nsentences=80, sample_size=889.9, wps=108.9, ups=0.12, wpb=889.9, bsz=80, num_updates=650, lr=3.82803e-06, gnorm=1.323, clip=70, loss_scale=128, train_wall=82, gb_free=6.8, wall=7728
2022-05-19 23:33:45 - progress_bar.py[line:274] - INFO: epoch 001:    661 / 7081 loss=-0.005, score=1.361, ntokens=884.6, nsentences=80, sample_size=884.6, wps=108.6, ups=0.12, wpb=884.6, bsz=80, num_updates=660, lr=3.88693e-06, gnorm=1.344, clip=100, loss_scale=128, train_wall=81, gb_free=6.8, wall=7809
2022-05-19 23:35:06 - progress_bar.py[line:274] - INFO: epoch 001:    671 / 7081 loss=-0.004, score=1.444, ntokens=886, nsentences=80, sample_size=886, wps=108.8, ups=0.12, wpb=886, bsz=80, num_updates=670, lr=3.94582e-06, gnorm=1.573, clip=80, loss_scale=128, train_wall=81, gb_free=6.8, wall=7891
2022-05-19 23:36:28 - progress_bar.py[line:274] - INFO: epoch 001:    681 / 7081 loss=-0.005, score=1.425, ntokens=894.9, nsentences=80, sample_size=894.9, wps=109.1, ups=0.12, wpb=894.9, bsz=80, num_updates=680, lr=4.00471e-06, gnorm=1.568, clip=90, loss_scale=128, train_wall=82, gb_free=6.8, wall=7973
2022-05-19 23:37:46 - progress_bar.py[line:274] - INFO: epoch 001:    691 / 7081 loss=-0.005, score=1.398, ntokens=890.9, nsentences=80, sample_size=890.9, wps=114.5, ups=0.13, wpb=890.9, bsz=80, num_updates=690, lr=4.0636e-06, gnorm=1.759, clip=70, loss_scale=128, train_wall=78, gb_free=6.8, wall=8051
2022-05-19 23:39:03 - progress_bar.py[line:274] - INFO: epoch 001:    701 / 7081 loss=-0.003, score=1.419, ntokens=890.3, nsentences=80, sample_size=890.3, wps=115.8, ups=0.13, wpb=890.3, bsz=80, num_updates=700, lr=4.1225e-06, gnorm=1.602, clip=80, loss_scale=128, train_wall=77, gb_free=6.8, wall=8127
2022-05-19 23:40:23 - progress_bar.py[line:274] - INFO: epoch 001:    711 / 7081 loss=-0.005, score=1.359, ntokens=897, nsentences=80, sample_size=897, wps=112.1, ups=0.13, wpb=897, bsz=80, num_updates=710, lr=4.18139e-06, gnorm=1.277, clip=80, loss_scale=128, train_wall=80, gb_free=6.8, wall=8207
2022-05-19 23:41:45 - progress_bar.py[line:274] - INFO: epoch 001:    721 / 7081 loss=-0.002, score=1.39, ntokens=904.1, nsentences=80, sample_size=904.1, wps=110.5, ups=0.12, wpb=904.1, bsz=80, num_updates=720, lr=4.24028e-06, gnorm=1.132, clip=50, loss_scale=128, train_wall=82, gb_free=6.8, wall=8289
2022-05-19 23:43:07 - progress_bar.py[line:274] - INFO: epoch 001:    731 / 7081 loss=-0.004, score=1.359, ntokens=897.2, nsentences=80, sample_size=897.2, wps=109.2, ups=0.12, wpb=897.2, bsz=80, num_updates=730, lr=4.29918e-06, gnorm=1.759, clip=70, loss_scale=128, train_wall=82, gb_free=6.8, wall=8371
2022-05-19 23:44:29 - progress_bar.py[line:274] - INFO: epoch 001:    741 / 7081 loss=-0.005, score=1.382, ntokens=893.6, nsentences=80, sample_size=893.6, wps=108.7, ups=0.12, wpb=893.6, bsz=80, num_updates=740, lr=4.35807e-06, gnorm=1.189, clip=60, loss_scale=128, train_wall=82, gb_free=6.8, wall=8454
2022-05-19 23:45:51 - progress_bar.py[line:274] - INFO: epoch 001:    751 / 7081 loss=-0.005, score=1.53, ntokens=896.8, nsentences=80, sample_size=896.8, wps=109.5, ups=0.12, wpb=896.8, bsz=80, num_updates=750, lr=4.41696e-06, gnorm=1.557, clip=80, loss_scale=128, train_wall=82, gb_free=6.8, wall=8536
2022-05-19 23:47:12 - progress_bar.py[line:274] - INFO: epoch 001:    761 / 7081 loss=-0.005, score=1.488, ntokens=882.8, nsentences=80, sample_size=882.8, wps=108.4, ups=0.12, wpb=882.8, bsz=80, num_updates=760, lr=4.47585e-06, gnorm=1.51, clip=90, loss_scale=128, train_wall=81, gb_free=6.8, wall=8617
2022-05-19 23:48:34 - progress_bar.py[line:274] - INFO: epoch 001:    771 / 7081 loss=-0.005, score=1.354, ntokens=890.6, nsentences=80, sample_size=890.6, wps=108.9, ups=0.12, wpb=890.6, bsz=80, num_updates=770, lr=4.53475e-06, gnorm=1.435, clip=90, loss_scale=128, train_wall=82, gb_free=6.8, wall=8699
2022-05-19 23:49:55 - progress_bar.py[line:274] - INFO: epoch 001:    781 / 7081 loss=-0.007, score=1.378, ntokens=885.6, nsentences=80, sample_size=885.6, wps=109.3, ups=0.12, wpb=885.6, bsz=80, num_updates=780, lr=4.59364e-06, gnorm=1.578, clip=70, loss_scale=128, train_wall=81, gb_free=6.8, wall=8780
2022-05-19 23:51:17 - progress_bar.py[line:274] - INFO: epoch 001:    791 / 7081 loss=-0.008, score=1.433, ntokens=881.3, nsentences=80, sample_size=881.3, wps=107.7, ups=0.12, wpb=881.3, bsz=80, num_updates=790, lr=4.65253e-06, gnorm=1.584, clip=80, loss_scale=128, train_wall=82, gb_free=6.7, wall=8862
2022-05-19 23:52:38 - progress_bar.py[line:274] - INFO: epoch 001:    801 / 7081 loss=-0.004, score=1.374, ntokens=881.3, nsentences=80, sample_size=881.3, wps=109, ups=0.12, wpb=881.3, bsz=80, num_updates=800, lr=4.71143e-06, gnorm=1.742, clip=60, loss_scale=128, train_wall=81, gb_free=6.8, wall=8942
2022-05-19 23:53:59 - progress_bar.py[line:274] - INFO: epoch 001:    811 / 7081 loss=-0.005, score=1.388, ntokens=881, nsentences=80, sample_size=881, wps=108.5, ups=0.12, wpb=881, bsz=80, num_updates=810, lr=4.77032e-06, gnorm=1.62, clip=90, loss_scale=128, train_wall=81, gb_free=6.8, wall=9024
2022-05-19 23:55:20 - progress_bar.py[line:274] - INFO: epoch 001:    821 / 7081 loss=-0.005, score=1.475, ntokens=883.9, nsentences=80, sample_size=883.9, wps=109.2, ups=0.12, wpb=883.9, bsz=80, num_updates=820, lr=4.82921e-06, gnorm=1.78, clip=80, loss_scale=128, train_wall=81, gb_free=6.8, wall=9105
2022-05-19 23:56:41 - progress_bar.py[line:274] - INFO: epoch 001:    831 / 7081 loss=-0.005, score=1.435, ntokens=885.8, nsentences=80, sample_size=885.8, wps=109.2, ups=0.12, wpb=885.8, bsz=80, num_updates=830, lr=4.8881e-06, gnorm=1.328, clip=70, loss_scale=128, train_wall=81, gb_free=6.8, wall=9186
2022-05-19 23:58:03 - progress_bar.py[line:274] - INFO: epoch 001:    841 / 7081 loss=-0.009, score=1.567, ntokens=898.7, nsentences=80, sample_size=898.7, wps=109.4, ups=0.12, wpb=898.7, bsz=80, num_updates=840, lr=4.947e-06, gnorm=1.38, clip=80, loss_scale=128, train_wall=82, gb_free=6.7, wall=9268
2022-05-19 23:59:25 - progress_bar.py[line:274] - INFO: epoch 001:    851 / 7081 loss=-0.003, score=1.393, ntokens=884.4, nsentences=80, sample_size=884.4, wps=107.5, ups=0.12, wpb=884.4, bsz=80, num_updates=850, lr=4.99964e-06, gnorm=1.398, clip=100, loss_scale=128, train_wall=82, gb_free=6.8, wall=9350
2022-05-20 00:00:47 - progress_bar.py[line:274] - INFO: epoch 001:    861 / 7081 loss=-0.004, score=1.393, ntokens=890.3, nsentences=80, sample_size=890.3, wps=109.1, ups=0.12, wpb=890.3, bsz=80, num_updates=860, lr=4.99603e-06, gnorm=1.894, clip=90, loss_scale=128, train_wall=82, gb_free=6.8, wall=9432
2022-05-20 00:02:09 - progress_bar.py[line:274] - INFO: epoch 001:    871 / 7081 loss=-0.006, score=1.492, ntokens=892.1, nsentences=80, sample_size=892.1, wps=108.5, ups=0.12, wpb=892.1, bsz=80, num_updates=870, lr=4.99243e-06, gnorm=1.779, clip=80, loss_scale=128, train_wall=82, gb_free=6.7, wall=9514
2022-05-20 00:03:29 - progress_bar.py[line:274] - INFO: epoch 001:    881 / 7081 loss=-0.004, score=1.423, ntokens=872.1, nsentences=80, sample_size=872.1, wps=109.8, ups=0.13, wpb=872.1, bsz=80, num_updates=880, lr=4.98882e-06, gnorm=1.641, clip=80, loss_scale=128, train_wall=79, gb_free=6.8, wall=9593
2022-05-20 00:04:46 - progress_bar.py[line:274] - INFO: epoch 001:    891 / 7081 loss=-0.003, score=1.418, ntokens=885.2, nsentences=80, sample_size=885.2, wps=115.2, ups=0.13, wpb=885.2, bsz=80, num_updates=890, lr=4.98522e-06, gnorm=1.943, clip=70, loss_scale=128, train_wall=77, gb_free=6.8, wall=9670
2022-05-20 00:06:03 - progress_bar.py[line:274] - INFO: epoch 001:    901 / 7081 loss=-0.005, score=1.345, ntokens=878, nsentences=80, sample_size=878, wps=112.9, ups=0.13, wpb=878, bsz=80, num_updates=900, lr=4.98161e-06, gnorm=1.341, clip=70, loss_scale=128, train_wall=78, gb_free=6.8, wall=9748
2022-05-20 00:07:24 - progress_bar.py[line:274] - INFO: epoch 001:    911 / 7081 loss=-0.008, score=1.454, ntokens=873.1, nsentences=80, sample_size=873.1, wps=107.8, ups=0.12, wpb=873.1, bsz=80, num_updates=910, lr=4.97801e-06, gnorm=1.761, clip=70, loss_scale=128, train_wall=81, gb_free=6.8, wall=9829
2022-05-20 00:08:45 - progress_bar.py[line:274] - INFO: epoch 001:    921 / 7081 loss=-0.006, score=1.46, ntokens=874.6, nsentences=80, sample_size=874.6, wps=108.7, ups=0.12, wpb=874.6, bsz=80, num_updates=920, lr=4.9744e-06, gnorm=1.51, clip=80, loss_scale=128, train_wall=80, gb_free=6.7, wall=9909
2022-05-20 00:10:06 - progress_bar.py[line:274] - INFO: epoch 001:    931 / 7081 loss=-0.003, score=1.413, ntokens=870.4, nsentences=80, sample_size=870.4, wps=107.5, ups=0.12, wpb=870.4, bsz=80, num_updates=930, lr=4.9708e-06, gnorm=1.223, clip=70, loss_scale=128, train_wall=81, gb_free=6.8, wall=9990
2022-05-20 00:11:27 - progress_bar.py[line:274] - INFO: epoch 001:    941 / 7081 loss=-0.005, score=1.412, ntokens=887.5, nsentences=80, sample_size=887.5, wps=108.8, ups=0.12, wpb=887.5, bsz=80, num_updates=940, lr=4.96719e-06, gnorm=1.815, clip=100, loss_scale=128, train_wall=81, gb_free=6.8, wall=10072
2022-05-20 00:12:48 - trainer.py[line:922] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-05-20 00:12:56 - progress_bar.py[line:274] - INFO: epoch 001:    952 / 7081 loss=-0.006, score=1.438, ntokens=864.9, nsentences=80, sample_size=864.9, wps=98, ups=0.11, wpb=864.9, bsz=80, num_updates=950, lr=4.96358e-06, gnorm=1.531, clip=80, loss_scale=64, train_wall=88, gb_free=6.8, wall=10160
2022-05-20 00:14:16 - progress_bar.py[line:274] - INFO: epoch 001:    962 / 7081 loss=-0.005, score=1.39, ntokens=879.9, nsentences=80, sample_size=879.9, wps=109.5, ups=0.12, wpb=879.9, bsz=80, num_updates=960, lr=4.95998e-06, gnorm=1.779, clip=100, loss_scale=64, train_wall=80, gb_free=6.7, wall=10241
2022-05-20 00:15:37 - progress_bar.py[line:274] - INFO: epoch 001:    972 / 7081 loss=-0.005, score=1.581, ntokens=879.6, nsentences=80, sample_size=879.6, wps=108.6, ups=0.12, wpb=879.6, bsz=80, num_updates=970, lr=4.95637e-06, gnorm=1.161, clip=70, loss_scale=64, train_wall=81, gb_free=6.8, wall=10322
2022-05-20 00:16:59 - progress_bar.py[line:274] - INFO: epoch 001:    982 / 7081 loss=-0.003, score=1.37, ntokens=881.3, nsentences=80, sample_size=881.3, wps=107.9, ups=0.12, wpb=881.3, bsz=80, num_updates=980, lr=4.95277e-06, gnorm=1.426, clip=70, loss_scale=64, train_wall=82, gb_free=6.8, wall=10403
2022-05-20 00:18:20 - progress_bar.py[line:274] - INFO: epoch 001:    992 / 7081 loss=-0.004, score=1.432, ntokens=886.9, nsentences=80, sample_size=886.9, wps=109.5, ups=0.12, wpb=886.9, bsz=80, num_updates=990, lr=4.94916e-06, gnorm=1.355, clip=90, loss_scale=64, train_wall=81, gb_free=6.8, wall=10484
2022-05-20 00:19:41 - progress_bar.py[line:274] - INFO: epoch 001:   1002 / 7081 loss=-0.008, score=1.48, ntokens=881.4, nsentences=80, sample_size=881.4, wps=108.4, ups=0.12, wpb=881.4, bsz=80, num_updates=1000, lr=4.94556e-06, gnorm=1.644, clip=90, loss_scale=64, train_wall=81, gb_free=6.8, wall=10566
2022-05-20 00:19:41 - train.py[line:436] - INFO: begin validation on "valid" subset
slice_id 0 seek offset 0
slice_id 1 seek offset 2500
slice_id 0 seek offset 0
slice_id 1 seek offset 2500
2022-05-20 00:59:43 - progress_bar.py[line:282] - INFO: epoch 001 | valid on 'valid' subset | loss -0.004 | score 1.283 | ntokens 110.076 | nsentences 10 | sample_size 110.076 | cider 1.374 | wps 114.6 | wpb 110.1 | bsz 10 | num_updates 1000 | best_cider 1.374
2022-05-20 00:59:43 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 1 @ 1000 updates
2022-05-20 00:59:43 - trainer.py[line:431] - INFO: Saving checkpoint to /database/jhkim/stage2_checkpoints//5e-6_2/checkpoint_1_1000.pt
2022-05-20 00:59:51 - trainer.py[line:441] - INFO: Finished saving checkpoint to /database/jhkim/stage2_checkpoints//5e-6_2/checkpoint_1_1000.pt
2022-05-20 01:01:42 - checkpoint_utils.py[line:135] - INFO: Saved checkpoint /database/jhkim/stage2_checkpoints//5e-6_2/checkpoint_1_1000.pt (epoch 1 @ 1000 updates, score 1.374) (writing took 119.27064813300967 seconds)
2022-05-20 01:03:02 - progress_bar.py[line:274] - INFO: epoch 001:   1012 / 7081 loss=-0.006, score=1.431, ntokens=877.1, nsentences=80, sample_size=877.1, wps=3.4, ups=0, wpb=877.1, bsz=80, num_updates=1010, lr=4.94195e-06, gnorm=1.982, clip=100, loss_scale=64, train_wall=80, gb_free=6.8, wall=13167
2022-05-20 01:04:23 - progress_bar.py[line:274] - INFO: epoch 001:   1022 / 7081 loss=-0.007, score=1.491, ntokens=880.5, nsentences=80, sample_size=880.5, wps=108.4, ups=0.12, wpb=880.5, bsz=80, num_updates=1020, lr=4.93835e-06, gnorm=1.947, clip=80, loss_scale=64, train_wall=81, gb_free=6.8, wall=13248
2022-05-20 01:05:45 - progress_bar.py[line:274] - INFO: epoch 001:   1032 / 7081 loss=-0.003, score=1.365, ntokens=889.2, nsentences=80, sample_size=889.2, wps=109.6, ups=0.12, wpb=889.2, bsz=80, num_updates=1030, lr=4.93474e-06, gnorm=2.232, clip=100, loss_scale=64, train_wall=81, gb_free=6.8, wall=13329
2022-05-20 01:07:05 - progress_bar.py[line:274] - INFO: epoch 001:   1042 / 7081 loss=-0.006, score=1.491, ntokens=879.8, nsentences=80, sample_size=879.8, wps=108.8, ups=0.12, wpb=879.8, bsz=80, num_updates=1040, lr=4.93113e-06, gnorm=1.612, clip=90, loss_scale=64, train_wall=81, gb_free=6.8, wall=13410
2022-05-20 01:08:26 - progress_bar.py[line:274] - INFO: epoch 001:   1052 / 7081 loss=-0.007, score=1.394, ntokens=867.8, nsentences=80, sample_size=867.8, wps=107.6, ups=0.12, wpb=867.8, bsz=80, num_updates=1050, lr=4.92753e-06, gnorm=1.882, clip=90, loss_scale=64, train_wall=81, gb_free=6.8, wall=13491
2022-05-20 01:09:47 - progress_bar.py[line:274] - INFO: epoch 001:   1062 / 7081 loss=-0.004, score=1.475, ntokens=884.4, nsentences=80, sample_size=884.4, wps=108.6, ups=0.12, wpb=884.4, bsz=80, num_updates=1060, lr=4.92392e-06, gnorm=1.525, clip=100, loss_scale=64, train_wall=81, gb_free=6.8, wall=13572
2022-05-20 01:11:10 - progress_bar.py[line:274] - INFO: epoch 001:   1072 / 7081 loss=-0.006, score=1.439, ntokens=897, nsentences=80, sample_size=897, wps=108.9, ups=0.12, wpb=897, bsz=80, num_updates=1070, lr=4.92032e-06, gnorm=1.902, clip=70, loss_scale=64, train_wall=82, gb_free=6.8, wall=13655
2022-05-20 01:12:32 - progress_bar.py[line:274] - INFO: epoch 001:   1082 / 7081 loss=-0.007, score=1.392, ntokens=889.6, nsentences=80, sample_size=889.6, wps=108.3, ups=0.12, wpb=889.6, bsz=80, num_updates=1080, lr=4.91671e-06, gnorm=1.754, clip=80, loss_scale=64, train_wall=82, gb_free=6.8, wall=13737
2022-05-20 01:13:53 - progress_bar.py[line:274] - INFO: epoch 001:   1092 / 7081 loss=-0.005, score=1.479, ntokens=867.2, nsentences=80, sample_size=867.2, wps=106.6, ups=0.12, wpb=867.2, bsz=80, num_updates=1090, lr=4.91311e-06, gnorm=1.294, clip=60, loss_scale=64, train_wall=81, gb_free=6.8, wall=13818
2022-05-20 01:15:15 - progress_bar.py[line:274] - INFO: epoch 001:   1102 / 7081 loss=-0.005, score=1.467, ntokens=879.2, nsentences=80, sample_size=879.2, wps=107.9, ups=0.12, wpb=879.2, bsz=80, num_updates=1100, lr=4.9095e-06, gnorm=1.299, clip=80, loss_scale=64, train_wall=81, gb_free=6.8, wall=13900
2022-05-20 01:16:36 - progress_bar.py[line:274] - INFO: epoch 001:   1112 / 7081 loss=-0.007, score=1.475, ntokens=884.1, nsentences=80, sample_size=884.1, wps=108.8, ups=0.12, wpb=884.1, bsz=80, num_updates=1110, lr=4.9059e-06, gnorm=1.611, clip=80, loss_scale=64, train_wall=81, gb_free=6.8, wall=13981
2022-05-20 01:17:57 - progress_bar.py[line:274] - INFO: epoch 001:   1122 / 7081 loss=-0.003, score=1.392, ntokens=885.9, nsentences=80, sample_size=885.9, wps=109, ups=0.12, wpb=885.9, bsz=80, num_updates=1120, lr=4.90229e-06, gnorm=1.832, clip=80, loss_scale=64, train_wall=81, gb_free=6.8, wall=14062
2022-05-20 01:19:18 - progress_bar.py[line:274] - INFO: epoch 001:   1132 / 7081 loss=-0.004, score=1.524, ntokens=877.1, nsentences=80, sample_size=877.1, wps=108.5, ups=0.12, wpb=877.1, bsz=80, num_updates=1130, lr=4.89869e-06, gnorm=1.578, clip=80, loss_scale=64, train_wall=81, gb_free=6.7, wall=14143
2022-05-20 01:20:39 - progress_bar.py[line:274] - INFO: epoch 001:   1142 / 7081 loss=-0.003, score=1.431, ntokens=882.3, nsentences=80, sample_size=882.3, wps=108.7, ups=0.12, wpb=882.3, bsz=80, num_updates=1140, lr=4.89508e-06, gnorm=1.787, clip=70, loss_scale=64, train_wall=81, gb_free=6.8, wall=14224
2022-05-20 01:21:59 - progress_bar.py[line:274] - INFO: epoch 001:   1152 / 7081 loss=-0.006, score=1.522, ntokens=887.1, nsentences=80, sample_size=887.1, wps=110.7, ups=0.12, wpb=887.1, bsz=80, num_updates=1150, lr=4.89147e-06, gnorm=1.862, clip=90, loss_scale=64, train_wall=80, gb_free=6.8, wall=14304
2022-05-20 01:23:16 - progress_bar.py[line:274] - INFO: epoch 001:   1162 / 7081 loss=-0.003, score=1.451, ntokens=888.5, nsentences=80, sample_size=888.5, wps=115.5, ups=0.13, wpb=888.5, bsz=80, num_updates=1160, lr=4.88787e-06, gnorm=1.293, clip=60, loss_scale=64, train_wall=77, gb_free=6.8, wall=14381
2022-05-20 01:24:34 - progress_bar.py[line:274] - INFO: epoch 001:   1172 / 7081 loss=-0.006, score=1.419, ntokens=892.9, nsentences=80, sample_size=892.9, wps=114.9, ups=0.13, wpb=892.9, bsz=80, num_updates=1170, lr=4.88426e-06, gnorm=1.793, clip=80, loss_scale=64, train_wall=78, gb_free=6.8, wall=14459
2022-05-20 01:25:56 - progress_bar.py[line:274] - INFO: epoch 001:   1182 / 7081 loss=-0.006, score=1.472, ntokens=884.6, nsentences=80, sample_size=884.6, wps=108, ups=0.12, wpb=884.6, bsz=80, num_updates=1180, lr=4.88066e-06, gnorm=1.405, clip=60, loss_scale=64, train_wall=82, gb_free=6.8, wall=14541
2022-05-20 01:27:18 - progress_bar.py[line:274] - INFO: epoch 001:   1192 / 7081 loss=-0.004, score=1.32, ntokens=889, nsentences=80, sample_size=889, wps=108.7, ups=0.12, wpb=889, bsz=80, num_updates=1190, lr=4.87705e-06, gnorm=1.543, clip=50, loss_scale=64, train_wall=82, gb_free=6.8, wall=14622
2022-05-20 01:28:39 - progress_bar.py[line:274] - INFO: epoch 001:   1202 / 7081 loss=-0.006, score=1.413, ntokens=890, nsentences=80, sample_size=890, wps=109.5, ups=0.12, wpb=890, bsz=80, num_updates=1200, lr=4.87345e-06, gnorm=1.593, clip=90, loss_scale=64, train_wall=81, gb_free=6.8, wall=14704
2022-05-20 01:30:00 - progress_bar.py[line:274] - INFO: epoch 001:   1212 / 7081 loss=-0.006, score=1.439, ntokens=876.4, nsentences=80, sample_size=876.4, wps=108, ups=0.12, wpb=876.4, bsz=80, num_updates=1210, lr=4.86984e-06, gnorm=1.657, clip=100, loss_scale=64, train_wall=81, gb_free=6.8, wall=14785
2022-05-20 01:31:21 - progress_bar.py[line:274] - INFO: epoch 001:   1222 / 7081 loss=-0.007, score=1.54, ntokens=881.7, nsentences=80, sample_size=881.7, wps=109, ups=0.12, wpb=881.7, bsz=80, num_updates=1220, lr=4.86624e-06, gnorm=1.423, clip=70, loss_scale=64, train_wall=81, gb_free=6.8, wall=14866
2022-05-20 01:32:42 - progress_bar.py[line:274] - INFO: epoch 001:   1232 / 7081 loss=-0.005, score=1.521, ntokens=875.7, nsentences=80, sample_size=875.7, wps=108, ups=0.12, wpb=875.7, bsz=80, num_updates=1230, lr=4.86263e-06, gnorm=2.956, clip=90, loss_scale=64, train_wall=81, gb_free=6.8, wall=14947
2022-05-20 01:34:04 - progress_bar.py[line:274] - INFO: epoch 001:   1242 / 7081 loss=-0.003, score=1.284, ntokens=894.1, nsentences=80, sample_size=894.1, wps=109.9, ups=0.12, wpb=894.1, bsz=80, num_updates=1240, lr=4.85903e-06, gnorm=1.222, clip=40, loss_scale=64, train_wall=81, gb_free=6.8, wall=15028
2022-05-20 01:35:25 - progress_bar.py[line:274] - INFO: epoch 001:   1252 / 7081 loss=-0.006, score=1.408, ntokens=884.9, nsentences=80, sample_size=884.9, wps=108.6, ups=0.12, wpb=884.9, bsz=80, num_updates=1250, lr=4.85542e-06, gnorm=1.244, clip=60, loss_scale=64, train_wall=81, gb_free=6.8, wall=15110
2022-05-20 01:36:47 - progress_bar.py[line:274] - INFO: epoch 001:   1262 / 7081 loss=-0.005, score=1.501, ntokens=910.2, nsentences=80, sample_size=910.2, wps=111.3, ups=0.12, wpb=910.2, bsz=80, num_updates=1260, lr=4.85181e-06, gnorm=1.457, clip=70, loss_scale=64, train_wall=82, gb_free=6.8, wall=15192
2022-05-20 01:38:08 - progress_bar.py[line:274] - INFO: epoch 001:   1272 / 7081 loss=-0.008, score=1.414, ntokens=886.7, nsentences=80, sample_size=886.7, wps=109, ups=0.12, wpb=886.7, bsz=80, num_updates=1270, lr=4.84821e-06, gnorm=1.562, clip=70, loss_scale=64, train_wall=81, gb_free=6.8, wall=15273
2022-05-20 01:39:30 - progress_bar.py[line:274] - INFO: epoch 001:   1282 / 7081 loss=-0.006, score=1.564, ntokens=890.4, nsentences=80, sample_size=890.4, wps=108.6, ups=0.12, wpb=890.4, bsz=80, num_updates=1280, lr=4.8446e-06, gnorm=1.377, clip=80, loss_scale=64, train_wall=82, gb_free=6.8, wall=15355
2022-05-20 01:40:52 - progress_bar.py[line:274] - INFO: epoch 001:   1292 / 7081 loss=-0.006, score=1.405, ntokens=881.2, nsentences=80, sample_size=881.2, wps=108.4, ups=0.12, wpb=881.2, bsz=80, num_updates=1290, lr=4.841e-06, gnorm=1.39, clip=90, loss_scale=64, train_wall=81, gb_free=6.8, wall=15436
2022-05-20 01:42:12 - progress_bar.py[line:274] - INFO: epoch 001:   1302 / 7081 loss=-0.008, score=1.48, ntokens=872.6, nsentences=80, sample_size=872.6, wps=108, ups=0.12, wpb=872.6, bsz=80, num_updates=1300, lr=4.83739e-06, gnorm=1.598, clip=90, loss_scale=64, train_wall=81, gb_free=6.7, wall=15517
2022-05-20 01:43:35 - progress_bar.py[line:274] - INFO: epoch 001:   1312 / 7081 loss=-0.005, score=1.337, ntokens=891.8, nsentences=80, sample_size=891.8, wps=108.6, ups=0.12, wpb=891.8, bsz=80, num_updates=1310, lr=4.83379e-06, gnorm=1.042, clip=60, loss_scale=64, train_wall=82, gb_free=6.8, wall=15599
2022-05-20 01:44:56 - progress_bar.py[line:274] - INFO: epoch 001:   1322 / 7081 loss=-0.005, score=1.281, ntokens=894.8, nsentences=80, sample_size=894.8, wps=110.2, ups=0.12, wpb=894.8, bsz=80, num_updates=1320, lr=4.83018e-06, gnorm=1.534, clip=90, loss_scale=64, train_wall=81, gb_free=6.8, wall=15680
2022-05-20 01:46:17 - progress_bar.py[line:274] - INFO: epoch 001:   1332 / 7081 loss=-0.003, score=1.375, ntokens=891.3, nsentences=80, sample_size=891.3, wps=109.5, ups=0.12, wpb=891.3, bsz=80, num_updates=1330, lr=4.82658e-06, gnorm=1.615, clip=80, loss_scale=64, train_wall=81, gb_free=6.8, wall=15762
2022-05-20 01:47:39 - progress_bar.py[line:274] - INFO: epoch 001:   1342 / 7081 loss=-0.003, score=1.405, ntokens=887.4, nsentences=80, sample_size=887.4, wps=108.9, ups=0.12, wpb=887.4, bsz=80, num_updates=1340, lr=4.82297e-06, gnorm=1.751, clip=90, loss_scale=64, train_wall=81, gb_free=6.8, wall=15843
2022-05-20 01:48:56 - progress_bar.py[line:274] - INFO: epoch 001:   1352 / 7081 loss=-0.008, score=1.408, ntokens=882.7, nsentences=80, sample_size=882.7, wps=114.6, ups=0.13, wpb=882.7, bsz=80, num_updates=1350, lr=4.81936e-06, gnorm=1.56, clip=100, loss_scale=64, train_wall=77, gb_free=6.8, wall=15920
2022-05-20 01:50:12 - progress_bar.py[line:274] - INFO: epoch 001:   1362 / 7081 loss=-0.008, score=1.482, ntokens=885.2, nsentences=80, sample_size=885.2, wps=115.6, ups=0.13, wpb=885.2, bsz=80, num_updates=1360, lr=4.81576e-06, gnorm=1.196, clip=70, loss_scale=64, train_wall=76, gb_free=6.8, wall=15997
2022-05-20 01:51:31 - progress_bar.py[line:274] - INFO: epoch 001:   1372 / 7081 loss=-0.008, score=1.388, ntokens=894.6, nsentences=80, sample_size=894.6, wps=112.9, ups=0.13, wpb=894.6, bsz=80, num_updates=1370, lr=4.81215e-06, gnorm=1.503, clip=90, loss_scale=64, train_wall=79, gb_free=6.8, wall=16076
2022-05-20 01:52:53 - progress_bar.py[line:274] - INFO: epoch 001:   1382 / 7081 loss=-0.008, score=1.518, ntokens=881.1, nsentences=80, sample_size=881.1, wps=108.3, ups=0.12, wpb=881.1, bsz=80, num_updates=1380, lr=4.80855e-06, gnorm=1.834, clip=100, loss_scale=64, train_wall=81, gb_free=6.8, wall=16157
2022-05-20 01:54:14 - progress_bar.py[line:274] - INFO: epoch 001:   1392 / 7081 loss=-0.005, score=1.391, ntokens=884.1, nsentences=80, sample_size=884.1, wps=108.6, ups=0.12, wpb=884.1, bsz=80, num_updates=1390, lr=4.80494e-06, gnorm=1.551, clip=50, loss_scale=64, train_wall=81, gb_free=6.8, wall=16239
2022-05-20 01:55:36 - progress_bar.py[line:274] - INFO: epoch 001:   1402 / 7081 loss=-0.006, score=1.453, ntokens=887.8, nsentences=80, sample_size=887.8, wps=108.3, ups=0.12, wpb=887.8, bsz=80, num_updates=1400, lr=4.80134e-06, gnorm=1.77, clip=80, loss_scale=64, train_wall=82, gb_free=6.8, wall=16321
2022-05-20 01:56:58 - progress_bar.py[line:274] - INFO: epoch 001:   1412 / 7081 loss=-0.006, score=1.387, ntokens=888.3, nsentences=80, sample_size=888.3, wps=109.1, ups=0.12, wpb=888.3, bsz=80, num_updates=1410, lr=4.79773e-06, gnorm=1.425, clip=90, loss_scale=64, train_wall=81, gb_free=6.7, wall=16402
2022-05-20 01:58:18 - progress_bar.py[line:274] - INFO: epoch 001:   1422 / 7081 loss=-0.006, score=1.585, ntokens=878.5, nsentences=80, sample_size=878.5, wps=108.5, ups=0.12, wpb=878.5, bsz=80, num_updates=1420, lr=4.79413e-06, gnorm=1.449, clip=80, loss_scale=64, train_wall=81, gb_free=6.8, wall=16483
2022-05-20 01:59:39 - progress_bar.py[line:274] - INFO: epoch 001:   1432 / 7081 loss=-0.004, score=1.483, ntokens=874.1, nsentences=80, sample_size=874.1, wps=107.9, ups=0.12, wpb=874.1, bsz=80, num_updates=1430, lr=4.79052e-06, gnorm=1.332, clip=90, loss_scale=64, train_wall=81, gb_free=6.8, wall=16564
2022-05-20 02:01:00 - progress_bar.py[line:274] - INFO: epoch 001:   1442 / 7081 loss=-0.003, score=1.439, ntokens=874.8, nsentences=80, sample_size=874.8, wps=108.7, ups=0.12, wpb=874.8, bsz=80, num_updates=1440, lr=4.78692e-06, gnorm=1.51, clip=80, loss_scale=64, train_wall=80, gb_free=6.8, wall=16645
2022-05-20 02:02:21 - progress_bar.py[line:274] - INFO: epoch 001:   1452 / 7081 loss=-0.006, score=1.541, ntokens=893.2, nsentences=80, sample_size=893.2, wps=109.7, ups=0.12, wpb=893.2, bsz=80, num_updates=1450, lr=4.78331e-06, gnorm=1.769, clip=70, loss_scale=64, train_wall=81, gb_free=6.8, wall=16726
2022-05-20 02:03:42 - progress_bar.py[line:274] - INFO: epoch 001:   1462 / 7081 loss=-0.006, score=1.443, ntokens=884, nsentences=80, sample_size=884, wps=109, ups=0.12, wpb=884, bsz=80, num_updates=1460, lr=4.7797e-06, gnorm=1.572, clip=90, loss_scale=64, train_wall=81, gb_free=6.8, wall=16807
2022-05-20 02:05:03 - progress_bar.py[line:274] - INFO: epoch 001:   1472 / 7081 loss=-0.007, score=1.411, ntokens=882.3, nsentences=80, sample_size=882.3, wps=109, ups=0.12, wpb=882.3, bsz=80, num_updates=1470, lr=4.7761e-06, gnorm=1.688, clip=80, loss_scale=128, train_wall=81, gb_free=6.8, wall=16888
2022-05-20 02:06:26 - progress_bar.py[line:274] - INFO: epoch 001:   1482 / 7081 loss=-0.004, score=1.529, ntokens=899.5, nsentences=80, sample_size=899.5, wps=109.2, ups=0.12, wpb=899.5, bsz=80, num_updates=1480, lr=4.77249e-06, gnorm=1.646, clip=70, loss_scale=128, train_wall=82, gb_free=6.7, wall=16970
2022-05-20 02:07:47 - progress_bar.py[line:274] - INFO: epoch 001:   1492 / 7081 loss=-0.003, score=1.363, ntokens=884.4, nsentences=80, sample_size=884.4, wps=109.1, ups=0.12, wpb=884.4, bsz=80, num_updates=1490, lr=4.76889e-06, gnorm=1.511, clip=80, loss_scale=128, train_wall=81, gb_free=6.8, wall=17052
2022-05-20 02:09:08 - progress_bar.py[line:274] - INFO: epoch 001:   1502 / 7081 loss=-0.007, score=1.545, ntokens=886.1, nsentences=80, sample_size=886.1, wps=109.3, ups=0.12, wpb=886.1, bsz=80, num_updates=1500, lr=4.76528e-06, gnorm=2, clip=90, loss_scale=128, train_wall=81, gb_free=6.8, wall=17133
2022-05-20 02:09:08 - train.py[line:436] - INFO: begin validation on "valid" subset
slice_id 0 seek offset 0
slice_id 0 seek offset 0
slice_id 1 seek offset 2500
slice_id 1 seek offset 2500
2022-05-20 02:49:26 - progress_bar.py[line:282] - INFO: epoch 001 | valid on 'valid' subset | loss -0.004 | score 1.286 | ntokens 111.161 | nsentences 10 | sample_size 111.161 | cider 1.378 | wps 114.9 | wpb 111.2 | bsz 10 | num_updates 1500 | best_cider 1.378
2022-05-20 02:49:26 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 1 @ 1500 updates
2022-05-20 02:49:26 - trainer.py[line:431] - INFO: Saving checkpoint to /database/jhkim/stage2_checkpoints//5e-6_2/checkpoint_1_1500.pt
2022-05-20 02:49:34 - trainer.py[line:441] - INFO: Finished saving checkpoint to /database/jhkim/stage2_checkpoints//5e-6_2/checkpoint_1_1500.pt
2022-05-20 02:51:02 - checkpoint_utils.py[line:135] - INFO: Saved checkpoint /database/jhkim/stage2_checkpoints//5e-6_2/checkpoint_1_1500.pt (epoch 1 @ 1500 updates, score 1.378) (writing took 95.8145576347597 seconds)
2022-05-20 02:52:23 - progress_bar.py[line:274] - INFO: epoch 001:   1512 / 7081 loss=-0.005, score=1.402, ntokens=898.7, nsentences=80, sample_size=898.7, wps=3.5, ups=0, wpb=898.7, bsz=80, num_updates=1510, lr=4.76168e-06, gnorm=1.379, clip=70, loss_scale=128, train_wall=81, gb_free=6.8, wall=19728
2022-05-20 02:53:44 - progress_bar.py[line:274] - INFO: epoch 001:   1522 / 7081 loss=-0.005, score=1.46, ntokens=885.4, nsentences=80, sample_size=885.4, wps=109.1, ups=0.12, wpb=885.4, bsz=80, num_updates=1520, lr=4.75807e-06, gnorm=1.423, clip=70, loss_scale=128, train_wall=81, gb_free=6.8, wall=19809
2022-05-20 02:55:06 - progress_bar.py[line:274] - INFO: epoch 001:   1532 / 7081 loss=-0.006, score=1.422, ntokens=878.5, nsentences=80, sample_size=878.5, wps=108.1, ups=0.12, wpb=878.5, bsz=80, num_updates=1530, lr=4.75447e-06, gnorm=1.551, clip=80, loss_scale=128, train_wall=81, gb_free=6.8, wall=19890
2022-05-20 02:56:27 - progress_bar.py[line:274] - INFO: epoch 001:   1542 / 7081 loss=-0.005, score=1.506, ntokens=894.7, nsentences=80, sample_size=894.7, wps=109.7, ups=0.12, wpb=894.7, bsz=80, num_updates=1540, lr=4.75086e-06, gnorm=1.906, clip=80, loss_scale=128, train_wall=81, gb_free=6.8, wall=19972
2022-05-20 02:57:49 - progress_bar.py[line:274] - INFO: epoch 001:   1552 / 7081 loss=-0.005, score=1.355, ntokens=899.8, nsentences=80, sample_size=899.8, wps=110.4, ups=0.12, wpb=899.8, bsz=80, num_updates=1550, lr=4.74725e-06, gnorm=1.255, clip=70, loss_scale=128, train_wall=81, gb_free=6.8, wall=20053
2022-05-20 02:59:10 - progress_bar.py[line:274] - INFO: epoch 001:   1562 / 7081 loss=-0.003, score=1.412, ntokens=899.6, nsentences=80, sample_size=899.6, wps=109.9, ups=0.12, wpb=899.6, bsz=80, num_updates=1560, lr=4.74365e-06, gnorm=1.453, clip=90, loss_scale=128, train_wall=82, gb_free=6.7, wall=20135
2022-05-20 03:00:32 - progress_bar.py[line:274] - INFO: epoch 001:   1572 / 7081 loss=-0.007, score=1.505, ntokens=889.3, nsentences=80, sample_size=889.3, wps=109.2, ups=0.12, wpb=889.3, bsz=80, num_updates=1570, lr=4.74004e-06, gnorm=1.551, clip=90, loss_scale=128, train_wall=81, gb_free=6.8, wall=20217
2022-05-20 03:01:53 - progress_bar.py[line:274] - INFO: epoch 001:   1582 / 7081 loss=-0.006, score=1.42, ntokens=882.4, nsentences=80, sample_size=882.4, wps=108.2, ups=0.12, wpb=882.4, bsz=80, num_updates=1580, lr=4.73644e-06, gnorm=1.443, clip=100, loss_scale=128, train_wall=81, gb_free=6.8, wall=20298
2022-05-20 03:03:15 - progress_bar.py[line:274] - INFO: epoch 001:   1592 / 7081 loss=-0.008, score=1.43, ntokens=887.5, nsentences=80, sample_size=887.5, wps=108.4, ups=0.12, wpb=887.5, bsz=80, num_updates=1590, lr=4.73283e-06, gnorm=1.774, clip=100, loss_scale=128, train_wall=82, gb_free=6.8, wall=20380
2022-05-20 03:04:36 - progress_bar.py[line:274] - INFO: epoch 001:   1602 / 7081 loss=-0.007, score=1.405, ntokens=882.5, nsentences=80, sample_size=882.5, wps=108.8, ups=0.12, wpb=882.5, bsz=80, num_updates=1600, lr=4.72923e-06, gnorm=1.814, clip=90, loss_scale=128, train_wall=81, gb_free=6.8, wall=20461
2022-05-20 03:05:58 - progress_bar.py[line:274] - INFO: epoch 001:   1612 / 7081 loss=-0.006, score=1.431, ntokens=866.2, nsentences=80, sample_size=866.2, wps=106.8, ups=0.12, wpb=866.2, bsz=80, num_updates=1610, lr=4.72562e-06, gnorm=1.931, clip=100, loss_scale=128, train_wall=81, gb_free=6.8, wall=20542
2022-05-20 03:07:18 - progress_bar.py[line:274] - INFO: epoch 001:   1622 / 7081 loss=-0.005, score=1.463, ntokens=863.7, nsentences=80, sample_size=863.7, wps=107.1, ups=0.12, wpb=863.7, bsz=80, num_updates=1620, lr=4.72202e-06, gnorm=1.912, clip=90, loss_scale=128, train_wall=81, gb_free=6.8, wall=20623
2022-05-20 03:08:35 - progress_bar.py[line:274] - INFO: epoch 001:   1632 / 7081 loss=-0.005, score=1.442, ntokens=888.7, nsentences=80, sample_size=888.7, wps=115.8, ups=0.13, wpb=888.7, bsz=80, num_updates=1630, lr=4.71841e-06, gnorm=1.386, clip=80, loss_scale=128, train_wall=77, gb_free=6.8, wall=20700
2022-05-20 03:09:52 - progress_bar.py[line:274] - INFO: epoch 001:   1642 / 7081 loss=-0.005, score=1.398, ntokens=891.5, nsentences=80, sample_size=891.5, wps=116.1, ups=0.13, wpb=891.5, bsz=80, num_updates=1640, lr=4.71481e-06, gnorm=1.704, clip=90, loss_scale=128, train_wall=77, gb_free=6.8, wall=20776
2022-05-20 03:10:47 - trainer.py[line:922] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-05-20 03:11:20 - progress_bar.py[line:274] - INFO: epoch 001:   1653 / 7081 loss=-0.003, score=1.463, ntokens=885.5, nsentences=80, sample_size=885.5, wps=99.9, ups=0.11, wpb=885.5, bsz=80, num_updates=1650, lr=4.7112e-06, gnorm=2.287, clip=100, loss_scale=64, train_wall=89, gb_free=6.8, wall=20865
2022-05-20 03:12:41 - progress_bar.py[line:274] - INFO: epoch 001:   1663 / 7081 loss=-0.006, score=1.473, ntokens=884.2, nsentences=80, sample_size=884.2, wps=109.3, ups=0.12, wpb=884.2, bsz=80, num_updates=1660, lr=4.70759e-06, gnorm=1.62, clip=90, loss_scale=64, train_wall=81, gb_free=6.8, wall=20946
2022-05-20 03:14:03 - progress_bar.py[line:274] - INFO: epoch 001:   1673 / 7081 loss=-0.004, score=1.361, ntokens=899.2, nsentences=80, sample_size=899.2, wps=110.2, ups=0.12, wpb=899.2, bsz=80, num_updates=1670, lr=4.70399e-06, gnorm=1.247, clip=60, loss_scale=64, train_wall=81, gb_free=6.8, wall=21027
2022-05-20 03:15:24 - progress_bar.py[line:274] - INFO: epoch 001:   1683 / 7081 loss=-0.007, score=1.523, ntokens=883.8, nsentences=80, sample_size=883.8, wps=108.7, ups=0.12, wpb=883.8, bsz=80, num_updates=1680, lr=4.70038e-06, gnorm=1.848, clip=90, loss_scale=64, train_wall=81, gb_free=6.8, wall=21109
2022-05-20 03:16:45 - progress_bar.py[line:274] - INFO: epoch 001:   1693 / 7081 loss=-0.005, score=1.394, ntokens=887.1, nsentences=80, sample_size=887.1, wps=109, ups=0.12, wpb=887.1, bsz=80, num_updates=1690, lr=4.69678e-06, gnorm=1.647, clip=70, loss_scale=64, train_wall=81, gb_free=6.8, wall=21190
2022-05-20 03:18:07 - progress_bar.py[line:274] - INFO: epoch 001:   1703 / 7081 loss=-0.004, score=1.371, ntokens=889.1, nsentences=80, sample_size=889.1, wps=108.6, ups=0.12, wpb=889.1, bsz=80, num_updates=1700, lr=4.69317e-06, gnorm=1.876, clip=100, loss_scale=64, train_wall=82, gb_free=6.8, wall=21272
2022-05-20 03:19:29 - progress_bar.py[line:274] - INFO: epoch 001:   1713 / 7081 loss=-0.006, score=1.452, ntokens=895.5, nsentences=80, sample_size=895.5, wps=109.7, ups=0.12, wpb=895.5, bsz=80, num_updates=1710, lr=4.68957e-06, gnorm=1.598, clip=90, loss_scale=64, train_wall=82, gb_free=6.8, wall=21354
2022-05-20 03:20:51 - progress_bar.py[line:274] - INFO: epoch 001:   1723 / 7081 loss=-0.004, score=1.433, ntokens=899, nsentences=80, sample_size=899, wps=109.6, ups=0.12, wpb=899, bsz=80, num_updates=1720, lr=4.68596e-06, gnorm=1.604, clip=80, loss_scale=64, train_wall=82, gb_free=6.8, wall=21436
2022-05-20 03:22:13 - progress_bar.py[line:274] - INFO: epoch 001:   1733 / 7081 loss=-0.002, score=1.449, ntokens=902.3, nsentences=80, sample_size=902.3, wps=110.4, ups=0.12, wpb=902.3, bsz=80, num_updates=1730, lr=4.68236e-06, gnorm=1.61, clip=90, loss_scale=64, train_wall=82, gb_free=6.8, wall=21517
2022-05-20 03:23:34 - progress_bar.py[line:274] - INFO: epoch 001:   1743 / 7081 loss=-0.004, score=1.445, ntokens=894.3, nsentences=80, sample_size=894.3, wps=109.4, ups=0.12, wpb=894.3, bsz=80, num_updates=1740, lr=4.67875e-06, gnorm=1.562, clip=90, loss_scale=64, train_wall=82, gb_free=6.8, wall=21599
2022-05-20 03:24:56 - progress_bar.py[line:274] - INFO: epoch 001:   1753 / 7081 loss=-0.008, score=1.516, ntokens=881.9, nsentences=80, sample_size=881.9, wps=108.1, ups=0.12, wpb=881.9, bsz=80, num_updates=1750, lr=4.67514e-06, gnorm=1.568, clip=80, loss_scale=64, train_wall=81, gb_free=6.8, wall=21681
2022-05-20 03:26:17 - progress_bar.py[line:274] - INFO: epoch 001:   1763 / 7081 loss=-0.002, score=1.528, ntokens=888.2, nsentences=80, sample_size=888.2, wps=109.2, ups=0.12, wpb=888.2, bsz=80, num_updates=1760, lr=4.67154e-06, gnorm=1.555, clip=80, loss_scale=64, train_wall=81, gb_free=6.8, wall=21762
2022-05-20 03:27:39 - progress_bar.py[line:274] - INFO: epoch 001:   1773 / 7081 loss=-0.006, score=1.427, ntokens=899.8, nsentences=80, sample_size=899.8, wps=109.6, ups=0.12, wpb=899.8, bsz=80, num_updates=1770, lr=4.66793e-06, gnorm=1.456, clip=100, loss_scale=64, train_wall=82, gb_free=6.8, wall=21844
2022-05-20 03:29:01 - progress_bar.py[line:274] - INFO: epoch 001:   1783 / 7081 loss=-0.005, score=1.337, ntokens=883.4, nsentences=80, sample_size=883.4, wps=107.8, ups=0.12, wpb=883.4, bsz=80, num_updates=1780, lr=4.66433e-06, gnorm=1.749, clip=90, loss_scale=64, train_wall=82, gb_free=6.8, wall=21926
2022-05-20 03:30:22 - progress_bar.py[line:274] - INFO: epoch 001:   1793 / 7081 loss=-0.008, score=1.433, ntokens=895.8, nsentences=80, sample_size=895.8, wps=110.6, ups=0.12, wpb=895.8, bsz=80, num_updates=1790, lr=4.66072e-06, gnorm=1.57, clip=90, loss_scale=64, train_wall=81, gb_free=6.8, wall=22007
2022-05-20 03:31:45 - progress_bar.py[line:274] - INFO: epoch 001:   1803 / 7081 loss=-0.002, score=1.433, ntokens=898, nsentences=80, sample_size=898, wps=108.9, ups=0.12, wpb=898, bsz=80, num_updates=1800, lr=4.65712e-06, gnorm=1.346, clip=80, loss_scale=64, train_wall=82, gb_free=6.8, wall=22090
2022-05-20 03:33:07 - progress_bar.py[line:274] - INFO: epoch 001:   1813 / 7081 loss=-0.005, score=1.397, ntokens=897.3, nsentences=80, sample_size=897.3, wps=110, ups=0.12, wpb=897.3, bsz=80, num_updates=1810, lr=4.65351e-06, gnorm=1.469, clip=90, loss_scale=64, train_wall=82, gb_free=6.7, wall=22171
2022-05-20 03:34:25 - progress_bar.py[line:274] - INFO: epoch 001:   1823 / 7081 loss=-0.006, score=1.37, ntokens=874.8, nsentences=80, sample_size=874.8, wps=111.9, ups=0.13, wpb=874.8, bsz=80, num_updates=1820, lr=4.64991e-06, gnorm=1.831, clip=90, loss_scale=64, train_wall=78, gb_free=6.8, wall=22249
2022-05-20 03:35:42 - progress_bar.py[line:274] - INFO: epoch 001:   1833 / 7081 loss=-0.007, score=1.329, ntokens=886.9, nsentences=80, sample_size=886.9, wps=115, ups=0.13, wpb=886.9, bsz=80, num_updates=1830, lr=4.6463e-06, gnorm=1.545, clip=80, loss_scale=64, train_wall=77, gb_free=6.7, wall=22327
2022-05-20 03:37:00 - progress_bar.py[line:274] - INFO: epoch 001:   1843 / 7081 loss=-0.01, score=1.54, ntokens=880.5, nsentences=80, sample_size=880.5, wps=112.3, ups=0.13, wpb=880.5, bsz=80, num_updates=1840, lr=4.6427e-06, gnorm=1.996, clip=100, loss_scale=64, train_wall=78, gb_free=6.8, wall=22405
2022-05-20 03:38:22 - progress_bar.py[line:274] - INFO: epoch 001:   1853 / 7081 loss=-0.005, score=1.468, ntokens=906.7, nsentences=80, sample_size=906.7, wps=110.3, ups=0.12, wpb=906.7, bsz=80, num_updates=1850, lr=4.63909e-06, gnorm=1.341, clip=80, loss_scale=64, train_wall=82, gb_free=6.8, wall=22487
2022-05-20 03:39:44 - progress_bar.py[line:274] - INFO: epoch 001:   1863 / 7081 loss=-0.008, score=1.538, ntokens=882, nsentences=80, sample_size=882, wps=107.9, ups=0.12, wpb=882, bsz=80, num_updates=1860, lr=4.63548e-06, gnorm=1.482, clip=80, loss_scale=64, train_wall=82, gb_free=6.8, wall=22569
2022-05-20 03:41:05 - progress_bar.py[line:274] - INFO: epoch 001:   1873 / 7081 loss=-0.008, score=1.429, ntokens=880.2, nsentences=80, sample_size=880.2, wps=108.4, ups=0.12, wpb=880.2, bsz=80, num_updates=1870, lr=4.63188e-06, gnorm=1.665, clip=60, loss_scale=64, train_wall=81, gb_free=6.8, wall=22650
2022-05-20 03:42:27 - progress_bar.py[line:274] - INFO: epoch 001:   1883 / 7081 loss=-0.007, score=1.492, ntokens=900.8, nsentences=80, sample_size=900.8, wps=110.1, ups=0.12, wpb=900.8, bsz=80, num_updates=1880, lr=4.62827e-06, gnorm=1.378, clip=100, loss_scale=64, train_wall=82, gb_free=6.8, wall=22732
2022-05-20 03:43:48 - progress_bar.py[line:274] - INFO: epoch 001:   1893 / 7081 loss=-0.004, score=1.379, ntokens=878.7, nsentences=80, sample_size=878.7, wps=108.1, ups=0.12, wpb=878.7, bsz=80, num_updates=1890, lr=4.62467e-06, gnorm=1.533, clip=80, loss_scale=64, train_wall=81, gb_free=6.8, wall=22813
2022-05-20 03:45:10 - progress_bar.py[line:274] - INFO: epoch 001:   1903 / 7081 loss=-0.005, score=1.401, ntokens=892.4, nsentences=80, sample_size=892.4, wps=109.2, ups=0.12, wpb=892.4, bsz=80, num_updates=1900, lr=4.62106e-06, gnorm=1.403, clip=80, loss_scale=64, train_wall=82, gb_free=6.8, wall=22895
2022-05-20 03:46:31 - progress_bar.py[line:274] - INFO: epoch 001:   1913 / 7081 loss=-0.003, score=1.446, ntokens=880.3, nsentences=80, sample_size=880.3, wps=108.6, ups=0.12, wpb=880.3, bsz=80, num_updates=1910, lr=4.61746e-06, gnorm=1.691, clip=80, loss_scale=64, train_wall=81, gb_free=6.8, wall=22976
2022-05-20 03:47:52 - progress_bar.py[line:274] - INFO: epoch 001:   1923 / 7081 loss=-0.006, score=1.427, ntokens=874.9, nsentences=80, sample_size=874.9, wps=108.3, ups=0.12, wpb=874.9, bsz=80, num_updates=1920, lr=4.61385e-06, gnorm=1.829, clip=100, loss_scale=64, train_wall=81, gb_free=6.8, wall=23057
2022-05-20 03:49:14 - progress_bar.py[line:274] - INFO: epoch 001:   1933 / 7081 loss=-0.007, score=1.461, ntokens=887.4, nsentences=80, sample_size=887.4, wps=108.5, ups=0.12, wpb=887.4, bsz=80, num_updates=1930, lr=4.61025e-06, gnorm=1.848, clip=70, loss_scale=64, train_wall=82, gb_free=6.8, wall=23138
2022-05-20 03:50:35 - progress_bar.py[line:274] - INFO: epoch 001:   1943 / 7081 loss=-0.005, score=1.399, ntokens=885.5, nsentences=80, sample_size=885.5, wps=108.5, ups=0.12, wpb=885.5, bsz=80, num_updates=1940, lr=4.60664e-06, gnorm=1.984, clip=100, loss_scale=64, train_wall=82, gb_free=6.7, wall=23220
2022-05-20 03:51:57 - progress_bar.py[line:274] - INFO: epoch 001:   1953 / 7081 loss=-0.005, score=1.436, ntokens=895.3, nsentences=80, sample_size=895.3, wps=110.3, ups=0.12, wpb=895.3, bsz=80, num_updates=1950, lr=4.60303e-06, gnorm=1.411, clip=70, loss_scale=64, train_wall=81, gb_free=6.8, wall=23301
2022-05-20 03:53:18 - progress_bar.py[line:274] - INFO: epoch 001:   1963 / 7081 loss=-0.008, score=1.346, ntokens=897.3, nsentences=80, sample_size=897.3, wps=109.9, ups=0.12, wpb=897.3, bsz=80, num_updates=1960, lr=4.59943e-06, gnorm=1.959, clip=100, loss_scale=64, train_wall=82, gb_free=6.8, wall=23383
2022-05-20 03:54:40 - progress_bar.py[line:274] - INFO: epoch 001:   1973 / 7081 loss=-0.006, score=1.397, ntokens=901.2, nsentences=80, sample_size=901.2, wps=109.6, ups=0.12, wpb=901.2, bsz=80, num_updates=1970, lr=4.59582e-06, gnorm=1.596, clip=80, loss_scale=64, train_wall=82, gb_free=6.8, wall=23465
2022-05-20 03:56:02 - progress_bar.py[line:274] - INFO: epoch 001:   1983 / 7081 loss=-0.005, score=1.537, ntokens=883.8, nsentences=80, sample_size=883.8, wps=108.4, ups=0.12, wpb=883.8, bsz=80, num_updates=1980, lr=4.59222e-06, gnorm=1.473, clip=80, loss_scale=64, train_wall=81, gb_free=6.8, wall=23547
2022-05-20 03:57:24 - progress_bar.py[line:274] - INFO: epoch 001:   1993 / 7081 loss=-0.005, score=1.542, ntokens=892, nsentences=80, sample_size=892, wps=109.3, ups=0.12, wpb=892, bsz=80, num_updates=1990, lr=4.58861e-06, gnorm=1.437, clip=90, loss_scale=64, train_wall=82, gb_free=6.8, wall=23628
2022-05-20 03:58:45 - progress_bar.py[line:274] - INFO: epoch 001:   2003 / 7081 loss=-0.005, score=1.475, ntokens=874.3, nsentences=80, sample_size=874.3, wps=107.8, ups=0.12, wpb=874.3, bsz=80, num_updates=2000, lr=4.58501e-06, gnorm=1.698, clip=80, loss_scale=64, train_wall=81, gb_free=6.8, wall=23709
slice_id 1 seek offset 2500
2022-05-20 03:58:45 - train.py[line:436] - INFO: begin validation on "valid" subset
slice_id 0 seek offset 0
slice_id 0 seek offset 0
slice_id 1 seek offset 2500
2022-05-20 04:39:13 - progress_bar.py[line:282] - INFO: epoch 001 | valid on 'valid' subset | loss -0.005 | score 1.288 | ntokens 111.686 | nsentences 10 | sample_size 111.686 | cider 1.378 | wps 115 | wpb 111.7 | bsz 10 | num_updates 2000 | best_cider 1.378
2022-05-20 04:39:13 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 1 @ 2000 updates
2022-05-20 04:39:13 - trainer.py[line:431] - INFO: Saving checkpoint to /database/jhkim/stage2_checkpoints//5e-6_2/checkpoint_1_2000.pt
2022-05-20 04:39:21 - trainer.py[line:441] - INFO: Finished saving checkpoint to /database/jhkim/stage2_checkpoints//5e-6_2/checkpoint_1_2000.pt
2022-05-20 04:41:03 - checkpoint_utils.py[line:135] - INFO: Saved checkpoint /database/jhkim/stage2_checkpoints//5e-6_2/checkpoint_1_2000.pt (epoch 1 @ 2000 updates, score 1.378) (writing took 110.90262685203925 seconds)
2022-05-20 04:42:24 - progress_bar.py[line:274] - INFO: epoch 001:   2013 / 7081 loss=-0.005, score=1.416, ntokens=889.8, nsentences=80, sample_size=889.8, wps=3.4, ups=0, wpb=889.8, bsz=80, num_updates=2010, lr=4.5814e-06, gnorm=1.308, clip=80, loss_scale=64, train_wall=80, gb_free=6.8, wall=26328
2022-05-20 04:43:45 - progress_bar.py[line:274] - INFO: epoch 001:   2023 / 7081 loss=-0.004, score=1.481, ntokens=903, nsentences=80, sample_size=903, wps=110.5, ups=0.12, wpb=903, bsz=80, num_updates=2020, lr=4.5778e-06, gnorm=1.738, clip=100, loss_scale=64, train_wall=82, gb_free=6.8, wall=26410
2022-05-20 04:45:07 - progress_bar.py[line:274] - INFO: epoch 001:   2033 / 7081 loss=-0.003, score=1.368, ntokens=882.1, nsentences=80, sample_size=882.1, wps=108.3, ups=0.12, wpb=882.1, bsz=80, num_updates=2030, lr=4.57419e-06, gnorm=1.609, clip=100, loss_scale=64, train_wall=81, gb_free=6.8, wall=26491
2022-05-20 04:46:29 - progress_bar.py[line:274] - INFO: epoch 001:   2043 / 7081 loss=-0.006, score=1.416, ntokens=890.2, nsentences=80, sample_size=890.2, wps=108.8, ups=0.12, wpb=890.2, bsz=80, num_updates=2040, lr=4.57059e-06, gnorm=1.413, clip=80, loss_scale=64, train_wall=82, gb_free=6.8, wall=26573
2022-05-20 04:47:50 - progress_bar.py[line:274] - INFO: epoch 001:   2053 / 7081 loss=-0.005, score=1.431, ntokens=891.4, nsentences=80, sample_size=891.4, wps=109.2, ups=0.12, wpb=891.4, bsz=80, num_updates=2050, lr=4.56698e-06, gnorm=2.039, clip=90, loss_scale=64, train_wall=82, gb_free=6.8, wall=26655
2022-05-20 04:49:13 - progress_bar.py[line:274] - INFO: epoch 001:   2063 / 7081 loss=-0.005, score=1.408, ntokens=908.2, nsentences=80, sample_size=908.2, wps=109.6, ups=0.12, wpb=908.2, bsz=80, num_updates=2060, lr=4.56337e-06, gnorm=1.365, clip=80, loss_scale=64, train_wall=83, gb_free=6.8, wall=26738
2022-05-20 04:50:34 - progress_bar.py[line:274] - INFO: epoch 001:   2073 / 7081 loss=-0.005, score=1.376, ntokens=874.9, nsentences=80, sample_size=874.9, wps=107.6, ups=0.12, wpb=874.9, bsz=80, num_updates=2070, lr=4.55977e-06, gnorm=1.653, clip=80, loss_scale=64, train_wall=81, gb_free=6.8, wall=26819
2022-05-20 04:51:56 - progress_bar.py[line:274] - INFO: epoch 001:   2083 / 7081 loss=-0.005, score=1.441, ntokens=897.8, nsentences=80, sample_size=897.8, wps=109.8, ups=0.12, wpb=897.8, bsz=80, num_updates=2080, lr=4.55616e-06, gnorm=1.551, clip=100, loss_scale=64, train_wall=82, gb_free=6.8, wall=26901
2022-05-20 04:53:15 - progress_bar.py[line:274] - INFO: epoch 001:   2093 / 7081 loss=-0.005, score=1.459, ntokens=881.7, nsentences=80, sample_size=881.7, wps=112.3, ups=0.13, wpb=881.7, bsz=80, num_updates=2090, lr=4.55256e-06, gnorm=2.296, clip=80, loss_scale=64, train_wall=78, gb_free=6.8, wall=26979
2022-05-20 04:54:32 - progress_bar.py[line:274] - INFO: epoch 001:   2103 / 7081 loss=-0.005, score=1.405, ntokens=909.6, nsentences=80, sample_size=909.6, wps=117.3, ups=0.13, wpb=909.6, bsz=80, num_updates=2100, lr=4.54895e-06, gnorm=1.568, clip=70, loss_scale=64, train_wall=77, gb_free=6.8, wall=27057
2022-05-20 04:55:51 - progress_bar.py[line:274] - INFO: epoch 001:   2113 / 7081 loss=-0.006, score=1.44, ntokens=894.8, nsentences=80, sample_size=894.8, wps=113.3, ups=0.13, wpb=894.8, bsz=80, num_updates=2110, lr=4.54535e-06, gnorm=1.625, clip=100, loss_scale=64, train_wall=79, gb_free=6.8, wall=27136
2022-05-20 04:57:13 - progress_bar.py[line:274] - INFO: epoch 001:   2123 / 7081 loss=-0.006, score=1.452, ntokens=886.9, nsentences=80, sample_size=886.9, wps=108.7, ups=0.12, wpb=886.9, bsz=80, num_updates=2120, lr=4.54174e-06, gnorm=2.377, clip=100, loss_scale=64, train_wall=81, gb_free=6.8, wall=27217
2022-05-20 04:58:35 - progress_bar.py[line:274] - INFO: epoch 001:   2133 / 7081 loss=-0.002, score=1.379, ntokens=913.6, nsentences=80, sample_size=913.6, wps=111.4, ups=0.12, wpb=913.6, bsz=80, num_updates=2130, lr=4.53814e-06, gnorm=1.411, clip=90, loss_scale=64, train_wall=82, gb_free=6.8, wall=27299
2022-05-20 04:59:56 - progress_bar.py[line:274] - INFO: epoch 001:   2143 / 7081 loss=-0.008, score=1.443, ntokens=882.2, nsentences=80, sample_size=882.2, wps=108.5, ups=0.12, wpb=882.2, bsz=80, num_updates=2140, lr=4.53453e-06, gnorm=1.441, clip=80, loss_scale=64, train_wall=81, gb_free=6.8, wall=27381
2022-05-20 05:01:18 - progress_bar.py[line:274] - INFO: epoch 001:   2153 / 7081 loss=-0.005, score=1.389, ntokens=890, nsentences=80, sample_size=890, wps=109.2, ups=0.12, wpb=890, bsz=80, num_updates=2150, lr=4.53092e-06, gnorm=1.766, clip=80, loss_scale=64, train_wall=81, gb_free=6.8, wall=27462
2022-05-20 05:02:39 - progress_bar.py[line:274] - INFO: epoch 001:   2163 / 7081 loss=-0.007, score=1.326, ntokens=889.1, nsentences=80, sample_size=889.1, wps=108.7, ups=0.12, wpb=889.1, bsz=80, num_updates=2160, lr=4.52732e-06, gnorm=1.945, clip=80, loss_scale=128, train_wall=82, gb_free=6.7, wall=27544
2022-05-20 05:04:01 - progress_bar.py[line:274] - INFO: epoch 001:   2173 / 7081 loss=-0.006, score=1.583, ntokens=899.6, nsentences=80, sample_size=899.6, wps=110.4, ups=0.12, wpb=899.6, bsz=80, num_updates=2170, lr=4.52371e-06, gnorm=1.482, clip=90, loss_scale=128, train_wall=81, gb_free=6.8, wall=27626
2022-05-20 05:05:22 - progress_bar.py[line:274] - INFO: epoch 001:   2183 / 7081 loss=-0.005, score=1.319, ntokens=886.4, nsentences=80, sample_size=886.4, wps=109.1, ups=0.12, wpb=886.4, bsz=80, num_updates=2180, lr=4.52011e-06, gnorm=1.237, clip=60, loss_scale=128, train_wall=81, gb_free=6.8, wall=27707
2022-05-20 05:06:44 - progress_bar.py[line:274] - INFO: epoch 001:   2193 / 7081 loss=-0.005, score=1.497, ntokens=896.7, nsentences=80, sample_size=896.7, wps=109.4, ups=0.12, wpb=896.7, bsz=80, num_updates=2190, lr=4.5165e-06, gnorm=1.524, clip=70, loss_scale=128, train_wall=82, gb_free=6.7, wall=27789
2022-05-20 05:08:06 - progress_bar.py[line:274] - INFO: epoch 001:   2203 / 7081 loss=-0.004, score=1.5, ntokens=891.2, nsentences=80, sample_size=891.2, wps=108.7, ups=0.12, wpb=891.2, bsz=80, num_updates=2200, lr=4.5129e-06, gnorm=1.547, clip=100, loss_scale=128, train_wall=82, gb_free=6.8, wall=27871
2022-05-20 05:09:28 - progress_bar.py[line:274] - INFO: epoch 001:   2213 / 7081 loss=-0.005, score=1.397, ntokens=896.2, nsentences=80, sample_size=896.2, wps=109.6, ups=0.12, wpb=896.2, bsz=80, num_updates=2210, lr=4.50929e-06, gnorm=1.981, clip=90, loss_scale=128, train_wall=82, gb_free=6.8, wall=27952
2022-05-20 05:10:50 - progress_bar.py[line:274] - INFO: epoch 001:   2223 / 7081 loss=-0.005, score=1.455, ntokens=885.4, nsentences=80, sample_size=885.4, wps=108, ups=0.12, wpb=885.4, bsz=80, num_updates=2220, lr=4.50569e-06, gnorm=1.38, clip=70, loss_scale=128, train_wall=82, gb_free=6.8, wall=28034
2022-05-20 05:12:12 - progress_bar.py[line:274] - INFO: epoch 001:   2233 / 7081 loss=-0.004, score=1.418, ntokens=897, nsentences=80, sample_size=897, wps=109.1, ups=0.12, wpb=897, bsz=80, num_updates=2230, lr=4.50208e-06, gnorm=1.598, clip=70, loss_scale=128, train_wall=82, gb_free=6.8, wall=28117
2022-05-20 05:13:33 - progress_bar.py[line:274] - INFO: epoch 001:   2243 / 7081 loss=-0.006, score=1.415, ntokens=882.4, nsentences=80, sample_size=882.4, wps=108.7, ups=0.12, wpb=882.4, bsz=80, num_updates=2240, lr=4.49848e-06, gnorm=1.655, clip=100, loss_scale=128, train_wall=81, gb_free=6.8, wall=28198
2022-05-20 05:14:55 - progress_bar.py[line:274] - INFO: epoch 001:   2253 / 7081 loss=-0.007, score=1.474, ntokens=893.4, nsentences=80, sample_size=893.4, wps=109.3, ups=0.12, wpb=893.4, bsz=80, num_updates=2250, lr=4.49487e-06, gnorm=1.582, clip=80, loss_scale=128, train_wall=82, gb_free=6.8, wall=28280
2022-05-20 05:16:16 - progress_bar.py[line:274] - INFO: epoch 001:   2263 / 7081 loss=-0.009, score=1.508, ntokens=888.3, nsentences=80, sample_size=888.3, wps=109.3, ups=0.12, wpb=888.3, bsz=80, num_updates=2260, lr=4.49126e-06, gnorm=1.884, clip=80, loss_scale=128, train_wall=81, gb_free=6.8, wall=28361
2022-05-20 05:17:38 - progress_bar.py[line:274] - INFO: epoch 001:   2273 / 7081 loss=-0.002, score=1.39, ntokens=899.7, nsentences=80, sample_size=899.7, wps=109.6, ups=0.12, wpb=899.7, bsz=80, num_updates=2270, lr=4.48766e-06, gnorm=1.279, clip=70, loss_scale=128, train_wall=82, gb_free=6.8, wall=28443
2022-05-20 05:18:59 - progress_bar.py[line:274] - INFO: epoch 001:   2283 / 7081 loss=-0.007, score=1.49, ntokens=885.6, nsentences=80, sample_size=885.6, wps=109.4, ups=0.12, wpb=885.6, bsz=80, num_updates=2280, lr=4.48405e-06, gnorm=1.689, clip=80, loss_scale=128, train_wall=81, gb_free=6.8, wall=28524
2022-05-20 05:20:16 - progress_bar.py[line:274] - INFO: epoch 001:   2293 / 7081 loss=-0.004, score=1.415, ntokens=895.7, nsentences=80, sample_size=895.7, wps=116, ups=0.13, wpb=895.7, bsz=80, num_updates=2290, lr=4.48045e-06, gnorm=1.304, clip=80, loss_scale=128, train_wall=77, gb_free=6.8, wall=28601
2022-05-20 05:21:33 - progress_bar.py[line:274] - INFO: epoch 001:   2303 / 7081 loss=-0.009, score=1.432, ntokens=884.3, nsentences=80, sample_size=884.3, wps=115.6, ups=0.13, wpb=884.3, bsz=80, num_updates=2300, lr=4.47684e-06, gnorm=1.181, clip=60, loss_scale=128, train_wall=76, gb_free=6.8, wall=28678
2022-05-20 05:22:53 - progress_bar.py[line:274] - INFO: epoch 001:   2313 / 7081 loss=-0.008, score=1.4, ntokens=890.8, nsentences=80, sample_size=890.8, wps=110.7, ups=0.12, wpb=890.8, bsz=80, num_updates=2310, lr=4.47324e-06, gnorm=1.616, clip=80, loss_scale=128, train_wall=80, gb_free=6.8, wall=28758
2022-05-20 05:24:14 - progress_bar.py[line:274] - INFO: epoch 001:   2323 / 7081 loss=-0.005, score=1.444, ntokens=877.5, nsentences=80, sample_size=877.5, wps=108.3, ups=0.12, wpb=877.5, bsz=80, num_updates=2320, lr=4.46963e-06, gnorm=1.685, clip=90, loss_scale=128, train_wall=81, gb_free=6.8, wall=28839
2022-05-20 05:25:36 - progress_bar.py[line:274] - INFO: epoch 001:   2333 / 7081 loss=-0.005, score=1.493, ntokens=882.9, nsentences=80, sample_size=882.9, wps=108.7, ups=0.12, wpb=882.9, bsz=80, num_updates=2330, lr=4.46603e-06, gnorm=1.462, clip=90, loss_scale=128, train_wall=81, gb_free=6.8, wall=28920
2022-05-20 05:26:57 - progress_bar.py[line:274] - INFO: epoch 001:   2343 / 7081 loss=-0.003, score=1.487, ntokens=890.9, nsentences=80, sample_size=890.9, wps=109.2, ups=0.12, wpb=890.9, bsz=80, num_updates=2340, lr=4.46242e-06, gnorm=1.883, clip=80, loss_scale=128, train_wall=82, gb_free=6.8, wall=29002
2022-05-20 05:27:30 - trainer.py[line:922] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-05-20 05:28:26 - progress_bar.py[line:274] - INFO: epoch 001:   2354 / 7081 loss=-0.007, score=1.414, ntokens=872.5, nsentences=80, sample_size=872.5, wps=98, ups=0.11, wpb=872.5, bsz=80, num_updates=2350, lr=4.45881e-06, gnorm=1.719, clip=90, loss_scale=64, train_wall=89, gb_free=6.8, wall=29091
2022-05-20 05:29:48 - progress_bar.py[line:274] - INFO: epoch 001:   2364 / 7081 loss=-0.007, score=1.383, ntokens=882.4, nsentences=80, sample_size=882.4, wps=108.3, ups=0.12, wpb=882.4, bsz=80, num_updates=2360, lr=4.45521e-06, gnorm=1.658, clip=90, loss_scale=64, train_wall=81, gb_free=6.8, wall=29172
2022-05-20 05:31:10 - progress_bar.py[line:274] - INFO: epoch 001:   2374 / 7081 loss=-0.003, score=1.39, ntokens=879.4, nsentences=80, sample_size=879.4, wps=107.4, ups=0.12, wpb=879.4, bsz=80, num_updates=2370, lr=4.4516e-06, gnorm=1.626, clip=90, loss_scale=64, train_wall=82, gb_free=6.8, wall=29254
2022-05-20 05:32:31 - progress_bar.py[line:274] - INFO: epoch 001:   2384 / 7081 loss=-0.005, score=1.403, ntokens=884.2, nsentences=80, sample_size=884.2, wps=108.7, ups=0.12, wpb=884.2, bsz=80, num_updates=2380, lr=4.448e-06, gnorm=1.615, clip=100, loss_scale=64, train_wall=81, gb_free=6.7, wall=29336
2022-05-20 05:33:52 - progress_bar.py[line:274] - INFO: epoch 001:   2394 / 7081 loss=-0.003, score=1.46, ntokens=875.3, nsentences=80, sample_size=875.3, wps=108.1, ups=0.12, wpb=875.3, bsz=80, num_updates=2390, lr=4.44439e-06, gnorm=1.765, clip=80, loss_scale=64, train_wall=81, gb_free=6.8, wall=29417
2022-05-20 05:35:13 - progress_bar.py[line:274] - INFO: epoch 001:   2404 / 7081 loss=-0.004, score=1.362, ntokens=878.8, nsentences=80, sample_size=878.8, wps=108.5, ups=0.12, wpb=878.8, bsz=80, num_updates=2400, lr=4.44079e-06, gnorm=1.362, clip=60, loss_scale=64, train_wall=81, gb_free=6.8, wall=29498
2022-05-20 05:36:35 - progress_bar.py[line:274] - INFO: epoch 001:   2414 / 7081 loss=-0.005, score=1.322, ntokens=900.2, nsentences=80, sample_size=900.2, wps=109.7, ups=0.12, wpb=900.2, bsz=80, num_updates=2410, lr=4.43718e-06, gnorm=1.255, clip=70, loss_scale=64, train_wall=82, gb_free=6.7, wall=29580
2022-05-20 05:37:56 - progress_bar.py[line:274] - INFO: epoch 001:   2424 / 7081 loss=-0.008, score=1.464, ntokens=888.3, nsentences=80, sample_size=888.3, wps=109.3, ups=0.12, wpb=888.3, bsz=80, num_updates=2420, lr=4.43358e-06, gnorm=1.5, clip=80, loss_scale=64, train_wall=81, gb_free=6.8, wall=29661
2022-05-20 05:39:18 - progress_bar.py[line:274] - INFO: epoch 001:   2434 / 7081 loss=-0.008, score=1.397, ntokens=904.1, nsentences=80, sample_size=904.1, wps=110.2, ups=0.12, wpb=904.1, bsz=80, num_updates=2430, lr=4.42997e-06, gnorm=1.659, clip=90, loss_scale=64, train_wall=82, gb_free=6.8, wall=29743
2022-05-20 05:40:39 - progress_bar.py[line:274] - INFO: epoch 001:   2444 / 7081 loss=-0.004, score=1.342, ntokens=886.2, nsentences=80, sample_size=886.2, wps=109.6, ups=0.12, wpb=886.2, bsz=80, num_updates=2440, lr=4.42637e-06, gnorm=1.751, clip=90, loss_scale=64, train_wall=81, gb_free=6.8, wall=29824
2022-05-20 05:42:01 - progress_bar.py[line:274] - INFO: epoch 001:   2454 / 7081 loss=-0.003, score=1.412, ntokens=888.5, nsentences=80, sample_size=888.5, wps=109.1, ups=0.12, wpb=888.5, bsz=80, num_updates=2450, lr=4.42276e-06, gnorm=1.23, clip=80, loss_scale=64, train_wall=81, gb_free=6.8, wall=29905
2022-05-20 05:43:22 - progress_bar.py[line:274] - INFO: epoch 001:   2464 / 7081 loss=-0.007, score=1.423, ntokens=874.1, nsentences=80, sample_size=874.1, wps=108, ups=0.12, wpb=874.1, bsz=80, num_updates=2460, lr=4.41915e-06, gnorm=1.622, clip=90, loss_scale=64, train_wall=81, gb_free=6.8, wall=29986
2022-05-20 05:44:43 - progress_bar.py[line:274] - INFO: epoch 001:   2474 / 7081 loss=-0.009, score=1.514, ntokens=893.3, nsentences=80, sample_size=893.3, wps=109.2, ups=0.12, wpb=893.3, bsz=80, num_updates=2470, lr=4.41555e-06, gnorm=1.226, clip=50, loss_scale=64, train_wall=82, gb_free=6.8, wall=30068
2022-05-20 05:46:02 - progress_bar.py[line:274] - INFO: epoch 001:   2484 / 7081 loss=-0.004, score=1.36, ntokens=899, nsentences=80, sample_size=899, wps=114.4, ups=0.13, wpb=899, bsz=80, num_updates=2480, lr=4.41194e-06, gnorm=1.182, clip=80, loss_scale=64, train_wall=79, gb_free=6.8, wall=30147
2022-05-20 05:47:19 - progress_bar.py[line:274] - INFO: epoch 001:   2494 / 7081 loss=-0.005, score=1.437, ntokens=887.3, nsentences=80, sample_size=887.3, wps=115.2, ups=0.13, wpb=887.3, bsz=80, num_updates=2490, lr=4.40834e-06, gnorm=1.879, clip=80, loss_scale=64, train_wall=77, gb_free=6.8, wall=30224
slice_id 1 seek offset 2500
2022-05-20 05:48:38 - progress_bar.py[line:274] - INFO: epoch 001:   2504 / 7081 loss=-0.003, score=1.553, ntokens=882.5, nsentences=80, sample_size=882.5, wps=112.3, ups=0.13, wpb=882.5, bsz=80, num_updates=2500, lr=4.40473e-06, gnorm=1.74, clip=100, loss_scale=64, train_wall=78, gb_free=6.8, wall=30302
2022-05-20 05:48:38 - train.py[line:436] - INFO: begin validation on "valid" subset
slice_id 0 seek offset 0
slice_id 1 seek offset 2500
slice_id 0 seek offset 0
2022-05-20 06:28:57 - progress_bar.py[line:282] - INFO: epoch 001 | valid on 'valid' subset | loss -0.004 | score 1.288 | ntokens 110.867 | nsentences 10 | sample_size 110.867 | cider 1.379 | wps 114.6 | wpb 110.9 | bsz 10 | num_updates 2500 | best_cider 1.379
2022-05-20 06:28:57 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 1 @ 2500 updates
2022-05-20 06:28:57 - trainer.py[line:431] - INFO: Saving checkpoint to /database/jhkim/stage2_checkpoints//5e-6_2/checkpoint_1_2500.pt
2022-05-20 06:29:06 - trainer.py[line:441] - INFO: Finished saving checkpoint to /database/jhkim/stage2_checkpoints//5e-6_2/checkpoint_1_2500.pt
2022-05-20 06:30:28 - checkpoint_utils.py[line:135] - INFO: Saved checkpoint /database/jhkim/stage2_checkpoints//5e-6_2/checkpoint_1_2500.pt (epoch 1 @ 2500 updates, score 1.379) (writing took 90.3563411287032 seconds)
2022-05-20 06:31:49 - progress_bar.py[line:274] - INFO: epoch 001:   2514 / 7081 loss=-0.006, score=1.329, ntokens=895.2, nsentences=80, sample_size=895.2, wps=3.5, ups=0, wpb=895.2, bsz=80, num_updates=2510, lr=4.40113e-06, gnorm=1.312, clip=60, loss_scale=64, train_wall=81, gb_free=6.8, wall=32894
2022-05-20 06:33:10 - progress_bar.py[line:274] - INFO: epoch 001:   2524 / 7081 loss=-0.006, score=1.43, ntokens=883.5, nsentences=80, sample_size=883.5, wps=109.3, ups=0.12, wpb=883.5, bsz=80, num_updates=2520, lr=4.39752e-06, gnorm=1.349, clip=90, loss_scale=64, train_wall=81, gb_free=6.8, wall=32975
2022-05-20 06:34:32 - progress_bar.py[line:274] - INFO: epoch 001:   2534 / 7081 loss=-0.008, score=1.48, ntokens=887.9, nsentences=80, sample_size=887.9, wps=108.9, ups=0.12, wpb=887.9, bsz=80, num_updates=2530, lr=4.39392e-06, gnorm=1.342, clip=80, loss_scale=64, train_wall=81, gb_free=6.8, wall=33056
2022-05-20 06:35:53 - progress_bar.py[line:274] - INFO: epoch 001:   2544 / 7081 loss=-0.004, score=1.435, ntokens=893.3, nsentences=80, sample_size=893.3, wps=109.9, ups=0.12, wpb=893.3, bsz=80, num_updates=2540, lr=4.39031e-06, gnorm=1.422, clip=80, loss_scale=64, train_wall=81, gb_free=6.8, wall=33138
2022-05-20 06:37:14 - progress_bar.py[line:274] - INFO: epoch 001:   2554 / 7081 loss=-0.008, score=1.559, ntokens=888.4, nsentences=80, sample_size=888.4, wps=109.2, ups=0.12, wpb=888.4, bsz=80, num_updates=2550, lr=4.3867e-06, gnorm=1.839, clip=90, loss_scale=64, train_wall=81, gb_free=6.8, wall=33219
2022-05-20 06:38:33 - progress_bar.py[line:274] - INFO: epoch 001:   2564 / 7081 loss=-0.005, score=1.428, ntokens=883.4, nsentences=80, sample_size=883.4, wps=112.9, ups=0.13, wpb=883.4, bsz=80, num_updates=2560, lr=4.3831e-06, gnorm=1.249, clip=80, loss_scale=64, train_wall=78, gb_free=6.8, wall=33297
2022-05-20 06:39:50 - progress_bar.py[line:274] - INFO: epoch 001:   2574 / 7081 loss=-0.004, score=1.369, ntokens=887.5, nsentences=80, sample_size=887.5, wps=115.1, ups=0.13, wpb=887.5, bsz=80, num_updates=2570, lr=4.37949e-06, gnorm=1.329, clip=90, loss_scale=64, train_wall=77, gb_free=6.8, wall=33374
2022-05-20 06:41:09 - progress_bar.py[line:274] - INFO: epoch 001:   2584 / 7081 loss=-0.006, score=1.369, ntokens=888.8, nsentences=80, sample_size=888.8, wps=112.7, ups=0.13, wpb=888.8, bsz=80, num_updates=2580, lr=4.37589e-06, gnorm=1.494, clip=80, loss_scale=64, train_wall=79, gb_free=6.8, wall=33453
2022-05-20 06:42:31 - progress_bar.py[line:274] - INFO: epoch 001:   2594 / 7081 loss=-0.009, score=1.51, ntokens=893, nsentences=80, sample_size=893, wps=108.5, ups=0.12, wpb=893, bsz=80, num_updates=2590, lr=4.37228e-06, gnorm=2.054, clip=70, loss_scale=64, train_wall=82, gb_free=6.8, wall=33536
2022-05-20 06:43:52 - progress_bar.py[line:274] - INFO: epoch 001:   2604 / 7081 loss=-0.002, score=1.527, ntokens=884.5, nsentences=80, sample_size=884.5, wps=108.8, ups=0.12, wpb=884.5, bsz=80, num_updates=2600, lr=4.36868e-06, gnorm=1.496, clip=90, loss_scale=64, train_wall=81, gb_free=6.8, wall=33617
2022-05-20 06:45:14 - progress_bar.py[line:274] - INFO: epoch 001:   2614 / 7081 loss=-0.008, score=1.459, ntokens=881, nsentences=80, sample_size=881, wps=107.8, ups=0.12, wpb=881, bsz=80, num_updates=2610, lr=4.36507e-06, gnorm=2.081, clip=90, loss_scale=64, train_wall=82, gb_free=6.8, wall=33699
2022-05-20 06:46:35 - progress_bar.py[line:274] - INFO: epoch 001:   2624 / 7081 loss=-0.006, score=1.477, ntokens=870.7, nsentences=80, sample_size=870.7, wps=107.5, ups=0.12, wpb=870.7, bsz=80, num_updates=2620, lr=4.36147e-06, gnorm=2.343, clip=80, loss_scale=64, train_wall=81, gb_free=6.8, wall=33780
2022-05-20 06:47:56 - progress_bar.py[line:274] - INFO: epoch 001:   2634 / 7081 loss=-0.003, score=1.511, ntokens=886.3, nsentences=80, sample_size=886.3, wps=109.8, ups=0.12, wpb=886.3, bsz=80, num_updates=2630, lr=4.35786e-06, gnorm=1.376, clip=80, loss_scale=64, train_wall=81, gb_free=6.8, wall=33860
2022-05-20 06:49:17 - progress_bar.py[line:274] - INFO: epoch 001:   2644 / 7081 loss=-0.004, score=1.376, ntokens=894.2, nsentences=80, sample_size=894.2, wps=110, ups=0.12, wpb=894.2, bsz=80, num_updates=2640, lr=4.35426e-06, gnorm=1.37, clip=90, loss_scale=64, train_wall=81, gb_free=6.8, wall=33942
2022-05-20 06:50:38 - progress_bar.py[line:274] - INFO: epoch 001:   2654 / 7081 loss=-0.009, score=1.401, ntokens=887.3, nsentences=80, sample_size=887.3, wps=109.5, ups=0.12, wpb=887.3, bsz=80, num_updates=2650, lr=4.35065e-06, gnorm=1.595, clip=90, loss_scale=64, train_wall=81, gb_free=6.8, wall=34023
2022-05-20 06:51:59 - progress_bar.py[line:274] - INFO: epoch 001:   2664 / 7081 loss=-0.004, score=1.433, ntokens=882.3, nsentences=80, sample_size=882.3, wps=108.7, ups=0.12, wpb=882.3, bsz=80, num_updates=2660, lr=4.34704e-06, gnorm=1.111, clip=70, loss_scale=64, train_wall=81, gb_free=6.8, wall=34104
2022-05-20 06:53:20 - progress_bar.py[line:274] - INFO: epoch 001:   2674 / 7081 loss=-0.005, score=1.438, ntokens=878.8, nsentences=80, sample_size=878.8, wps=108.9, ups=0.12, wpb=878.8, bsz=80, num_updates=2670, lr=4.34344e-06, gnorm=1.472, clip=90, loss_scale=64, train_wall=81, gb_free=6.8, wall=34185
2022-05-20 06:54:41 - progress_bar.py[line:274] - INFO: epoch 001:   2684 / 7081 loss=-0.005, score=1.405, ntokens=888.4, nsentences=80, sample_size=888.4, wps=109.5, ups=0.12, wpb=888.4, bsz=80, num_updates=2680, lr=4.33983e-06, gnorm=1.533, clip=90, loss_scale=64, train_wall=81, gb_free=6.8, wall=34266
2022-05-20 06:56:02 - progress_bar.py[line:274] - INFO: epoch 001:   2694 / 7081 loss=-0.004, score=1.437, ntokens=890.2, nsentences=80, sample_size=890.2, wps=109.6, ups=0.12, wpb=890.2, bsz=80, num_updates=2690, lr=4.33623e-06, gnorm=1.532, clip=80, loss_scale=64, train_wall=81, gb_free=6.8, wall=34347
2022-05-20 06:57:24 - progress_bar.py[line:274] - INFO: epoch 001:   2704 / 7081 loss=-0.005, score=1.496, ntokens=882, nsentences=80, sample_size=882, wps=108.3, ups=0.12, wpb=882, bsz=80, num_updates=2700, lr=4.33262e-06, gnorm=1.414, clip=80, loss_scale=64, train_wall=81, gb_free=6.8, wall=34428
2022-05-20 06:58:45 - progress_bar.py[line:274] - INFO: epoch 001:   2714 / 7081 loss=-0.005, score=1.43, ntokens=902.3, nsentences=80, sample_size=902.3, wps=110.8, ups=0.12, wpb=902.3, bsz=80, num_updates=2710, lr=4.32902e-06, gnorm=1.401, clip=80, loss_scale=64, train_wall=81, gb_free=6.8, wall=34510
2022-05-20 07:00:06 - progress_bar.py[line:274] - INFO: epoch 001:   2724 / 7081 loss=-0.008, score=1.436, ntokens=887.3, nsentences=80, sample_size=887.3, wps=109.3, ups=0.12, wpb=887.3, bsz=80, num_updates=2720, lr=4.32541e-06, gnorm=1.846, clip=80, loss_scale=64, train_wall=81, gb_free=6.8, wall=34591
2022-05-20 07:01:27 - progress_bar.py[line:274] - INFO: epoch 001:   2734 / 7081 loss=-0.006, score=1.529, ntokens=878.8, nsentences=80, sample_size=878.8, wps=108.5, ups=0.12, wpb=878.8, bsz=80, num_updates=2730, lr=4.32181e-06, gnorm=1.64, clip=70, loss_scale=64, train_wall=81, gb_free=6.8, wall=34672
2022-05-20 07:02:49 - progress_bar.py[line:274] - INFO: epoch 001:   2744 / 7081 loss=-0.005, score=1.577, ntokens=885.6, nsentences=80, sample_size=885.6, wps=108.5, ups=0.12, wpb=885.6, bsz=80, num_updates=2740, lr=4.3182e-06, gnorm=1.802, clip=90, loss_scale=64, train_wall=82, gb_free=6.8, wall=34754
2022-05-20 07:04:10 - progress_bar.py[line:274] - INFO: epoch 001:   2754 / 7081 loss=-0.003, score=1.412, ntokens=892.1, nsentences=80, sample_size=892.1, wps=110.6, ups=0.12, wpb=892.1, bsz=80, num_updates=2750, lr=4.31459e-06, gnorm=2.057, clip=90, loss_scale=64, train_wall=81, gb_free=6.8, wall=34834
2022-05-20 07:05:27 - progress_bar.py[line:274] - INFO: epoch 001:   2764 / 7081 loss=-0.006, score=1.38, ntokens=892.4, nsentences=80, sample_size=892.4, wps=115.6, ups=0.13, wpb=892.4, bsz=80, num_updates=2760, lr=4.31099e-06, gnorm=1.616, clip=80, loss_scale=64, train_wall=77, gb_free=6.7, wall=34911
2022-05-20 07:06:43 - progress_bar.py[line:274] - INFO: epoch 001:   2774 / 7081 loss=-0.006, score=1.507, ntokens=882.1, nsentences=80, sample_size=882.1, wps=115, ups=0.13, wpb=882.1, bsz=80, num_updates=2770, lr=4.30738e-06, gnorm=1.886, clip=100, loss_scale=64, train_wall=77, gb_free=6.8, wall=34988
2022-05-20 07:08:05 - progress_bar.py[line:274] - INFO: epoch 001:   2784 / 7081 loss=-0.004, score=1.337, ntokens=895.7, nsentences=80, sample_size=895.7, wps=110.1, ups=0.12, wpb=895.7, bsz=80, num_updates=2780, lr=4.30378e-06, gnorm=1.182, clip=60, loss_scale=64, train_wall=81, gb_free=6.8, wall=35069
2022-05-20 07:09:26 - progress_bar.py[line:274] - INFO: epoch 001:   2794 / 7081 loss=-0.009, score=1.463, ntokens=884.7, nsentences=80, sample_size=884.7, wps=109.2, ups=0.12, wpb=884.7, bsz=80, num_updates=2790, lr=4.30017e-06, gnorm=1.476, clip=90, loss_scale=64, train_wall=81, gb_free=6.8, wall=35151
2022-05-20 07:10:47 - progress_bar.py[line:274] - INFO: epoch 001:   2804 / 7081 loss=-0.005, score=1.434, ntokens=886.8, nsentences=80, sample_size=886.8, wps=108.8, ups=0.12, wpb=886.8, bsz=80, num_updates=2800, lr=4.29657e-06, gnorm=1.652, clip=80, loss_scale=64, train_wall=81, gb_free=6.8, wall=35232
2022-05-20 07:12:09 - progress_bar.py[line:274] - INFO: epoch 001:   2814 / 7081 loss=-0.006, score=1.451, ntokens=893.3, nsentences=80, sample_size=893.3, wps=109.9, ups=0.12, wpb=893.3, bsz=80, num_updates=2810, lr=4.29296e-06, gnorm=1.289, clip=70, loss_scale=64, train_wall=81, gb_free=6.8, wall=35313
2022-05-20 07:13:30 - progress_bar.py[line:274] - INFO: epoch 001:   2824 / 7081 loss=-0.006, score=1.522, ntokens=883.2, nsentences=80, sample_size=883.2, wps=109.2, ups=0.12, wpb=883.2, bsz=80, num_updates=2820, lr=4.28936e-06, gnorm=1.366, clip=80, loss_scale=64, train_wall=81, gb_free=6.8, wall=35394
2022-05-20 07:14:51 - progress_bar.py[line:274] - INFO: epoch 001:   2834 / 7081 loss=-0.005, score=1.324, ntokens=889.1, nsentences=80, sample_size=889.1, wps=108.8, ups=0.12, wpb=889.1, bsz=80, num_updates=2830, lr=4.28575e-06, gnorm=1.568, clip=80, loss_scale=64, train_wall=82, gb_free=6.8, wall=35476
2022-05-20 07:16:13 - progress_bar.py[line:274] - INFO: epoch 001:   2844 / 7081 loss=-0.006, score=1.415, ntokens=882.2, nsentences=80, sample_size=882.2, wps=108.1, ups=0.12, wpb=882.2, bsz=80, num_updates=2840, lr=4.28215e-06, gnorm=1.55, clip=80, loss_scale=64, train_wall=82, gb_free=6.8, wall=35557
2022-05-20 07:17:34 - progress_bar.py[line:274] - INFO: epoch 001:   2854 / 7081 loss=-0.006, score=1.439, ntokens=879.8, nsentences=80, sample_size=879.8, wps=108.3, ups=0.12, wpb=879.8, bsz=80, num_updates=2850, lr=4.27854e-06, gnorm=1.169, clip=80, loss_scale=64, train_wall=81, gb_free=6.8, wall=35639
2022-05-20 07:18:56 - progress_bar.py[line:274] - INFO: epoch 001:   2864 / 7081 loss=-0.004, score=1.382, ntokens=892, nsentences=80, sample_size=892, wps=109.1, ups=0.12, wpb=892, bsz=80, num_updates=2860, lr=4.27493e-06, gnorm=1.633, clip=80, loss_scale=128, train_wall=82, gb_free=6.8, wall=35720
2022-05-20 07:20:18 - progress_bar.py[line:274] - INFO: epoch 001:   2874 / 7081 loss=-0.005, score=1.441, ntokens=900.1, nsentences=80, sample_size=900.1, wps=109.3, ups=0.12, wpb=900.1, bsz=80, num_updates=2870, lr=4.27133e-06, gnorm=1.471, clip=80, loss_scale=128, train_wall=82, gb_free=6.7, wall=35803
2022-05-20 07:21:40 - progress_bar.py[line:274] - INFO: epoch 001:   2884 / 7081 loss=-0.007, score=1.488, ntokens=880.7, nsentences=80, sample_size=880.7, wps=108.2, ups=0.12, wpb=880.7, bsz=80, num_updates=2880, lr=4.26772e-06, gnorm=1.609, clip=90, loss_scale=128, train_wall=81, gb_free=6.8, wall=35884
2022-05-20 07:23:01 - progress_bar.py[line:274] - INFO: epoch 001:   2894 / 7081 loss=-0.007, score=1.583, ntokens=879.4, nsentences=80, sample_size=879.4, wps=108, ups=0.12, wpb=879.4, bsz=80, num_updates=2890, lr=4.26412e-06, gnorm=1.707, clip=100, loss_scale=128, train_wall=81, gb_free=6.8, wall=35966
2022-05-20 07:24:22 - progress_bar.py[line:274] - INFO: epoch 001:   2904 / 7081 loss=-0.007, score=1.447, ntokens=882, nsentences=80, sample_size=882, wps=108.6, ups=0.12, wpb=882, bsz=80, num_updates=2900, lr=4.26051e-06, gnorm=1.587, clip=100, loss_scale=128, train_wall=81, gb_free=6.8, wall=36047
2022-05-20 07:25:44 - progress_bar.py[line:274] - INFO: epoch 001:   2914 / 7081 loss=-0.004, score=1.396, ntokens=885.7, nsentences=80, sample_size=885.7, wps=108.3, ups=0.12, wpb=885.7, bsz=80, num_updates=2910, lr=4.25691e-06, gnorm=1.715, clip=100, loss_scale=128, train_wall=82, gb_free=6.8, wall=36129
2022-05-20 07:27:06 - progress_bar.py[line:274] - INFO: epoch 001:   2924 / 7081 loss=-0.005, score=1.419, ntokens=892.1, nsentences=80, sample_size=892.1, wps=109, ups=0.12, wpb=892.1, bsz=80, num_updates=2920, lr=4.2533e-06, gnorm=1.376, clip=70, loss_scale=128, train_wall=82, gb_free=6.8, wall=36210
2022-05-20 07:28:27 - progress_bar.py[line:274] - INFO: epoch 001:   2934 / 7081 loss=-0.002, score=1.419, ntokens=891.4, nsentences=80, sample_size=891.4, wps=109.4, ups=0.12, wpb=891.4, bsz=80, num_updates=2930, lr=4.2497e-06, gnorm=1.674, clip=90, loss_scale=128, train_wall=81, gb_free=6.8, wall=36292
2022-05-20 07:29:49 - progress_bar.py[line:274] - INFO: epoch 001:   2944 / 7081 loss=-0.004, score=1.444, ntokens=885.7, nsentences=80, sample_size=885.7, wps=108.3, ups=0.12, wpb=885.7, bsz=80, num_updates=2940, lr=4.24609e-06, gnorm=1.39, clip=80, loss_scale=128, train_wall=82, gb_free=6.8, wall=36374
2022-05-20 07:31:08 - progress_bar.py[line:274] - INFO: epoch 001:   2954 / 7081 loss=-0.006, score=1.472, ntokens=889.6, nsentences=80, sample_size=889.6, wps=112.4, ups=0.13, wpb=889.6, bsz=80, num_updates=2950, lr=4.24248e-06, gnorm=1.308, clip=70, loss_scale=128, train_wall=79, gb_free=6.8, wall=36453
2022-05-20 07:32:25 - progress_bar.py[line:274] - INFO: epoch 001:   2964 / 7081 loss=-0.008, score=1.43, ntokens=877.4, nsentences=80, sample_size=877.4, wps=114.3, ups=0.13, wpb=877.4, bsz=80, num_updates=2960, lr=4.23888e-06, gnorm=1.753, clip=90, loss_scale=128, train_wall=77, gb_free=6.8, wall=36530
2022-05-20 07:33:44 - progress_bar.py[line:274] - INFO: epoch 001:   2974 / 7081 loss=-0.007, score=1.486, ntokens=893.3, nsentences=80, sample_size=893.3, wps=113.6, ups=0.13, wpb=893.3, bsz=80, num_updates=2970, lr=4.23527e-06, gnorm=1.474, clip=80, loss_scale=128, train_wall=79, gb_free=6.8, wall=36608
2022-05-20 07:35:05 - progress_bar.py[line:274] - INFO: epoch 001:   2984 / 7081 loss=-0.006, score=1.428, ntokens=887.2, nsentences=80, sample_size=887.2, wps=109, ups=0.12, wpb=887.2, bsz=80, num_updates=2980, lr=4.23167e-06, gnorm=1.619, clip=80, loss_scale=128, train_wall=81, gb_free=6.8, wall=36690
2022-05-20 07:36:27 - progress_bar.py[line:274] - INFO: epoch 001:   2994 / 7081 loss=-0.005, score=1.36, ntokens=886.1, nsentences=80, sample_size=886.1, wps=108.7, ups=0.12, wpb=886.1, bsz=80, num_updates=2990, lr=4.22806e-06, gnorm=1.201, clip=60, loss_scale=128, train_wall=81, gb_free=6.8, wall=36771
2022-05-20 07:37:49 - progress_bar.py[line:274] - INFO: epoch 001:   3004 / 7081 loss=-0.007, score=1.416, ntokens=896.7, nsentences=80, sample_size=896.7, wps=108.9, ups=0.12, wpb=896.7, bsz=80, num_updates=3000, lr=4.22446e-06, gnorm=1.897, clip=90, loss_scale=128, train_wall=82, gb_free=6.8, wall=36854
slice_id 1 seek offset 2500
2022-05-20 07:37:49 - train.py[line:436] - INFO: begin validation on "valid" subset
slice_id 0 seek offset 0
slice_id 1 seek offset 2500
slice_id 0 seek offset 0
2022-05-20 08:18:05 - progress_bar.py[line:282] - INFO: epoch 001 | valid on 'valid' subset | loss -0.005 | score 1.289 | ntokens 110.509 | nsentences 10 | sample_size 110.509 | cider 1.377 | wps 114.3 | wpb 110.5 | bsz 10 | num_updates 3000 | best_cider 1.379
2022-05-20 08:18:05 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 1 @ 3000 updates
2022-05-20 08:18:05 - trainer.py[line:431] - INFO: Saving checkpoint to /database/jhkim/stage2_checkpoints//5e-6_2/checkpoint_1_3000.pt
2022-05-20 08:18:14 - trainer.py[line:441] - INFO: Finished saving checkpoint to /database/jhkim/stage2_checkpoints//5e-6_2/checkpoint_1_3000.pt
2022-05-20 08:18:46 - checkpoint_utils.py[line:135] - INFO: Saved checkpoint /database/jhkim/stage2_checkpoints//5e-6_2/checkpoint_1_3000.pt (epoch 1 @ 3000 updates, score 1.377) (writing took 41.15888113854453 seconds)
2022-05-20 08:20:07 - progress_bar.py[line:274] - INFO: epoch 001:   3014 / 7081 loss=-0.003, score=1.412, ntokens=884.6, nsentences=80, sample_size=884.6, wps=3.5, ups=0, wpb=884.6, bsz=80, num_updates=3010, lr=4.22085e-06, gnorm=1.293, clip=80, loss_scale=128, train_wall=81, gb_free=6.8, wall=39392
2022-05-20 08:21:28 - progress_bar.py[line:274] - INFO: epoch 001:   3024 / 7081 loss=-0.009, score=1.448, ntokens=875.8, nsentences=80, sample_size=875.8, wps=107.7, ups=0.12, wpb=875.8, bsz=80, num_updates=3020, lr=4.21725e-06, gnorm=1.298, clip=60, loss_scale=128, train_wall=81, gb_free=6.8, wall=39473
2022-05-20 08:22:50 - progress_bar.py[line:274] - INFO: epoch 001:   3034 / 7081 loss=-0.007, score=1.423, ntokens=874.7, nsentences=80, sample_size=874.7, wps=107.7, ups=0.12, wpb=874.7, bsz=80, num_updates=3030, lr=4.21364e-06, gnorm=1.587, clip=70, loss_scale=128, train_wall=81, gb_free=6.8, wall=39554
2022-05-20 08:24:07 - progress_bar.py[line:274] - INFO: epoch 001:   3044 / 7081 loss=-0.003, score=1.426, ntokens=880.6, nsentences=80, sample_size=880.6, wps=114.2, ups=0.13, wpb=880.6, bsz=80, num_updates=3040, lr=4.21004e-06, gnorm=1.257, clip=60, loss_scale=128, train_wall=77, gb_free=6.8, wall=39631
2022-05-20 08:25:24 - progress_bar.py[line:274] - INFO: epoch 001:   3054 / 7081 loss=-0.005, score=1.551, ntokens=875.9, nsentences=80, sample_size=875.9, wps=114, ups=0.13, wpb=875.9, bsz=80, num_updates=3050, lr=4.20643e-06, gnorm=1.311, clip=70, loss_scale=128, train_wall=77, gb_free=6.8, wall=39708
2022-05-20 08:26:44 - progress_bar.py[line:274] - INFO: epoch 001:   3064 / 7081 loss=-0.006, score=1.475, ntokens=882.4, nsentences=80, sample_size=882.4, wps=109.5, ups=0.12, wpb=882.4, bsz=80, num_updates=3060, lr=4.20282e-06, gnorm=1.565, clip=90, loss_scale=128, train_wall=80, gb_free=6.8, wall=39789
2022-05-20 08:28:06 - progress_bar.py[line:274] - INFO: epoch 001:   3074 / 7081 loss=-0.006, score=1.36, ntokens=880.4, nsentences=80, sample_size=880.4, wps=107.5, ups=0.12, wpb=880.4, bsz=80, num_updates=3070, lr=4.19922e-06, gnorm=1.574, clip=80, loss_scale=128, train_wall=82, gb_free=6.8, wall=39871
2022-05-20 08:28:38 - trainer.py[line:922] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-05-20 08:29:35 - progress_bar.py[line:274] - INFO: epoch 001:   3085 / 7081 loss=-0.007, score=1.496, ntokens=884.9, nsentences=80, sample_size=884.9, wps=99.2, ups=0.11, wpb=884.9, bsz=80, num_updates=3080, lr=4.19561e-06, gnorm=1.569, clip=80, loss_scale=64, train_wall=89, gb_free=6.8, wall=39960
2022-05-20 08:30:57 - progress_bar.py[line:274] - INFO: epoch 001:   3095 / 7081 loss=-0.006, score=1.457, ntokens=870.5, nsentences=80, sample_size=870.5, wps=107.1, ups=0.12, wpb=870.5, bsz=80, num_updates=3090, lr=4.19201e-06, gnorm=1.605, clip=80, loss_scale=64, train_wall=81, gb_free=6.8, wall=40041
2022-05-20 08:32:18 - progress_bar.py[line:274] - INFO: epoch 001:   3105 / 7081 loss=-0.006, score=1.531, ntokens=879.2, nsentences=80, sample_size=879.2, wps=108, ups=0.12, wpb=879.2, bsz=80, num_updates=3100, lr=4.1884e-06, gnorm=1.59, clip=80, loss_scale=64, train_wall=81, gb_free=6.8, wall=40123
2022-05-20 08:33:39 - progress_bar.py[line:274] - INFO: epoch 001:   3115 / 7081 loss=-0.003, score=1.379, ntokens=884, nsentences=80, sample_size=884, wps=109.2, ups=0.12, wpb=884, bsz=80, num_updates=3110, lr=4.1848e-06, gnorm=1.071, clip=50, loss_scale=64, train_wall=81, gb_free=6.8, wall=40204
2022-05-20 08:35:00 - progress_bar.py[line:274] - INFO: epoch 001:   3125 / 7081 loss=-0.008, score=1.436, ntokens=875.4, nsentences=80, sample_size=875.4, wps=107.9, ups=0.12, wpb=875.4, bsz=80, num_updates=3120, lr=4.18119e-06, gnorm=1.433, clip=80, loss_scale=64, train_wall=81, gb_free=6.8, wall=40285
2022-05-20 08:36:21 - progress_bar.py[line:274] - INFO: epoch 001:   3135 / 7081 loss=-0.001, score=1.305, ntokens=890.1, nsentences=80, sample_size=890.1, wps=109.5, ups=0.12, wpb=890.1, bsz=80, num_updates=3130, lr=4.17759e-06, gnorm=1.252, clip=80, loss_scale=64, train_wall=81, gb_free=6.8, wall=40366
2022-05-20 08:37:43 - progress_bar.py[line:274] - INFO: epoch 001:   3145 / 7081 loss=-0.007, score=1.391, ntokens=876.9, nsentences=80, sample_size=876.9, wps=107.9, ups=0.12, wpb=876.9, bsz=80, num_updates=3140, lr=4.17398e-06, gnorm=1.888, clip=100, loss_scale=64, train_wall=81, gb_free=6.8, wall=40447
2022-05-20 08:39:04 - progress_bar.py[line:274] - INFO: epoch 001:   3155 / 7081 loss=-0.008, score=1.48, ntokens=882.2, nsentences=80, sample_size=882.2, wps=108.8, ups=0.12, wpb=882.2, bsz=80, num_updates=3150, lr=4.17037e-06, gnorm=1.496, clip=90, loss_scale=64, train_wall=81, gb_free=6.8, wall=40528
2022-05-20 08:40:25 - progress_bar.py[line:274] - INFO: epoch 001:   3165 / 7081 loss=-0.004, score=1.505, ntokens=874.1, nsentences=80, sample_size=874.1, wps=107.7, ups=0.12, wpb=874.1, bsz=80, num_updates=3160, lr=4.16677e-06, gnorm=1.544, clip=70, loss_scale=64, train_wall=81, gb_free=6.8, wall=40609
2022-05-20 08:41:46 - progress_bar.py[line:274] - INFO: epoch 001:   3175 / 7081 loss=-0.006, score=1.443, ntokens=872.7, nsentences=80, sample_size=872.7, wps=107.4, ups=0.12, wpb=872.7, bsz=80, num_updates=3170, lr=4.16316e-06, gnorm=1.201, clip=60, loss_scale=64, train_wall=81, gb_free=6.8, wall=40691
2022-05-20 08:43:07 - progress_bar.py[line:274] - INFO: epoch 001:   3185 / 7081 loss=-0.005, score=1.567, ntokens=880.6, nsentences=80, sample_size=880.6, wps=108.6, ups=0.12, wpb=880.6, bsz=80, num_updates=3180, lr=4.15956e-06, gnorm=1.329, clip=70, loss_scale=64, train_wall=81, gb_free=6.8, wall=40772
2022-05-20 08:44:28 - progress_bar.py[line:274] - INFO: epoch 001:   3195 / 7081 loss=-0.005, score=1.512, ntokens=858.1, nsentences=80, sample_size=858.1, wps=106.5, ups=0.12, wpb=858.1, bsz=80, num_updates=3190, lr=4.15595e-06, gnorm=1.261, clip=70, loss_scale=64, train_wall=81, gb_free=6.8, wall=40852
2022-05-20 08:45:49 - progress_bar.py[line:274] - INFO: epoch 001:   3205 / 7081 loss=-0.008, score=1.467, ntokens=887, nsentences=80, sample_size=887, wps=108.9, ups=0.12, wpb=887, bsz=80, num_updates=3200, lr=4.15235e-06, gnorm=1.34, clip=70, loss_scale=64, train_wall=81, gb_free=6.8, wall=40934
2022-05-20 08:47:11 - progress_bar.py[line:274] - INFO: epoch 001:   3215 / 7081 loss=-0.006, score=1.427, ntokens=873.8, nsentences=80, sample_size=873.8, wps=107.2, ups=0.12, wpb=873.8, bsz=80, num_updates=3210, lr=4.14874e-06, gnorm=1.436, clip=80, loss_scale=64, train_wall=81, gb_free=6.8, wall=41015
2022-05-20 08:48:32 - progress_bar.py[line:274] - INFO: epoch 001:   3225 / 7081 loss=-0.006, score=1.543, ntokens=873.1, nsentences=80, sample_size=873.1, wps=107.9, ups=0.12, wpb=873.1, bsz=80, num_updates=3220, lr=4.14514e-06, gnorm=1.647, clip=100, loss_scale=64, train_wall=81, gb_free=6.8, wall=41096
2022-05-20 08:49:51 - progress_bar.py[line:274] - INFO: epoch 001:   3235 / 7081 loss=-0.006, score=1.551, ntokens=870.6, nsentences=80, sample_size=870.6, wps=109.9, ups=0.13, wpb=870.6, bsz=80, num_updates=3230, lr=4.14153e-06, gnorm=1.561, clip=100, loss_scale=64, train_wall=79, gb_free=6.8, wall=41175
2022-05-20 08:51:07 - progress_bar.py[line:274] - INFO: epoch 001:   3245 / 7081 loss=-0.005, score=1.391, ntokens=872.1, nsentences=80, sample_size=872.1, wps=114, ups=0.13, wpb=872.1, bsz=80, num_updates=3240, lr=4.13793e-06, gnorm=1.482, clip=90, loss_scale=64, train_wall=76, gb_free=6.8, wall=41252
2022-05-20 08:52:26 - progress_bar.py[line:274] - INFO: epoch 001:   3255 / 7081 loss=-0.006, score=1.489, ntokens=890.3, nsentences=80, sample_size=890.3, wps=113, ups=0.13, wpb=890.3, bsz=80, num_updates=3250, lr=4.13432e-06, gnorm=1.394, clip=80, loss_scale=64, train_wall=79, gb_free=6.8, wall=41331
2022-05-20 08:53:47 - progress_bar.py[line:274] - INFO: epoch 001:   3265 / 7081 loss=-0.007, score=1.421, ntokens=871.6, nsentences=80, sample_size=871.6, wps=107.6, ups=0.12, wpb=871.6, bsz=80, num_updates=3260, lr=4.13071e-06, gnorm=1.779, clip=100, loss_scale=64, train_wall=81, gb_free=6.8, wall=41412
2022-05-20 08:55:08 - progress_bar.py[line:274] - INFO: epoch 001:   3275 / 7081 loss=-0.005, score=1.437, ntokens=879.6, nsentences=80, sample_size=879.6, wps=108.1, ups=0.12, wpb=879.6, bsz=80, num_updates=3270, lr=4.12711e-06, gnorm=1.403, clip=80, loss_scale=64, train_wall=81, gb_free=6.8, wall=41493
2022-05-20 08:56:30 - progress_bar.py[line:274] - INFO: epoch 001:   3285 / 7081 loss=-0.005, score=1.478, ntokens=870, nsentences=80, sample_size=870, wps=107.1, ups=0.12, wpb=870, bsz=80, num_updates=3280, lr=4.1235e-06, gnorm=1.781, clip=100, loss_scale=64, train_wall=81, gb_free=6.8, wall=41574
2022-05-20 08:57:51 - progress_bar.py[line:274] - INFO: epoch 001:   3295 / 7081 loss=-0.004, score=1.427, ntokens=869.8, nsentences=80, sample_size=869.8, wps=107.4, ups=0.12, wpb=869.8, bsz=80, num_updates=3290, lr=4.1199e-06, gnorm=1.969, clip=80, loss_scale=64, train_wall=81, gb_free=6.8, wall=41655
2022-05-20 08:59:12 - progress_bar.py[line:274] - INFO: epoch 001:   3305 / 7081 loss=-0.004, score=1.505, ntokens=884.5, nsentences=80, sample_size=884.5, wps=108.9, ups=0.12, wpb=884.5, bsz=80, num_updates=3300, lr=4.11629e-06, gnorm=1.709, clip=70, loss_scale=64, train_wall=81, gb_free=6.8, wall=41737
2022-05-20 09:00:34 - progress_bar.py[line:274] - INFO: epoch 001:   3315 / 7081 loss=-0.006, score=1.527, ntokens=890.6, nsentences=80, sample_size=890.6, wps=108.9, ups=0.12, wpb=890.6, bsz=80, num_updates=3310, lr=4.11269e-06, gnorm=1.943, clip=70, loss_scale=64, train_wall=82, gb_free=6.8, wall=41818
2022-05-20 09:01:55 - progress_bar.py[line:274] - INFO: epoch 001:   3325 / 7081 loss=-0.005, score=1.369, ntokens=878.4, nsentences=80, sample_size=878.4, wps=108, ups=0.12, wpb=878.4, bsz=80, num_updates=3320, lr=4.10908e-06, gnorm=2.083, clip=100, loss_scale=64, train_wall=81, gb_free=6.8, wall=41900
2022-05-20 09:03:16 - progress_bar.py[line:274] - INFO: epoch 001:   3335 / 7081 loss=-0.003, score=1.355, ntokens=878.2, nsentences=80, sample_size=878.2, wps=108.5, ups=0.12, wpb=878.2, bsz=80, num_updates=3330, lr=4.10548e-06, gnorm=1.502, clip=80, loss_scale=64, train_wall=81, gb_free=6.7, wall=41981
2022-05-20 09:04:37 - progress_bar.py[line:274] - INFO: epoch 001:   3345 / 7081 loss=-0.005, score=1.42, ntokens=887, nsentences=80, sample_size=887, wps=108.9, ups=0.12, wpb=887, bsz=80, num_updates=3340, lr=4.10187e-06, gnorm=1.608, clip=70, loss_scale=64, train_wall=81, gb_free=6.8, wall=42062
2022-05-20 09:05:59 - progress_bar.py[line:274] - INFO: epoch 001:   3355 / 7081 loss=-0.004, score=1.494, ntokens=888.6, nsentences=80, sample_size=888.6, wps=109.4, ups=0.12, wpb=888.6, bsz=80, num_updates=3350, lr=4.09826e-06, gnorm=1.225, clip=90, loss_scale=64, train_wall=81, gb_free=6.8, wall=42143
2022-05-20 09:07:20 - progress_bar.py[line:274] - INFO: epoch 001:   3365 / 7081 loss=-0.004, score=1.443, ntokens=879.9, nsentences=80, sample_size=879.9, wps=108.2, ups=0.12, wpb=879.9, bsz=80, num_updates=3360, lr=4.09466e-06, gnorm=1.557, clip=90, loss_scale=64, train_wall=81, gb_free=6.8, wall=42225
2022-05-20 09:08:41 - progress_bar.py[line:274] - INFO: epoch 001:   3375 / 7081 loss=-0.007, score=1.446, ntokens=881.9, nsentences=80, sample_size=881.9, wps=108.6, ups=0.12, wpb=881.9, bsz=80, num_updates=3370, lr=4.09105e-06, gnorm=1.434, clip=70, loss_scale=64, train_wall=81, gb_free=6.8, wall=42306
2022-05-20 09:10:02 - progress_bar.py[line:274] - INFO: epoch 001:   3385 / 7081 loss=-0.006, score=1.433, ntokens=877.2, nsentences=80, sample_size=877.2, wps=107.9, ups=0.12, wpb=877.2, bsz=80, num_updates=3380, lr=4.08745e-06, gnorm=1.397, clip=80, loss_scale=64, train_wall=81, gb_free=6.8, wall=42387
2022-05-20 09:11:24 - progress_bar.py[line:274] - INFO: epoch 001:   3395 / 7081 loss=-0.003, score=1.536, ntokens=883.1, nsentences=80, sample_size=883.1, wps=108.1, ups=0.12, wpb=883.1, bsz=80, num_updates=3390, lr=4.08384e-06, gnorm=1.791, clip=80, loss_scale=64, train_wall=82, gb_free=6.7, wall=42469
2022-05-20 09:12:45 - progress_bar.py[line:274] - INFO: epoch 001:   3405 / 7081 loss=-0.006, score=1.433, ntokens=874, nsentences=80, sample_size=874, wps=107.8, ups=0.12, wpb=874, bsz=80, num_updates=3400, lr=4.08024e-06, gnorm=1.33, clip=80, loss_scale=64, train_wall=81, gb_free=6.8, wall=42550
2022-05-20 09:14:07 - progress_bar.py[line:274] - INFO: epoch 001:   3415 / 7081 loss=-0.007, score=1.384, ntokens=885.1, nsentences=80, sample_size=885.1, wps=108.6, ups=0.12, wpb=885.1, bsz=80, num_updates=3410, lr=4.07663e-06, gnorm=1.49, clip=100, loss_scale=64, train_wall=81, gb_free=6.8, wall=42631
2022-05-20 09:15:28 - progress_bar.py[line:274] - INFO: epoch 001:   3425 / 7081 loss=-0.004, score=1.466, ntokens=884.3, nsentences=80, sample_size=884.3, wps=108.5, ups=0.12, wpb=884.3, bsz=80, num_updates=3420, lr=4.07303e-06, gnorm=1.783, clip=100, loss_scale=64, train_wall=81, gb_free=6.8, wall=42713
2022-05-20 09:16:46 - progress_bar.py[line:274] - INFO: epoch 001:   3435 / 7081 loss=-0.005, score=1.444, ntokens=892.9, nsentences=80, sample_size=892.9, wps=114.6, ups=0.13, wpb=892.9, bsz=80, num_updates=3430, lr=4.06942e-06, gnorm=1.75, clip=90, loss_scale=64, train_wall=78, gb_free=6.8, wall=42791
2022-05-20 09:18:04 - progress_bar.py[line:274] - INFO: epoch 001:   3445 / 7081 loss=-0.006, score=1.462, ntokens=897.3, nsentences=80, sample_size=897.3, wps=115.2, ups=0.13, wpb=897.3, bsz=80, num_updates=3440, lr=4.06582e-06, gnorm=1.299, clip=70, loss_scale=64, train_wall=78, gb_free=6.8, wall=42869
2022-05-20 09:19:24 - progress_bar.py[line:274] - INFO: epoch 001:   3455 / 7081 loss=-0.006, score=1.43, ntokens=883.3, nsentences=80, sample_size=883.3, wps=110.6, ups=0.13, wpb=883.3, bsz=80, num_updates=3450, lr=4.06221e-06, gnorm=1.578, clip=90, loss_scale=64, train_wall=80, gb_free=6.7, wall=42948
2022-05-20 09:20:45 - progress_bar.py[line:274] - INFO: epoch 001:   3465 / 7081 loss=-0.005, score=1.426, ntokens=881.6, nsentences=80, sample_size=881.6, wps=108.3, ups=0.12, wpb=881.6, bsz=80, num_updates=3460, lr=4.0586e-06, gnorm=1.788, clip=90, loss_scale=64, train_wall=81, gb_free=6.8, wall=43030
2022-05-20 09:22:07 - progress_bar.py[line:274] - INFO: epoch 001:   3475 / 7081 loss=-0.005, score=1.523, ntokens=884.8, nsentences=80, sample_size=884.8, wps=108.8, ups=0.12, wpb=884.8, bsz=80, num_updates=3470, lr=4.055e-06, gnorm=2.242, clip=90, loss_scale=64, train_wall=81, gb_free=6.8, wall=43111
2022-05-20 09:23:27 - progress_bar.py[line:274] - INFO: epoch 001:   3485 / 7081 loss=-0.006, score=1.453, ntokens=873.7, nsentences=80, sample_size=873.7, wps=108.4, ups=0.12, wpb=873.7, bsz=80, num_updates=3480, lr=4.05139e-06, gnorm=1.966, clip=100, loss_scale=64, train_wall=81, gb_free=6.8, wall=43192
2022-05-20 09:24:48 - progress_bar.py[line:274] - INFO: epoch 001:   3495 / 7081 loss=-0.007, score=1.529, ntokens=876.4, nsentences=80, sample_size=876.4, wps=108.1, ups=0.12, wpb=876.4, bsz=80, num_updates=3490, lr=4.04779e-06, gnorm=1.887, clip=90, loss_scale=64, train_wall=81, gb_free=6.8, wall=43273
2022-05-20 09:26:10 - progress_bar.py[line:274] - INFO: epoch 001:   3505 / 7081 loss=-0.005, score=1.444, ntokens=886.7, nsentences=80, sample_size=886.7, wps=108.3, ups=0.12, wpb=886.7, bsz=80, num_updates=3500, lr=4.04418e-06, gnorm=1.517, clip=80, loss_scale=64, train_wall=82, gb_free=6.8, wall=43355
slice_id 1 seek offset 2500
2022-05-20 09:26:10 - train.py[line:436] - INFO: begin validation on "valid" subset
slice_id 0 seek offset 0
slice_id 0 seek offset 0
slice_id 1 seek offset 2500
2022-05-20 10:06:25 - progress_bar.py[line:282] - INFO: epoch 001 | valid on 'valid' subset | loss -0.005 | score 1.291 | ntokens 110.475 | nsentences 10 | sample_size 110.475 | cider 1.377 | wps 114.4 | wpb 110.5 | bsz 10 | num_updates 3500 | best_cider 1.379
2022-05-20 10:06:25 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 1 @ 3500 updates
2022-05-20 10:06:25 - trainer.py[line:431] - INFO: Saving checkpoint to /database/jhkim/stage2_checkpoints//5e-6_2/checkpoint_1_3500.pt
2022-05-20 10:06:34 - trainer.py[line:441] - INFO: Finished saving checkpoint to /database/jhkim/stage2_checkpoints//5e-6_2/checkpoint_1_3500.pt
2022-05-20 10:07:07 - checkpoint_utils.py[line:135] - INFO: Saved checkpoint /database/jhkim/stage2_checkpoints//5e-6_2/checkpoint_1_3500.pt (epoch 1 @ 3500 updates, score 1.377) (writing took 42.18001549784094 seconds)
2022-05-20 10:08:27 - progress_bar.py[line:274] - INFO: epoch 001:   3515 / 7081 loss=-0.01, score=1.399, ntokens=886.1, nsentences=80, sample_size=886.1, wps=3.5, ups=0, wpb=886.1, bsz=80, num_updates=3510, lr=4.04058e-06, gnorm=1.573, clip=80, loss_scale=64, train_wall=79, gb_free=6.8, wall=45891
2022-05-20 10:09:43 - progress_bar.py[line:274] - INFO: epoch 001:   3525 / 7081 loss=-0.005, score=1.492, ntokens=876.4, nsentences=80, sample_size=876.4, wps=114.5, ups=0.13, wpb=876.4, bsz=80, num_updates=3520, lr=4.03697e-06, gnorm=1.754, clip=90, loss_scale=64, train_wall=76, gb_free=6.8, wall=45968
2022-05-20 10:11:00 - progress_bar.py[line:274] - INFO: epoch 001:   3535 / 7081 loss=-0.005, score=1.519, ntokens=881.7, nsentences=80, sample_size=881.7, wps=115.2, ups=0.13, wpb=881.7, bsz=80, num_updates=3530, lr=4.03337e-06, gnorm=2.254, clip=100, loss_scale=64, train_wall=76, gb_free=6.8, wall=46045
2022-05-20 10:12:21 - progress_bar.py[line:274] - INFO: epoch 001:   3545 / 7081 loss=-0.008, score=1.553, ntokens=873.9, nsentences=80, sample_size=873.9, wps=108.1, ups=0.12, wpb=873.9, bsz=80, num_updates=3540, lr=4.02976e-06, gnorm=1.584, clip=90, loss_scale=64, train_wall=81, gb_free=6.8, wall=46125
2022-05-20 10:13:42 - progress_bar.py[line:274] - INFO: epoch 001:   3555 / 7081 loss=-0.003, score=1.375, ntokens=882.8, nsentences=80, sample_size=882.8, wps=108.8, ups=0.12, wpb=882.8, bsz=80, num_updates=3550, lr=4.02615e-06, gnorm=1.626, clip=100, loss_scale=64, train_wall=81, gb_free=6.8, wall=46207
2022-05-20 10:15:03 - progress_bar.py[line:274] - INFO: epoch 001:   3565 / 7081 loss=-0.005, score=1.321, ntokens=886.4, nsentences=80, sample_size=886.4, wps=108.9, ups=0.12, wpb=886.4, bsz=80, num_updates=3560, lr=4.02255e-06, gnorm=1.554, clip=70, loss_scale=64, train_wall=81, gb_free=6.8, wall=46288
2022-05-20 10:16:25 - progress_bar.py[line:274] - INFO: epoch 001:   3575 / 7081 loss=-0.003, score=1.321, ntokens=881.4, nsentences=80, sample_size=881.4, wps=108.5, ups=0.12, wpb=881.4, bsz=80, num_updates=3570, lr=4.01894e-06, gnorm=1.377, clip=90, loss_scale=64, train_wall=81, gb_free=6.8, wall=46369
2022-05-20 10:17:46 - progress_bar.py[line:274] - INFO: epoch 001:   3585 / 7081 loss=-0.008, score=1.614, ntokens=868, nsentences=80, sample_size=868, wps=106.5, ups=0.12, wpb=868, bsz=80, num_updates=3580, lr=4.01534e-06, gnorm=1.439, clip=90, loss_scale=64, train_wall=81, gb_free=6.8, wall=46451
2022-05-20 10:19:07 - progress_bar.py[line:274] - INFO: epoch 001:   3595 / 7081 loss=-0.006, score=1.487, ntokens=877.6, nsentences=80, sample_size=877.6, wps=108.5, ups=0.12, wpb=877.6, bsz=80, num_updates=3590, lr=4.01173e-06, gnorm=1.624, clip=70, loss_scale=128, train_wall=81, gb_free=6.8, wall=46532
2022-05-20 10:19:56 - trainer.py[line:922] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-05-20 10:20:37 - progress_bar.py[line:274] - INFO: epoch 001:   3606 / 7081 loss=-0.007, score=1.519, ntokens=897.5, nsentences=80, sample_size=897.5, wps=99.6, ups=0.11, wpb=897.5, bsz=80, num_updates=3600, lr=4.00813e-06, gnorm=1.788, clip=90, loss_scale=64, train_wall=90, gb_free=6.8, wall=46622
2022-05-20 10:21:58 - progress_bar.py[line:274] - INFO: epoch 001:   3616 / 7081 loss=-0.006, score=1.411, ntokens=877.4, nsentences=80, sample_size=877.4, wps=107.9, ups=0.12, wpb=877.4, bsz=80, num_updates=3610, lr=4.00452e-06, gnorm=1.789, clip=90, loss_scale=64, train_wall=81, gb_free=6.8, wall=46703
2022-05-20 10:23:19 - progress_bar.py[line:274] - INFO: epoch 001:   3626 / 7081 loss=-0.007, score=1.438, ntokens=878.9, nsentences=80, sample_size=878.9, wps=108.8, ups=0.12, wpb=878.9, bsz=80, num_updates=3620, lr=4.00092e-06, gnorm=1.855, clip=100, loss_scale=64, train_wall=81, gb_free=6.8, wall=46784
2022-05-20 10:24:40 - progress_bar.py[line:274] - INFO: epoch 001:   3636 / 7081 loss=-0.003, score=1.501, ntokens=883.4, nsentences=80, sample_size=883.4, wps=108.7, ups=0.12, wpb=883.4, bsz=80, num_updates=3630, lr=3.99731e-06, gnorm=1.215, clip=70, loss_scale=64, train_wall=81, gb_free=6.8, wall=46865
2022-05-20 10:26:01 - progress_bar.py[line:274] - INFO: epoch 001:   3646 / 7081 loss=-0.003, score=1.566, ntokens=875.5, nsentences=80, sample_size=875.5, wps=108.9, ups=0.12, wpb=875.5, bsz=80, num_updates=3640, lr=3.99371e-06, gnorm=1.821, clip=90, loss_scale=64, train_wall=80, gb_free=6.8, wall=46945
2022-05-20 10:27:22 - progress_bar.py[line:274] - INFO: epoch 001:   3656 / 7081 loss=-0.006, score=1.563, ntokens=873.6, nsentences=80, sample_size=873.6, wps=107.1, ups=0.12, wpb=873.6, bsz=80, num_updates=3650, lr=3.9901e-06, gnorm=1.297, clip=70, loss_scale=64, train_wall=81, gb_free=6.8, wall=47027
2022-05-20 10:28:44 - progress_bar.py[line:274] - INFO: epoch 001:   3666 / 7081 loss=-0.002, score=1.401, ntokens=890.8, nsentences=80, sample_size=890.8, wps=109.2, ups=0.12, wpb=890.8, bsz=80, num_updates=3660, lr=3.98649e-06, gnorm=1.232, clip=80, loss_scale=64, train_wall=81, gb_free=6.8, wall=47109
2022-05-20 10:30:05 - progress_bar.py[line:274] - INFO: epoch 001:   3676 / 7081 loss=-0.004, score=1.35, ntokens=881.5, nsentences=80, sample_size=881.5, wps=108.7, ups=0.12, wpb=881.5, bsz=80, num_updates=3670, lr=3.98289e-06, gnorm=1.498, clip=70, loss_scale=64, train_wall=81, gb_free=6.8, wall=47190
2022-05-20 10:31:27 - progress_bar.py[line:274] - INFO: epoch 001:   3686 / 7081 loss=-0.002, score=1.313, ntokens=893.5, nsentences=80, sample_size=893.5, wps=109.3, ups=0.12, wpb=893.5, bsz=80, num_updates=3680, lr=3.97928e-06, gnorm=1.736, clip=80, loss_scale=64, train_wall=82, gb_free=6.8, wall=47271
2022-05-20 10:32:48 - progress_bar.py[line:274] - INFO: epoch 001:   3696 / 7081 loss=-0.005, score=1.373, ntokens=880.9, nsentences=80, sample_size=880.9, wps=108.7, ups=0.12, wpb=880.9, bsz=80, num_updates=3690, lr=3.97568e-06, gnorm=1.253, clip=80, loss_scale=64, train_wall=81, gb_free=6.8, wall=47352
2022-05-20 10:34:09 - progress_bar.py[line:274] - INFO: epoch 001:   3706 / 7081 loss=-0.004, score=1.448, ntokens=892.6, nsentences=80, sample_size=892.6, wps=109.8, ups=0.12, wpb=892.6, bsz=80, num_updates=3700, lr=3.97207e-06, gnorm=1.498, clip=80, loss_scale=64, train_wall=81, gb_free=6.8, wall=47434
2022-05-20 10:35:27 - progress_bar.py[line:274] - INFO: epoch 001:   3716 / 7081 loss=-0.004, score=1.377, ntokens=875, nsentences=80, sample_size=875, wps=112.6, ups=0.13, wpb=875, bsz=80, num_updates=3710, lr=3.96847e-06, gnorm=1.621, clip=70, loss_scale=64, train_wall=78, gb_free=6.8, wall=47511
2022-05-20 10:36:44 - progress_bar.py[line:274] - INFO: epoch 001:   3726 / 7081 loss=-0.005, score=1.479, ntokens=885.1, nsentences=80, sample_size=885.1, wps=115.2, ups=0.13, wpb=885.1, bsz=80, num_updates=3720, lr=3.96486e-06, gnorm=1.275, clip=50, loss_scale=64, train_wall=77, gb_free=6.8, wall=47588
2022-05-20 10:38:03 - progress_bar.py[line:274] - INFO: epoch 001:   3736 / 7081 loss=-0.006, score=1.385, ntokens=886.7, nsentences=80, sample_size=886.7, wps=112.3, ups=0.13, wpb=886.7, bsz=80, num_updates=3730, lr=3.96126e-06, gnorm=1.7, clip=70, loss_scale=64, train_wall=79, gb_free=6.8, wall=47667
2022-05-20 10:39:24 - progress_bar.py[line:274] - INFO: epoch 001:   3746 / 7081 loss=-0.006, score=1.384, ntokens=883.8, nsentences=80, sample_size=883.8, wps=108.8, ups=0.12, wpb=883.8, bsz=80, num_updates=3740, lr=3.95765e-06, gnorm=1.133, clip=70, loss_scale=64, train_wall=81, gb_free=6.8, wall=47748
2022-05-20 10:40:45 - progress_bar.py[line:274] - INFO: epoch 001:   3756 / 7081 loss=-0.006, score=1.361, ntokens=880.6, nsentences=80, sample_size=880.6, wps=108.1, ups=0.12, wpb=880.6, bsz=80, num_updates=3750, lr=3.95404e-06, gnorm=1.561, clip=80, loss_scale=64, train_wall=81, gb_free=6.8, wall=47830
2022-05-20 10:42:06 - progress_bar.py[line:274] - INFO: epoch 001:   3766 / 7081 loss=-0.004, score=1.426, ntokens=887.6, nsentences=80, sample_size=887.6, wps=109.4, ups=0.12, wpb=887.6, bsz=80, num_updates=3760, lr=3.95044e-06, gnorm=1.789, clip=70, loss_scale=64, train_wall=81, gb_free=6.8, wall=47911
2022-05-20 10:43:28 - progress_bar.py[line:274] - INFO: epoch 001:   3776 / 7081 loss=-0.004, score=1.524, ntokens=898.7, nsentences=80, sample_size=898.7, wps=110.4, ups=0.12, wpb=898.7, bsz=80, num_updates=3770, lr=3.94683e-06, gnorm=1.353, clip=90, loss_scale=64, train_wall=81, gb_free=6.8, wall=47992
2022-05-20 10:44:50 - progress_bar.py[line:274] - INFO: epoch 001:   3786 / 7081 loss=-0.005, score=1.436, ntokens=876.7, nsentences=80, sample_size=876.7, wps=107, ups=0.12, wpb=876.7, bsz=80, num_updates=3780, lr=3.94323e-06, gnorm=1.765, clip=100, loss_scale=64, train_wall=82, gb_free=6.8, wall=48074
2022-05-20 10:46:11 - progress_bar.py[line:274] - INFO: epoch 001:   3796 / 7081 loss=-0.004, score=1.411, ntokens=878.4, nsentences=80, sample_size=878.4, wps=108.3, ups=0.12, wpb=878.4, bsz=80, num_updates=3790, lr=3.93962e-06, gnorm=1.261, clip=70, loss_scale=64, train_wall=81, gb_free=6.8, wall=48156
2022-05-20 10:47:32 - progress_bar.py[line:274] - INFO: epoch 001:   3806 / 7081 loss=-0.008, score=1.468, ntokens=890.2, nsentences=80, sample_size=890.2, wps=109.7, ups=0.12, wpb=890.2, bsz=80, num_updates=3800, lr=3.93602e-06, gnorm=1.704, clip=80, loss_scale=64, train_wall=81, gb_free=6.8, wall=48237
2022-05-20 10:48:53 - progress_bar.py[line:274] - INFO: epoch 001:   3816 / 7081 loss=-0.005, score=1.523, ntokens=876.3, nsentences=80, sample_size=876.3, wps=107.5, ups=0.12, wpb=876.3, bsz=80, num_updates=3810, lr=3.93241e-06, gnorm=2.346, clip=100, loss_scale=64, train_wall=81, gb_free=6.8, wall=48318
2022-05-20 10:50:14 - progress_bar.py[line:274] - INFO: epoch 001:   3826 / 7081 loss=-0.006, score=1.466, ntokens=878.2, nsentences=80, sample_size=878.2, wps=109.4, ups=0.12, wpb=878.2, bsz=80, num_updates=3820, lr=3.92881e-06, gnorm=1.897, clip=100, loss_scale=64, train_wall=80, gb_free=6.8, wall=48398
2022-05-20 10:51:35 - progress_bar.py[line:274] - INFO: epoch 001:   3836 / 7081 loss=-0.005, score=1.458, ntokens=888.7, nsentences=80, sample_size=888.7, wps=109.4, ups=0.12, wpb=888.7, bsz=80, num_updates=3830, lr=3.9252e-06, gnorm=1.252, clip=80, loss_scale=64, train_wall=81, gb_free=6.8, wall=48480
2022-05-20 10:52:56 - progress_bar.py[line:274] - INFO: epoch 001:   3846 / 7081 loss=-0.005, score=1.409, ntokens=874.6, nsentences=80, sample_size=874.6, wps=107.6, ups=0.12, wpb=874.6, bsz=80, num_updates=3840, lr=3.9216e-06, gnorm=1.676, clip=80, loss_scale=64, train_wall=81, gb_free=6.8, wall=48561
2022-05-20 10:54:17 - progress_bar.py[line:274] - INFO: epoch 001:   3856 / 7081 loss=-0.009, score=1.504, ntokens=876.7, nsentences=80, sample_size=876.7, wps=108.4, ups=0.12, wpb=876.7, bsz=80, num_updates=3850, lr=3.91799e-06, gnorm=1.747, clip=90, loss_scale=64, train_wall=81, gb_free=6.8, wall=48642
2022-05-20 10:55:38 - progress_bar.py[line:274] - INFO: epoch 001:   3866 / 7081 loss=-0.005, score=1.517, ntokens=877.3, nsentences=80, sample_size=877.3, wps=108.5, ups=0.12, wpb=877.3, bsz=80, num_updates=3860, lr=3.91438e-06, gnorm=1.56, clip=90, loss_scale=64, train_wall=81, gb_free=6.8, wall=48723
2022-05-20 10:56:59 - progress_bar.py[line:274] - INFO: epoch 001:   3876 / 7081 loss=-0.006, score=1.37, ntokens=888.6, nsentences=80, sample_size=888.6, wps=109.5, ups=0.12, wpb=888.6, bsz=80, num_updates=3870, lr=3.91078e-06, gnorm=2.449, clip=80, loss_scale=64, train_wall=81, gb_free=6.8, wall=48804
2022-05-20 10:58:21 - progress_bar.py[line:274] - INFO: epoch 001:   3886 / 7081 loss=-0.007, score=1.49, ntokens=896.3, nsentences=80, sample_size=896.3, wps=109, ups=0.12, wpb=896.3, bsz=80, num_updates=3880, lr=3.90717e-06, gnorm=2.193, clip=80, loss_scale=64, train_wall=82, gb_free=6.8, wall=48886
2022-05-20 10:59:43 - progress_bar.py[line:274] - INFO: epoch 001:   3896 / 7081 loss=-0.003, score=1.388, ntokens=888.3, nsentences=80, sample_size=888.3, wps=109.3, ups=0.12, wpb=888.3, bsz=80, num_updates=3890, lr=3.90357e-06, gnorm=1.868, clip=90, loss_scale=64, train_wall=81, gb_free=6.8, wall=48967
2022-05-20 11:01:03 - progress_bar.py[line:274] - INFO: epoch 001:   3906 / 7081 loss=-0.006, score=1.418, ntokens=884.6, nsentences=80, sample_size=884.6, wps=110.8, ups=0.13, wpb=884.6, bsz=80, num_updates=3900, lr=3.89996e-06, gnorm=1.641, clip=90, loss_scale=64, train_wall=80, gb_free=6.8, wall=49047
2022-05-20 11:02:20 - progress_bar.py[line:274] - INFO: epoch 001:   3916 / 7081 loss=-0.008, score=1.486, ntokens=885.9, nsentences=80, sample_size=885.9, wps=114.8, ups=0.13, wpb=885.9, bsz=80, num_updates=3910, lr=3.89636e-06, gnorm=1.922, clip=90, loss_scale=64, train_wall=77, gb_free=6.8, wall=49124
2022-05-20 11:03:37 - progress_bar.py[line:274] - INFO: epoch 001:   3926 / 7081 loss=-0.007, score=1.415, ntokens=880.8, nsentences=80, sample_size=880.8, wps=114.1, ups=0.13, wpb=880.8, bsz=80, num_updates=3920, lr=3.89275e-06, gnorm=1.902, clip=80, loss_scale=64, train_wall=77, gb_free=6.8, wall=49202
2022-05-20 11:04:59 - progress_bar.py[line:274] - INFO: epoch 001:   3936 / 7081 loss=-0.005, score=1.444, ntokens=887.3, nsentences=80, sample_size=887.3, wps=108.5, ups=0.12, wpb=887.3, bsz=80, num_updates=3930, lr=3.88915e-06, gnorm=1.736, clip=70, loss_scale=64, train_wall=82, gb_free=6.8, wall=49283
2022-05-20 11:06:21 - progress_bar.py[line:274] - INFO: epoch 001:   3946 / 7081 loss=-0.005, score=1.491, ntokens=887.7, nsentences=80, sample_size=887.7, wps=107.8, ups=0.12, wpb=887.7, bsz=80, num_updates=3940, lr=3.88554e-06, gnorm=1.829, clip=100, loss_scale=64, train_wall=82, gb_free=6.8, wall=49366
2022-05-20 11:07:44 - progress_bar.py[line:274] - INFO: epoch 001:   3956 / 7081 loss=-0.006, score=1.494, ntokens=880.3, nsentences=80, sample_size=880.3, wps=106.3, ups=0.12, wpb=880.3, bsz=80, num_updates=3950, lr=3.88193e-06, gnorm=2.116, clip=90, loss_scale=64, train_wall=83, gb_free=6.8, wall=49448
2022-05-20 11:09:06 - progress_bar.py[line:274] - INFO: epoch 001:   3966 / 7081 loss=-0.005, score=1.377, ntokens=892.2, nsentences=80, sample_size=892.2, wps=108.1, ups=0.12, wpb=892.2, bsz=80, num_updates=3960, lr=3.87833e-06, gnorm=2.236, clip=100, loss_scale=64, train_wall=82, gb_free=6.8, wall=49531
2022-05-20 11:10:28 - progress_bar.py[line:274] - INFO: epoch 001:   3976 / 7081 loss=-0.005, score=1.54, ntokens=868.6, nsentences=80, sample_size=868.6, wps=106.3, ups=0.12, wpb=868.6, bsz=80, num_updates=3970, lr=3.87472e-06, gnorm=1.999, clip=90, loss_scale=64, train_wall=82, gb_free=6.8, wall=49613
2022-05-20 11:11:51 - progress_bar.py[line:274] - INFO: epoch 001:   3986 / 7081 loss=-0.005, score=1.502, ntokens=888.5, nsentences=80, sample_size=888.5, wps=107.5, ups=0.12, wpb=888.5, bsz=80, num_updates=3980, lr=3.87112e-06, gnorm=1.931, clip=80, loss_scale=64, train_wall=83, gb_free=6.8, wall=49695
2022-05-20 11:13:13 - progress_bar.py[line:274] - INFO: epoch 001:   3996 / 7081 loss=-0.002, score=1.486, ntokens=884.2, nsentences=80, sample_size=884.2, wps=106.8, ups=0.12, wpb=884.2, bsz=80, num_updates=3990, lr=3.86751e-06, gnorm=2.05, clip=90, loss_scale=64, train_wall=83, gb_free=6.8, wall=49778
2022-05-20 11:14:36 - progress_bar.py[line:274] - INFO: epoch 001:   4006 / 7081 loss=-0.005, score=1.461, ntokens=887.1, nsentences=80, sample_size=887.1, wps=107.8, ups=0.12, wpb=887.1, bsz=80, num_updates=4000, lr=3.86391e-06, gnorm=1.527, clip=80, loss_scale=64, train_wall=82, gb_free=6.8, wall=49860
slice_id 1 seek offset 2500
2022-05-20 11:14:36 - train.py[line:436] - INFO: begin validation on "valid" subset
slice_id 0 seek offset 0
slice_id 0 seek offset 0
slice_id 1 seek offset 2500
2022-05-20 11:55:20 - progress_bar.py[line:282] - INFO: epoch 001 | valid on 'valid' subset | loss -0.005 | score 1.292 | ntokens 110.496 | nsentences 10 | sample_size 110.496 | cider 1.382 | wps 113 | wpb 110.5 | bsz 10 | num_updates 4000 | best_cider 1.382
2022-05-20 11:55:20 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 1 @ 4000 updates
2022-05-20 11:55:20 - trainer.py[line:431] - INFO: Saving checkpoint to /database/jhkim/stage2_checkpoints//5e-6_2/checkpoint_1_4000.pt
2022-05-20 11:55:28 - trainer.py[line:441] - INFO: Finished saving checkpoint to /database/jhkim/stage2_checkpoints//5e-6_2/checkpoint_1_4000.pt
2022-05-20 11:58:23 - checkpoint_utils.py[line:135] - INFO: Saved checkpoint /database/jhkim/stage2_checkpoints//5e-6_2/checkpoint_1_4000.pt (epoch 1 @ 4000 updates, score 1.382) (writing took 183.48036545701325 seconds)
2022-05-20 11:59:44 - progress_bar.py[line:274] - INFO: epoch 001:   4016 / 7081 loss=-0.005, score=1.447, ntokens=888.6, nsentences=80, sample_size=888.6, wps=3.3, ups=0, wpb=888.6, bsz=80, num_updates=4010, lr=3.8603e-06, gnorm=1.918, clip=80, loss_scale=64, train_wall=81, gb_free=6.8, wall=52569
2022-05-20 12:01:06 - progress_bar.py[line:274] - INFO: epoch 001:   4026 / 7081 loss=-0.004, score=1.359, ntokens=871.7, nsentences=80, sample_size=871.7, wps=106.8, ups=0.12, wpb=871.7, bsz=80, num_updates=4020, lr=3.8567e-06, gnorm=1.705, clip=80, loss_scale=64, train_wall=82, gb_free=6.8, wall=52651
2022-05-20 12:02:27 - progress_bar.py[line:274] - INFO: epoch 001:   4036 / 7081 loss=-0.007, score=1.379, ntokens=874.7, nsentences=80, sample_size=874.7, wps=107.4, ups=0.12, wpb=874.7, bsz=80, num_updates=4030, lr=3.85309e-06, gnorm=1.879, clip=90, loss_scale=64, train_wall=81, gb_free=6.8, wall=52732
2022-05-20 12:03:49 - progress_bar.py[line:274] - INFO: epoch 001:   4046 / 7081 loss=-0.006, score=1.419, ntokens=874.8, nsentences=80, sample_size=874.8, wps=107.4, ups=0.12, wpb=874.8, bsz=80, num_updates=4040, lr=3.84949e-06, gnorm=1.759, clip=90, loss_scale=64, train_wall=81, gb_free=6.8, wall=52814
2022-05-20 12:05:10 - progress_bar.py[line:274] - INFO: epoch 001:   4056 / 7081 loss=-0.006, score=1.49, ntokens=886.2, nsentences=80, sample_size=886.2, wps=109, ups=0.12, wpb=886.2, bsz=80, num_updates=4050, lr=3.84588e-06, gnorm=1.952, clip=90, loss_scale=64, train_wall=81, gb_free=6.8, wall=52895
2022-05-20 12:06:32 - progress_bar.py[line:274] - INFO: epoch 001:   4066 / 7081 loss=-0.004, score=1.441, ntokens=887, nsentences=80, sample_size=887, wps=108.3, ups=0.12, wpb=887, bsz=80, num_updates=4060, lr=3.84227e-06, gnorm=1.592, clip=90, loss_scale=64, train_wall=82, gb_free=6.8, wall=52977
2022-05-20 12:07:54 - progress_bar.py[line:274] - INFO: epoch 001:   4076 / 7081 loss=-0.006, score=1.542, ntokens=888.3, nsentences=80, sample_size=888.3, wps=108.4, ups=0.12, wpb=888.3, bsz=80, num_updates=4070, lr=3.83867e-06, gnorm=1.901, clip=90, loss_scale=64, train_wall=82, gb_free=6.8, wall=53059
2022-05-20 12:09:16 - progress_bar.py[line:274] - INFO: epoch 001:   4086 / 7081 loss=-0.006, score=1.444, ntokens=874.3, nsentences=80, sample_size=874.3, wps=106.8, ups=0.12, wpb=874.3, bsz=80, num_updates=4080, lr=3.83506e-06, gnorm=1.678, clip=100, loss_scale=64, train_wall=82, gb_free=6.8, wall=53141
2022-05-20 12:10:38 - progress_bar.py[line:274] - INFO: epoch 001:   4096 / 7081 loss=-0.003, score=1.413, ntokens=879, nsentences=80, sample_size=879, wps=107.3, ups=0.12, wpb=879, bsz=80, num_updates=4090, lr=3.83146e-06, gnorm=1.602, clip=90, loss_scale=64, train_wall=82, gb_free=6.8, wall=53223
2022-05-20 12:12:00 - progress_bar.py[line:274] - INFO: epoch 001:   4106 / 7081 loss=-0.005, score=1.417, ntokens=876.7, nsentences=80, sample_size=876.7, wps=107.5, ups=0.12, wpb=876.7, bsz=80, num_updates=4100, lr=3.82785e-06, gnorm=1.948, clip=80, loss_scale=64, train_wall=81, gb_free=6.8, wall=53304
2022-05-20 12:13:22 - progress_bar.py[line:274] - INFO: epoch 001:   4116 / 7081 loss=-0.007, score=1.493, ntokens=874.4, nsentences=80, sample_size=874.4, wps=106.4, ups=0.12, wpb=874.4, bsz=80, num_updates=4110, lr=3.82425e-06, gnorm=2.538, clip=100, loss_scale=128, train_wall=82, gb_free=6.8, wall=53386
2022-05-20 12:14:43 - progress_bar.py[line:274] - INFO: epoch 001:   4126 / 7081 loss=-0.005, score=1.347, ntokens=869.2, nsentences=80, sample_size=869.2, wps=106.6, ups=0.12, wpb=869.2, bsz=80, num_updates=4120, lr=3.82064e-06, gnorm=1.51, clip=80, loss_scale=128, train_wall=81, gb_free=6.8, wall=53468
2022-05-20 12:16:05 - progress_bar.py[line:274] - INFO: epoch 001:   4136 / 7081 loss=-0.007, score=1.5, ntokens=877.1, nsentences=80, sample_size=877.1, wps=106.7, ups=0.12, wpb=877.1, bsz=80, num_updates=4130, lr=3.81704e-06, gnorm=1.986, clip=100, loss_scale=128, train_wall=82, gb_free=6.8, wall=53550
2022-05-20 12:17:27 - progress_bar.py[line:274] - INFO: epoch 001:   4146 / 7081 loss=-0.004, score=1.476, ntokens=870.1, nsentences=80, sample_size=870.1, wps=107.2, ups=0.12, wpb=870.1, bsz=80, num_updates=4140, lr=3.81343e-06, gnorm=1.762, clip=80, loss_scale=128, train_wall=81, gb_free=6.8, wall=53631
2022-05-20 12:18:49 - progress_bar.py[line:274] - INFO: epoch 001:   4156 / 7081 loss=-0.003, score=1.361, ntokens=892, nsentences=80, sample_size=892, wps=108.5, ups=0.12, wpb=892, bsz=80, num_updates=4150, lr=3.80982e-06, gnorm=1.653, clip=50, loss_scale=128, train_wall=82, gb_free=6.8, wall=53713
2022-05-20 12:20:10 - progress_bar.py[line:274] - INFO: epoch 001:   4166 / 7081 loss=-0.011, score=1.525, ntokens=874.7, nsentences=80, sample_size=874.7, wps=108, ups=0.12, wpb=874.7, bsz=80, num_updates=4160, lr=3.80622e-06, gnorm=2.575, clip=90, loss_scale=128, train_wall=81, gb_free=6.8, wall=53794
2022-05-20 12:21:27 - progress_bar.py[line:274] - INFO: epoch 001:   4176 / 7081 loss=-0.007, score=1.472, ntokens=898.8, nsentences=80, sample_size=898.8, wps=116.6, ups=0.13, wpb=898.8, bsz=80, num_updates=4170, lr=3.80261e-06, gnorm=2.37, clip=90, loss_scale=128, train_wall=77, gb_free=6.8, wall=53872
2022-05-20 12:22:43 - progress_bar.py[line:274] - INFO: epoch 001:   4186 / 7081 loss=-0.006, score=1.467, ntokens=880.6, nsentences=80, sample_size=880.6, wps=115.1, ups=0.13, wpb=880.6, bsz=80, num_updates=4180, lr=3.79901e-06, gnorm=1.661, clip=80, loss_scale=128, train_wall=76, gb_free=6.7, wall=53948
2022-05-20 12:24:05 - progress_bar.py[line:274] - INFO: epoch 001:   4196 / 7081 loss=-0.007, score=1.486, ntokens=886.4, nsentences=80, sample_size=886.4, wps=108.7, ups=0.12, wpb=886.4, bsz=80, num_updates=4190, lr=3.7954e-06, gnorm=1.784, clip=80, loss_scale=128, train_wall=81, gb_free=6.8, wall=54030
2022-05-20 12:25:27 - progress_bar.py[line:274] - INFO: epoch 001:   4206 / 7081 loss=-0.003, score=1.375, ntokens=886.3, nsentences=80, sample_size=886.3, wps=108.3, ups=0.12, wpb=886.3, bsz=80, num_updates=4200, lr=3.7918e-06, gnorm=1.833, clip=100, loss_scale=128, train_wall=82, gb_free=6.8, wall=54111
2022-05-20 12:26:48 - progress_bar.py[line:274] - INFO: epoch 001:   4216 / 7081 loss=-0.006, score=1.48, ntokens=878.8, nsentences=80, sample_size=878.8, wps=108, ups=0.12, wpb=878.8, bsz=80, num_updates=4210, lr=3.78819e-06, gnorm=2.12, clip=90, loss_scale=128, train_wall=81, gb_free=6.8, wall=54193
2022-05-20 12:28:10 - progress_bar.py[line:274] - INFO: epoch 001:   4226 / 7081 loss=-0.01, score=1.476, ntokens=889.1, nsentences=80, sample_size=889.1, wps=108.7, ups=0.12, wpb=889.1, bsz=80, num_updates=4220, lr=3.78459e-06, gnorm=1.97, clip=90, loss_scale=128, train_wall=82, gb_free=6.8, wall=54275
2022-05-20 12:29:07 - trainer.py[line:922] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-05-20 12:29:40 - progress_bar.py[line:274] - INFO: epoch 001:   4237 / 7081 loss=-0.009, score=1.419, ntokens=888.5, nsentences=80, sample_size=888.5, wps=98.5, ups=0.11, wpb=888.5, bsz=80, num_updates=4230, lr=3.78098e-06, gnorm=1.609, clip=90, loss_scale=64, train_wall=90, gb_free=6.8, wall=54365
2022-05-20 12:31:02 - progress_bar.py[line:274] - INFO: epoch 001:   4247 / 7081 loss=-0.007, score=1.522, ntokens=886, nsentences=80, sample_size=886, wps=108.1, ups=0.12, wpb=886, bsz=80, num_updates=4240, lr=3.77738e-06, gnorm=1.989, clip=100, loss_scale=64, train_wall=82, gb_free=6.8, wall=54447
2022-05-20 12:32:24 - progress_bar.py[line:274] - INFO: epoch 001:   4257 / 7081 loss=-0.005, score=1.466, ntokens=877.7, nsentences=80, sample_size=877.7, wps=107.5, ups=0.12, wpb=877.7, bsz=80, num_updates=4250, lr=3.77377e-06, gnorm=1.934, clip=80, loss_scale=64, train_wall=82, gb_free=6.8, wall=54529
2022-05-20 12:33:46 - progress_bar.py[line:274] - INFO: epoch 001:   4267 / 7081 loss=-0.006, score=1.405, ntokens=886.5, nsentences=80, sample_size=886.5, wps=107.6, ups=0.12, wpb=886.5, bsz=80, num_updates=4260, lr=3.77016e-06, gnorm=1.855, clip=90, loss_scale=64, train_wall=82, gb_free=6.8, wall=54611
2022-05-20 12:35:08 - progress_bar.py[line:274] - INFO: epoch 001:   4277 / 7081 loss=-0.006, score=1.521, ntokens=889.2, nsentences=80, sample_size=889.2, wps=108.8, ups=0.12, wpb=889.2, bsz=80, num_updates=4270, lr=3.76656e-06, gnorm=1.884, clip=100, loss_scale=64, train_wall=82, gb_free=6.8, wall=54693
2022-05-20 12:36:30 - progress_bar.py[line:274] - INFO: epoch 001:   4287 / 7081 loss=-0.007, score=1.462, ntokens=888.7, nsentences=80, sample_size=888.7, wps=107.9, ups=0.12, wpb=888.7, bsz=80, num_updates=4280, lr=3.76295e-06, gnorm=1.371, clip=80, loss_scale=64, train_wall=82, gb_free=6.8, wall=54775
2022-05-20 12:37:52 - progress_bar.py[line:274] - INFO: epoch 001:   4297 / 7081 loss=-0.008, score=1.385, ntokens=888.2, nsentences=80, sample_size=888.2, wps=108.3, ups=0.12, wpb=888.2, bsz=80, num_updates=4290, lr=3.75935e-06, gnorm=1.815, clip=80, loss_scale=64, train_wall=82, gb_free=6.8, wall=54857
2022-05-20 12:39:14 - progress_bar.py[line:274] - INFO: epoch 001:   4307 / 7081 loss=-0.007, score=1.517, ntokens=880.4, nsentences=80, sample_size=880.4, wps=107.3, ups=0.12, wpb=880.4, bsz=80, num_updates=4300, lr=3.75574e-06, gnorm=1.687, clip=100, loss_scale=64, train_wall=82, gb_free=6.8, wall=54939
2022-05-20 12:40:37 - progress_bar.py[line:274] - INFO: epoch 001:   4317 / 7081 loss=-0.005, score=1.335, ntokens=888.9, nsentences=80, sample_size=888.9, wps=107.7, ups=0.12, wpb=888.9, bsz=80, num_updates=4310, lr=3.75214e-06, gnorm=1.428, clip=90, loss_scale=64, train_wall=82, gb_free=6.8, wall=55022
2022-05-20 12:42:00 - progress_bar.py[line:274] - INFO: epoch 001:   4327 / 7081 loss=-0.006, score=1.421, ntokens=896.8, nsentences=80, sample_size=896.8, wps=108.6, ups=0.12, wpb=896.8, bsz=80, num_updates=4320, lr=3.74853e-06, gnorm=2.149, clip=80, loss_scale=64, train_wall=82, gb_free=6.7, wall=55104
2022-05-20 12:43:22 - progress_bar.py[line:274] - INFO: epoch 001:   4337 / 7081 loss=-0.008, score=1.486, ntokens=891.3, nsentences=80, sample_size=891.3, wps=108.4, ups=0.12, wpb=891.3, bsz=80, num_updates=4330, lr=3.74493e-06, gnorm=1.528, clip=90, loss_scale=64, train_wall=82, gb_free=6.8, wall=55186
2022-05-20 12:44:44 - progress_bar.py[line:274] - INFO: epoch 001:   4347 / 7081 loss=-0.004, score=1.496, ntokens=881.9, nsentences=80, sample_size=881.9, wps=107.2, ups=0.12, wpb=881.9, bsz=80, num_updates=4340, lr=3.74132e-06, gnorm=1.641, clip=60, loss_scale=64, train_wall=82, gb_free=6.8, wall=55269
2022-05-20 12:46:06 - progress_bar.py[line:274] - INFO: epoch 001:   4357 / 7081 loss=-0.005, score=1.404, ntokens=878.4, nsentences=80, sample_size=878.4, wps=107.5, ups=0.12, wpb=878.4, bsz=80, num_updates=4350, lr=3.73772e-06, gnorm=2.087, clip=100, loss_scale=64, train_wall=82, gb_free=6.8, wall=55350
2022-05-20 12:47:24 - progress_bar.py[line:274] - INFO: epoch 001:   4367 / 7081 loss=-0.008, score=1.497, ntokens=883.2, nsentences=80, sample_size=883.2, wps=113.3, ups=0.13, wpb=883.2, bsz=80, num_updates=4360, lr=3.73411e-06, gnorm=2.211, clip=100, loss_scale=64, train_wall=78, gb_free=6.8, wall=55428
2022-05-20 12:48:40 - progress_bar.py[line:274] - INFO: epoch 001:   4377 / 7081 loss=-0.008, score=1.389, ntokens=885.3, nsentences=80, sample_size=885.3, wps=115.6, ups=0.13, wpb=885.3, bsz=80, num_updates=4370, lr=3.7305e-06, gnorm=2.325, clip=80, loss_scale=64, train_wall=76, gb_free=6.8, wall=55505
2022-05-20 12:50:00 - progress_bar.py[line:274] - INFO: epoch 001:   4387 / 7081 loss=-0.008, score=1.464, ntokens=886.2, nsentences=80, sample_size=886.2, wps=111.3, ups=0.13, wpb=886.2, bsz=80, num_updates=4380, lr=3.7269e-06, gnorm=1.914, clip=80, loss_scale=64, train_wall=80, gb_free=6.7, wall=55585
2022-05-20 12:51:22 - progress_bar.py[line:274] - INFO: epoch 001:   4397 / 7081 loss=-0.005, score=1.391, ntokens=890.8, nsentences=80, sample_size=890.8, wps=108.7, ups=0.12, wpb=890.8, bsz=80, num_updates=4390, lr=3.72329e-06, gnorm=1.549, clip=80, loss_scale=64, train_wall=82, gb_free=6.8, wall=55667
2022-05-20 12:52:43 - progress_bar.py[line:274] - INFO: epoch 001:   4407 / 7081 loss=-0.005, score=1.434, ntokens=889.5, nsentences=80, sample_size=889.5, wps=109.6, ups=0.12, wpb=889.5, bsz=80, num_updates=4400, lr=3.71969e-06, gnorm=1.365, clip=80, loss_scale=64, train_wall=81, gb_free=6.8, wall=55748
2022-05-20 12:54:05 - progress_bar.py[line:274] - INFO: epoch 001:   4417 / 7081 loss=-0.005, score=1.513, ntokens=872.6, nsentences=80, sample_size=872.6, wps=107.1, ups=0.12, wpb=872.6, bsz=80, num_updates=4410, lr=3.71608e-06, gnorm=1.524, clip=70, loss_scale=64, train_wall=81, gb_free=6.8, wall=55829
2022-05-20 12:55:27 - progress_bar.py[line:274] - INFO: epoch 001:   4427 / 7081 loss=-0.006, score=1.394, ntokens=879.8, nsentences=80, sample_size=879.8, wps=107.2, ups=0.12, wpb=879.8, bsz=80, num_updates=4420, lr=3.71248e-06, gnorm=1.743, clip=90, loss_scale=64, train_wall=82, gb_free=6.8, wall=55911
2022-05-20 12:56:48 - progress_bar.py[line:274] - INFO: epoch 001:   4437 / 7081 loss=-0.006, score=1.33, ntokens=877.4, nsentences=80, sample_size=877.4, wps=107.3, ups=0.12, wpb=877.4, bsz=80, num_updates=4430, lr=3.70887e-06, gnorm=1.7, clip=100, loss_scale=64, train_wall=82, gb_free=6.8, wall=55993
2022-05-20 12:58:11 - progress_bar.py[line:274] - INFO: epoch 001:   4447 / 7081 loss=-0.008, score=1.379, ntokens=878.9, nsentences=80, sample_size=878.9, wps=106.5, ups=0.12, wpb=878.9, bsz=80, num_updates=4440, lr=3.70527e-06, gnorm=1.779, clip=90, loss_scale=64, train_wall=82, gb_free=6.8, wall=56076
2022-05-20 12:59:32 - progress_bar.py[line:274] - INFO: epoch 001:   4457 / 7081 loss=-0.005, score=1.44, ntokens=873, nsentences=80, sample_size=873, wps=107.5, ups=0.12, wpb=873, bsz=80, num_updates=4450, lr=3.70166e-06, gnorm=1.883, clip=100, loss_scale=64, train_wall=81, gb_free=6.8, wall=56157
2022-05-20 13:00:54 - progress_bar.py[line:274] - INFO: epoch 001:   4467 / 7081 loss=-0.003, score=1.387, ntokens=890.3, nsentences=80, sample_size=890.3, wps=108.4, ups=0.12, wpb=890.3, bsz=80, num_updates=4460, lr=3.69805e-06, gnorm=1.51, clip=100, loss_scale=64, train_wall=82, gb_free=6.8, wall=56239
2022-05-20 13:02:16 - progress_bar.py[line:274] - INFO: epoch 001:   4477 / 7081 loss=-0.008, score=1.462, ntokens=874.1, nsentences=80, sample_size=874.1, wps=106.9, ups=0.12, wpb=874.1, bsz=80, num_updates=4470, lr=3.69445e-06, gnorm=2.541, clip=90, loss_scale=64, train_wall=82, gb_free=6.8, wall=56321
2022-05-20 13:03:38 - progress_bar.py[line:274] - INFO: epoch 001:   4487 / 7081 loss=-0.008, score=1.441, ntokens=883.5, nsentences=80, sample_size=883.5, wps=107.2, ups=0.12, wpb=883.5, bsz=80, num_updates=4480, lr=3.69084e-06, gnorm=2.297, clip=100, loss_scale=64, train_wall=82, gb_free=6.8, wall=56403
2022-05-20 13:05:01 - progress_bar.py[line:274] - INFO: epoch 001:   4497 / 7081 loss=-0.006, score=1.349, ntokens=882.3, nsentences=80, sample_size=882.3, wps=107.3, ups=0.12, wpb=882.3, bsz=80, num_updates=4490, lr=3.68724e-06, gnorm=1.981, clip=100, loss_scale=64, train_wall=82, gb_free=6.8, wall=56485
2022-05-20 13:06:23 - progress_bar.py[line:274] - INFO: epoch 001:   4507 / 7081 loss=-0.008, score=1.397, ntokens=876.8, nsentences=80, sample_size=876.8, wps=107, ups=0.12, wpb=876.8, bsz=80, num_updates=4500, lr=3.68363e-06, gnorm=1.793, clip=100, loss_scale=64, train_wall=82, gb_free=6.8, wall=56567
2022-05-20 13:06:23 - train.py[line:436] - INFO: begin validation on "valid" subset
slice_id 0 seek offset 0
slice_id 0 seek offset 0
slice_id 1 seek offset 2500
slice_id 1 seek offset 2500
2022-05-20 13:46:40 - progress_bar.py[line:282] - INFO: epoch 001 | valid on 'valid' subset | loss -0.005 | score 1.291 | ntokens 109.97 | nsentences 10 | sample_size 109.97 | cider 1.382 | wps 113.7 | wpb 110 | bsz 10 | num_updates 4500 | best_cider 1.382
2022-05-20 13:46:40 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 1 @ 4500 updates
2022-05-20 13:46:40 - trainer.py[line:431] - INFO: Saving checkpoint to /database/jhkim/stage2_checkpoints//5e-6_2/checkpoint_1_4500.pt
2022-05-20 13:46:48 - trainer.py[line:441] - INFO: Finished saving checkpoint to /database/jhkim/stage2_checkpoints//5e-6_2/checkpoint_1_4500.pt
2022-05-20 13:48:33 - checkpoint_utils.py[line:135] - INFO: Saved checkpoint /database/jhkim/stage2_checkpoints//5e-6_2/checkpoint_1_4500.pt (epoch 1 @ 4500 updates, score 1.382) (writing took 113.47234263597056 seconds)
2022-05-20 13:49:54 - progress_bar.py[line:274] - INFO: epoch 001:   4517 / 7081 loss=-0.007, score=1.487, ntokens=880.7, nsentences=80, sample_size=880.7, wps=3.4, ups=0, wpb=880.7, bsz=80, num_updates=4510, lr=3.68003e-06, gnorm=1.767, clip=80, loss_scale=64, train_wall=81, gb_free=6.8, wall=59179
2022-05-20 13:51:15 - progress_bar.py[line:274] - INFO: epoch 001:   4527 / 7081 loss=-0.01, score=1.425, ntokens=872.6, nsentences=80, sample_size=872.6, wps=107.7, ups=0.12, wpb=872.6, bsz=80, num_updates=4520, lr=3.67642e-06, gnorm=1.336, clip=80, loss_scale=64, train_wall=81, gb_free=6.8, wall=59260
2022-05-20 13:52:37 - progress_bar.py[line:274] - INFO: epoch 001:   4537 / 7081 loss=-0.001, score=1.44, ntokens=873.7, nsentences=80, sample_size=873.7, wps=106.8, ups=0.12, wpb=873.7, bsz=80, num_updates=4530, lr=3.67282e-06, gnorm=1.737, clip=100, loss_scale=64, train_wall=82, gb_free=6.8, wall=59342
2022-05-20 13:53:59 - progress_bar.py[line:274] - INFO: epoch 001:   4547 / 7081 loss=-0.003, score=1.353, ntokens=871.9, nsentences=80, sample_size=871.9, wps=106.7, ups=0.12, wpb=871.9, bsz=80, num_updates=4540, lr=3.66921e-06, gnorm=1.574, clip=90, loss_scale=64, train_wall=82, gb_free=6.8, wall=59424
2022-05-20 13:55:21 - progress_bar.py[line:274] - INFO: epoch 001:   4557 / 7081 loss=-0.003, score=1.41, ntokens=886.8, nsentences=80, sample_size=886.8, wps=108.1, ups=0.12, wpb=886.8, bsz=80, num_updates=4550, lr=3.66561e-06, gnorm=1.226, clip=80, loss_scale=64, train_wall=82, gb_free=6.8, wall=59506
2022-05-20 13:56:43 - progress_bar.py[line:274] - INFO: epoch 001:   4567 / 7081 loss=-0.004, score=1.394, ntokens=885.4, nsentences=80, sample_size=885.4, wps=108.5, ups=0.12, wpb=885.4, bsz=80, num_updates=4560, lr=3.662e-06, gnorm=1.294, clip=70, loss_scale=64, train_wall=82, gb_free=6.8, wall=59587
2022-05-20 13:58:04 - progress_bar.py[line:274] - INFO: epoch 001:   4577 / 7081 loss=-0.005, score=1.569, ntokens=872.3, nsentences=80, sample_size=872.3, wps=107.2, ups=0.12, wpb=872.3, bsz=80, num_updates=4570, lr=3.65839e-06, gnorm=1.485, clip=80, loss_scale=64, train_wall=81, gb_free=6.8, wall=59669
2022-05-20 13:59:26 - progress_bar.py[line:274] - INFO: epoch 001:   4587 / 7081 loss=-0.006, score=1.498, ntokens=885.8, nsentences=80, sample_size=885.8, wps=108.3, ups=0.12, wpb=885.8, bsz=80, num_updates=4580, lr=3.65479e-06, gnorm=1.379, clip=80, loss_scale=64, train_wall=82, gb_free=6.8, wall=59750
2022-05-20 14:00:48 - progress_bar.py[line:274] - INFO: epoch 001:   4597 / 7081 loss=-0.004, score=1.312, ntokens=888.3, nsentences=80, sample_size=888.3, wps=108.4, ups=0.12, wpb=888.3, bsz=80, num_updates=4590, lr=3.65118e-06, gnorm=1.439, clip=80, loss_scale=64, train_wall=82, gb_free=6.8, wall=59832
2022-05-20 14:02:10 - progress_bar.py[line:274] - INFO: epoch 001:   4607 / 7081 loss=-0.005, score=1.416, ntokens=889.9, nsentences=80, sample_size=889.9, wps=108.5, ups=0.12, wpb=889.9, bsz=80, num_updates=4600, lr=3.64758e-06, gnorm=2.254, clip=90, loss_scale=64, train_wall=82, gb_free=6.8, wall=59914
2022-05-20 14:03:31 - progress_bar.py[line:274] - INFO: epoch 001:   4617 / 7081 loss=-0.008, score=1.376, ntokens=880.6, nsentences=80, sample_size=880.6, wps=108, ups=0.12, wpb=880.6, bsz=80, num_updates=4610, lr=3.64397e-06, gnorm=1.874, clip=80, loss_scale=64, train_wall=81, gb_free=6.8, wall=59996
2022-05-20 14:04:54 - progress_bar.py[line:274] - INFO: epoch 001:   4627 / 7081 loss=-0.006, score=1.512, ntokens=881.9, nsentences=80, sample_size=881.9, wps=107, ups=0.12, wpb=881.9, bsz=80, num_updates=4620, lr=3.64037e-06, gnorm=1.46, clip=90, loss_scale=64, train_wall=82, gb_free=6.8, wall=60078
2022-05-20 14:06:11 - progress_bar.py[line:274] - INFO: epoch 001:   4637 / 7081 loss=-0.007, score=1.41, ntokens=889.4, nsentences=80, sample_size=889.4, wps=114.7, ups=0.13, wpb=889.4, bsz=80, num_updates=4630, lr=3.63676e-06, gnorm=1.357, clip=70, loss_scale=64, train_wall=77, gb_free=6.8, wall=60156
2022-05-20 14:07:28 - progress_bar.py[line:274] - INFO: epoch 001:   4647 / 7081 loss=-0.001, score=1.341, ntokens=883.9, nsentences=80, sample_size=883.9, wps=114.9, ups=0.13, wpb=883.9, bsz=80, num_updates=4640, lr=3.63316e-06, gnorm=1.883, clip=100, loss_scale=64, train_wall=77, gb_free=6.8, wall=60233
2022-05-20 14:08:48 - progress_bar.py[line:274] - INFO: epoch 001:   4657 / 7081 loss=-0.006, score=1.507, ntokens=877.5, nsentences=80, sample_size=877.5, wps=110, ups=0.13, wpb=877.5, bsz=80, num_updates=4650, lr=3.62955e-06, gnorm=1.576, clip=60, loss_scale=64, train_wall=80, gb_free=6.8, wall=60313
2022-05-20 14:10:10 - progress_bar.py[line:274] - INFO: epoch 001:   4667 / 7081 loss=-0.003, score=1.49, ntokens=884.1, nsentences=80, sample_size=884.1, wps=108.1, ups=0.12, wpb=884.1, bsz=80, num_updates=4660, lr=3.62594e-06, gnorm=1.602, clip=90, loss_scale=64, train_wall=82, gb_free=6.8, wall=60394
2022-05-20 14:11:32 - progress_bar.py[line:274] - INFO: epoch 001:   4677 / 7081 loss=-0.007, score=1.477, ntokens=875.4, nsentences=80, sample_size=875.4, wps=107, ups=0.12, wpb=875.4, bsz=80, num_updates=4670, lr=3.62234e-06, gnorm=1.46, clip=80, loss_scale=64, train_wall=82, gb_free=6.7, wall=60476
2022-05-20 14:12:54 - progress_bar.py[line:274] - INFO: epoch 001:   4687 / 7081 loss=-0.006, score=1.359, ntokens=887.6, nsentences=80, sample_size=887.6, wps=108.2, ups=0.12, wpb=887.6, bsz=80, num_updates=4680, lr=3.61873e-06, gnorm=1.696, clip=70, loss_scale=64, train_wall=82, gb_free=6.8, wall=60558
2022-05-20 14:14:15 - progress_bar.py[line:274] - INFO: epoch 001:   4697 / 7081 loss=-0.007, score=1.426, ntokens=870.1, nsentences=80, sample_size=870.1, wps=107, ups=0.12, wpb=870.1, bsz=80, num_updates=4690, lr=3.61513e-06, gnorm=1.775, clip=90, loss_scale=64, train_wall=81, gb_free=6.8, wall=60640
2022-05-20 14:15:37 - progress_bar.py[line:274] - INFO: epoch 001:   4707 / 7081 loss=-0.007, score=1.614, ntokens=900.7, nsentences=80, sample_size=900.7, wps=109.2, ups=0.12, wpb=900.7, bsz=80, num_updates=4700, lr=3.61152e-06, gnorm=1.555, clip=100, loss_scale=64, train_wall=82, gb_free=6.8, wall=60722
2022-05-20 14:16:59 - progress_bar.py[line:274] - INFO: epoch 001:   4717 / 7081 loss=-0.004, score=1.496, ntokens=878.9, nsentences=80, sample_size=878.9, wps=107.1, ups=0.12, wpb=878.9, bsz=80, num_updates=4710, lr=3.60792e-06, gnorm=1.724, clip=80, loss_scale=64, train_wall=82, gb_free=6.8, wall=60804
2022-05-20 14:18:22 - progress_bar.py[line:274] - INFO: epoch 001:   4727 / 7081 loss=-0.008, score=1.399, ntokens=886.2, nsentences=80, sample_size=886.2, wps=107, ups=0.12, wpb=886.2, bsz=80, num_updates=4720, lr=3.60431e-06, gnorm=3.111, clip=100, loss_scale=64, train_wall=83, gb_free=6.8, wall=60887
2022-05-20 14:19:45 - progress_bar.py[line:274] - INFO: epoch 001:   4737 / 7081 loss=-0.005, score=1.471, ntokens=874.1, nsentences=80, sample_size=874.1, wps=105.8, ups=0.12, wpb=874.1, bsz=80, num_updates=4730, lr=3.60071e-06, gnorm=1.365, clip=90, loss_scale=64, train_wall=83, gb_free=6.7, wall=60970
2022-05-20 14:21:09 - progress_bar.py[line:274] - INFO: epoch 001:   4747 / 7081 loss=-0.007, score=1.415, ntokens=884, nsentences=80, sample_size=884, wps=105.1, ups=0.12, wpb=884, bsz=80, num_updates=4740, lr=3.5971e-06, gnorm=1.626, clip=90, loss_scale=128, train_wall=84, gb_free=6.8, wall=61054
2022-05-20 14:22:31 - progress_bar.py[line:274] - INFO: epoch 001:   4757 / 7081 loss=-0.005, score=1.439, ntokens=878.9, nsentences=80, sample_size=878.9, wps=107.2, ups=0.12, wpb=878.9, bsz=80, num_updates=4750, lr=3.5935e-06, gnorm=1.35, clip=80, loss_scale=128, train_wall=82, gb_free=6.8, wall=61136
2022-05-20 14:23:53 - progress_bar.py[line:274] - INFO: epoch 001:   4767 / 7081 loss=-0.007, score=1.454, ntokens=868.3, nsentences=80, sample_size=868.3, wps=106, ups=0.12, wpb=868.3, bsz=80, num_updates=4760, lr=3.58989e-06, gnorm=2.157, clip=100, loss_scale=128, train_wall=82, gb_free=6.8, wall=61218
2022-05-20 14:25:15 - progress_bar.py[line:274] - INFO: epoch 001:   4777 / 7081 loss=-0.008, score=1.499, ntokens=880.4, nsentences=80, sample_size=880.4, wps=106.8, ups=0.12, wpb=880.4, bsz=80, num_updates=4770, lr=3.58628e-06, gnorm=2.1, clip=90, loss_scale=128, train_wall=82, gb_free=6.8, wall=61300
2022-05-20 14:26:40 - progress_bar.py[line:274] - INFO: epoch 001:   4787 / 7081 loss=-0.007, score=1.416, ntokens=869.4, nsentences=80, sample_size=869.4, wps=103.1, ups=0.12, wpb=869.4, bsz=80, num_updates=4780, lr=3.58268e-06, gnorm=1.708, clip=100, loss_scale=128, train_wall=84, gb_free=6.8, wall=61384
2022-05-20 14:28:02 - progress_bar.py[line:274] - INFO: epoch 001:   4797 / 7081 loss=-0.002, score=1.486, ntokens=875.3, nsentences=80, sample_size=875.3, wps=106.6, ups=0.12, wpb=875.3, bsz=80, num_updates=4790, lr=3.57907e-06, gnorm=2.45, clip=100, loss_scale=128, train_wall=82, gb_free=6.7, wall=61466
2022-05-20 14:29:23 - progress_bar.py[line:274] - INFO: epoch 001:   4807 / 7081 loss=-0.005, score=1.397, ntokens=873.6, nsentences=80, sample_size=873.6, wps=107.6, ups=0.12, wpb=873.6, bsz=80, num_updates=4800, lr=3.57547e-06, gnorm=1.976, clip=100, loss_scale=128, train_wall=81, gb_free=6.8, wall=61548
2022-05-20 14:30:44 - progress_bar.py[line:274] - INFO: epoch 001:   4817 / 7081 loss=-0.005, score=1.411, ntokens=868.7, nsentences=80, sample_size=868.7, wps=106.9, ups=0.12, wpb=868.7, bsz=80, num_updates=4810, lr=3.57186e-06, gnorm=1.726, clip=90, loss_scale=128, train_wall=81, gb_free=6.8, wall=61629
2022-05-20 14:32:04 - progress_bar.py[line:274] - INFO: epoch 001:   4827 / 7081 loss=-0.004, score=1.465, ntokens=883, nsentences=80, sample_size=883, wps=110.7, ups=0.13, wpb=883, bsz=80, num_updates=4820, lr=3.56826e-06, gnorm=1.449, clip=80, loss_scale=128, train_wall=80, gb_free=6.7, wall=61709
2022-05-20 14:33:21 - progress_bar.py[line:274] - INFO: epoch 001:   4837 / 7081 loss=-0.004, score=1.474, ntokens=877.8, nsentences=80, sample_size=877.8, wps=114.4, ups=0.13, wpb=877.8, bsz=80, num_updates=4830, lr=3.56465e-06, gnorm=1.429, clip=80, loss_scale=128, train_wall=77, gb_free=6.8, wall=61785
2022-05-20 14:34:38 - progress_bar.py[line:274] - INFO: epoch 001:   4847 / 7081 loss=-0.007, score=1.558, ntokens=881.1, nsentences=80, sample_size=881.1, wps=114, ups=0.13, wpb=881.1, bsz=80, num_updates=4840, lr=3.56105e-06, gnorm=1.675, clip=100, loss_scale=128, train_wall=77, gb_free=6.8, wall=61863
2022-05-20 14:36:00 - progress_bar.py[line:274] - INFO: epoch 001:   4857 / 7081 loss=-0.007, score=1.543, ntokens=884.4, nsentences=80, sample_size=884.4, wps=108.5, ups=0.12, wpb=884.4, bsz=80, num_updates=4850, lr=3.55744e-06, gnorm=1.937, clip=80, loss_scale=128, train_wall=81, gb_free=6.8, wall=61944
2022-05-20 14:37:22 - progress_bar.py[line:274] - INFO: epoch 001:   4867 / 7081 loss=-0.003, score=1.462, ntokens=882.2, nsentences=80, sample_size=882.2, wps=107.5, ups=0.12, wpb=882.2, bsz=80, num_updates=4860, lr=3.55383e-06, gnorm=1.788, clip=100, loss_scale=128, train_wall=82, gb_free=6.8, wall=62026
2022-05-20 14:37:55 - trainer.py[line:922] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-05-20 14:38:52 - progress_bar.py[line:274] - INFO: epoch 001:   4878 / 7081 loss=-0.006, score=1.516, ntokens=889.2, nsentences=80, sample_size=889.2, wps=98.2, ups=0.11, wpb=889.2, bsz=80, num_updates=4870, lr=3.55023e-06, gnorm=1.676, clip=90, loss_scale=64, train_wall=90, gb_free=6.8, wall=62117
2022-05-20 14:40:14 - progress_bar.py[line:274] - INFO: epoch 001:   4888 / 7081 loss=-0.008, score=1.478, ntokens=886.5, nsentences=80, sample_size=886.5, wps=108.4, ups=0.12, wpb=886.5, bsz=80, num_updates=4880, lr=3.54662e-06, gnorm=1.559, clip=90, loss_scale=64, train_wall=82, gb_free=6.7, wall=62199
2022-05-20 14:41:37 - progress_bar.py[line:274] - INFO: epoch 001:   4898 / 7081 loss=-0.004, score=1.439, ntokens=880.5, nsentences=80, sample_size=880.5, wps=106.6, ups=0.12, wpb=880.5, bsz=80, num_updates=4890, lr=3.54302e-06, gnorm=1.836, clip=80, loss_scale=64, train_wall=83, gb_free=6.8, wall=62281
2022-05-20 14:42:59 - progress_bar.py[line:274] - INFO: epoch 001:   4908 / 7081 loss=-0.004, score=1.48, ntokens=875.4, nsentences=80, sample_size=875.4, wps=106.1, ups=0.12, wpb=875.4, bsz=80, num_updates=4900, lr=3.53941e-06, gnorm=1.435, clip=90, loss_scale=64, train_wall=82, gb_free=6.8, wall=62364
2022-05-20 14:44:21 - progress_bar.py[line:274] - INFO: epoch 001:   4918 / 7081 loss=-0.008, score=1.48, ntokens=885.6, nsentences=80, sample_size=885.6, wps=108.6, ups=0.12, wpb=885.6, bsz=80, num_updates=4910, lr=3.53581e-06, gnorm=1.432, clip=70, loss_scale=64, train_wall=81, gb_free=6.8, wall=62445
2022-05-20 14:45:43 - progress_bar.py[line:274] - INFO: epoch 001:   4928 / 7081 loss=-0.006, score=1.501, ntokens=895.6, nsentences=80, sample_size=895.6, wps=108, ups=0.12, wpb=895.6, bsz=80, num_updates=4920, lr=3.5322e-06, gnorm=1.954, clip=90, loss_scale=64, train_wall=83, gb_free=6.8, wall=62528
2022-05-20 14:47:05 - progress_bar.py[line:274] - INFO: epoch 001:   4938 / 7081 loss=-0.007, score=1.564, ntokens=870.5, nsentences=80, sample_size=870.5, wps=106.8, ups=0.12, wpb=870.5, bsz=80, num_updates=4930, lr=3.5286e-06, gnorm=1.869, clip=80, loss_scale=64, train_wall=81, gb_free=6.8, wall=62610
2022-05-20 14:48:27 - progress_bar.py[line:274] - INFO: epoch 001:   4948 / 7081 loss=-0.007, score=1.455, ntokens=895.4, nsentences=80, sample_size=895.4, wps=109.5, ups=0.12, wpb=895.4, bsz=80, num_updates=4940, lr=3.52499e-06, gnorm=1.695, clip=60, loss_scale=64, train_wall=82, gb_free=6.8, wall=62691
2022-05-20 14:49:49 - progress_bar.py[line:274] - INFO: epoch 001:   4958 / 7081 loss=-0.007, score=1.465, ntokens=885.3, nsentences=80, sample_size=885.3, wps=107.9, ups=0.12, wpb=885.3, bsz=80, num_updates=4950, lr=3.52139e-06, gnorm=1.806, clip=100, loss_scale=64, train_wall=82, gb_free=6.8, wall=62773
2022-05-20 14:51:11 - progress_bar.py[line:274] - INFO: epoch 001:   4968 / 7081 loss=-0.006, score=1.475, ntokens=895.3, nsentences=80, sample_size=895.3, wps=109.1, ups=0.12, wpb=895.3, bsz=80, num_updates=4960, lr=3.51778e-06, gnorm=1.575, clip=80, loss_scale=64, train_wall=82, gb_free=6.8, wall=62856
2022-05-20 14:52:33 - progress_bar.py[line:274] - INFO: epoch 001:   4978 / 7081 loss=-0.007, score=1.436, ntokens=878.8, nsentences=80, sample_size=878.8, wps=107.2, ups=0.12, wpb=878.8, bsz=80, num_updates=4970, lr=3.51417e-06, gnorm=1.586, clip=100, loss_scale=64, train_wall=82, gb_free=6.8, wall=62938
2022-05-20 14:53:55 - progress_bar.py[line:274] - INFO: epoch 001:   4988 / 7081 loss=-0.005, score=1.489, ntokens=890.7, nsentences=80, sample_size=890.7, wps=108.5, ups=0.12, wpb=890.7, bsz=80, num_updates=4980, lr=3.51057e-06, gnorm=1.914, clip=80, loss_scale=64, train_wall=82, gb_free=6.8, wall=63020
2022-05-20 14:55:17 - progress_bar.py[line:274] - INFO: epoch 001:   4998 / 7081 loss=-0.008, score=1.478, ntokens=871, nsentences=80, sample_size=871, wps=106.3, ups=0.12, wpb=871, bsz=80, num_updates=4990, lr=3.50696e-06, gnorm=1.635, clip=80, loss_scale=64, train_wall=82, gb_free=6.8, wall=63102
2022-05-20 14:56:39 - progress_bar.py[line:274] - INFO: epoch 001:   5008 / 7081 loss=-0.004, score=1.383, ntokens=887.2, nsentences=80, sample_size=887.2, wps=108.1, ups=0.12, wpb=887.2, bsz=80, num_updates=5000, lr=3.50336e-06, gnorm=1.314, clip=80, loss_scale=64, train_wall=82, gb_free=6.8, wall=63184
2022-05-20 14:56:39 - train.py[line:436] - INFO: begin validation on "valid" subset
slice_id 0 seek offset 0
slice_id 0 seek offset 0
slice_id 1 seek offset 2500
slice_id 1 seek offset 2500
2022-05-20 15:37:07 - progress_bar.py[line:282] - INFO: epoch 001 | valid on 'valid' subset | loss -0.005 | score 1.293 | ntokens 110.152 | nsentences 10 | sample_size 110.152 | cider 1.385 | wps 113.4 | wpb 110.2 | bsz 10 | num_updates 5000 | best_cider 1.385
2022-05-20 15:37:07 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 1 @ 5000 updates
2022-05-20 15:37:07 - trainer.py[line:431] - INFO: Saving checkpoint to /database/jhkim/stage2_checkpoints//5e-6_2/checkpoint_1_5000.pt
2022-05-20 15:37:16 - trainer.py[line:441] - INFO: Finished saving checkpoint to /database/jhkim/stage2_checkpoints//5e-6_2/checkpoint_1_5000.pt
2022-05-20 15:38:36 - checkpoint_utils.py[line:135] - INFO: Saved checkpoint /database/jhkim/stage2_checkpoints//5e-6_2/checkpoint_1_5000.pt (epoch 1 @ 5000 updates, score 1.385) (writing took 88.72119053080678 seconds)
2022-05-20 15:39:58 - progress_bar.py[line:274] - INFO: epoch 001:   5018 / 7081 loss=-0.007, score=1.321, ntokens=879.5, nsentences=80, sample_size=879.5, wps=3.4, ups=0, wpb=879.5, bsz=80, num_updates=5010, lr=3.49975e-06, gnorm=1.279, clip=80, loss_scale=64, train_wall=82, gb_free=6.8, wall=65783
2022-05-20 15:41:21 - progress_bar.py[line:274] - INFO: epoch 001:   5028 / 7081 loss=-0.008, score=1.511, ntokens=873.6, nsentences=80, sample_size=873.6, wps=105.9, ups=0.12, wpb=873.6, bsz=80, num_updates=5020, lr=3.49615e-06, gnorm=1.803, clip=90, loss_scale=64, train_wall=82, gb_free=6.8, wall=65866
2022-05-20 15:42:43 - progress_bar.py[line:274] - INFO: epoch 001:   5038 / 7081 loss=-0.004, score=1.498, ntokens=887.2, nsentences=80, sample_size=887.2, wps=108.2, ups=0.12, wpb=887.2, bsz=80, num_updates=5030, lr=3.49254e-06, gnorm=1.738, clip=90, loss_scale=64, train_wall=82, gb_free=6.7, wall=65948
2022-05-20 15:44:05 - progress_bar.py[line:274] - INFO: epoch 001:   5048 / 7081 loss=-0.006, score=1.418, ntokens=874.8, nsentences=80, sample_size=874.8, wps=106.6, ups=0.12, wpb=874.8, bsz=80, num_updates=5040, lr=3.48894e-06, gnorm=1.481, clip=80, loss_scale=64, train_wall=82, gb_free=6.8, wall=66030
2022-05-20 15:45:27 - progress_bar.py[line:274] - INFO: epoch 001:   5058 / 7081 loss=-0.008, score=1.473, ntokens=898.7, nsentences=80, sample_size=898.7, wps=109.1, ups=0.12, wpb=898.7, bsz=80, num_updates=5050, lr=3.48533e-06, gnorm=2.743, clip=90, loss_scale=64, train_wall=82, gb_free=6.8, wall=66112
2022-05-20 15:46:49 - progress_bar.py[line:274] - INFO: epoch 001:   5068 / 7081 loss=-0.009, score=1.456, ntokens=864.5, nsentences=80, sample_size=864.5, wps=106.5, ups=0.12, wpb=864.5, bsz=80, num_updates=5060, lr=3.48172e-06, gnorm=1.843, clip=90, loss_scale=64, train_wall=81, gb_free=6.8, wall=66193
2022-05-20 15:48:10 - progress_bar.py[line:274] - INFO: epoch 001:   5078 / 7081 loss=-0.006, score=1.516, ntokens=876.6, nsentences=80, sample_size=876.6, wps=107.2, ups=0.12, wpb=876.6, bsz=80, num_updates=5070, lr=3.47812e-06, gnorm=1.823, clip=80, loss_scale=64, train_wall=82, gb_free=6.8, wall=66275
2022-05-20 15:49:32 - progress_bar.py[line:274] - INFO: epoch 001:   5088 / 7081 loss=-0.003, score=1.313, ntokens=887.1, nsentences=80, sample_size=887.1, wps=108.4, ups=0.12, wpb=887.1, bsz=80, num_updates=5080, lr=3.47451e-06, gnorm=1.67, clip=80, loss_scale=64, train_wall=82, gb_free=6.8, wall=66357
2022-05-20 15:50:54 - progress_bar.py[line:274] - INFO: epoch 001:   5098 / 7081 loss=-0.004, score=1.331, ntokens=874.4, nsentences=80, sample_size=874.4, wps=107, ups=0.12, wpb=874.4, bsz=80, num_updates=5090, lr=3.47091e-06, gnorm=1.521, clip=80, loss_scale=64, train_wall=82, gb_free=6.8, wall=66439
2022-05-20 15:52:13 - progress_bar.py[line:274] - INFO: epoch 001:   5108 / 7081 loss=-0.005, score=1.45, ntokens=873, nsentences=80, sample_size=873, wps=110.1, ups=0.13, wpb=873, bsz=80, num_updates=5100, lr=3.4673e-06, gnorm=1.52, clip=80, loss_scale=64, train_wall=79, gb_free=6.8, wall=66518
2022-05-20 15:53:31 - progress_bar.py[line:274] - INFO: epoch 001:   5118 / 7081 loss=-0.006, score=1.425, ntokens=880.5, nsentences=80, sample_size=880.5, wps=113.5, ups=0.13, wpb=880.5, bsz=80, num_updates=5110, lr=3.4637e-06, gnorm=1.364, clip=70, loss_scale=64, train_wall=77, gb_free=6.8, wall=66595
2022-05-20 15:54:49 - progress_bar.py[line:274] - INFO: epoch 001:   5128 / 7081 loss=-0.005, score=1.555, ntokens=893.3, nsentences=80, sample_size=893.3, wps=114.2, ups=0.13, wpb=893.3, bsz=80, num_updates=5120, lr=3.46009e-06, gnorm=1.85, clip=90, loss_scale=64, train_wall=78, gb_free=6.8, wall=66674
2022-05-20 15:56:11 - progress_bar.py[line:274] - INFO: epoch 001:   5138 / 7081 loss=-0.003, score=1.492, ntokens=877.2, nsentences=80, sample_size=877.2, wps=106.4, ups=0.12, wpb=877.2, bsz=80, num_updates=5130, lr=3.45649e-06, gnorm=1.7, clip=80, loss_scale=64, train_wall=82, gb_free=6.8, wall=66756
2022-05-20 15:57:34 - progress_bar.py[line:274] - INFO: epoch 001:   5148 / 7081 loss=-0.007, score=1.463, ntokens=884.6, nsentences=80, sample_size=884.6, wps=107.7, ups=0.12, wpb=884.6, bsz=80, num_updates=5140, lr=3.45288e-06, gnorm=1.57, clip=80, loss_scale=64, train_wall=82, gb_free=6.8, wall=66838
2022-05-20 15:58:57 - progress_bar.py[line:274] - INFO: epoch 001:   5158 / 7081 loss=-0.005, score=1.336, ntokens=878, nsentences=80, sample_size=878, wps=105.9, ups=0.12, wpb=878, bsz=80, num_updates=5150, lr=3.44928e-06, gnorm=1.544, clip=90, loss_scale=64, train_wall=83, gb_free=6.8, wall=66921
2022-05-20 16:00:18 - progress_bar.py[line:274] - INFO: epoch 001:   5168 / 7081 loss=-0.008, score=1.49, ntokens=861.1, nsentences=80, sample_size=861.1, wps=105.2, ups=0.12, wpb=861.1, bsz=80, num_updates=5160, lr=3.44567e-06, gnorm=2.002, clip=100, loss_scale=64, train_wall=82, gb_free=6.8, wall=67003
2022-05-20 16:01:41 - progress_bar.py[line:274] - INFO: epoch 001:   5178 / 7081 loss=-0.002, score=1.427, ntokens=882.7, nsentences=80, sample_size=882.7, wps=106.7, ups=0.12, wpb=882.7, bsz=80, num_updates=5170, lr=3.44206e-06, gnorm=2.069, clip=90, loss_scale=64, train_wall=83, gb_free=6.8, wall=67086
2022-05-20 16:03:03 - progress_bar.py[line:274] - INFO: epoch 001:   5188 / 7081 loss=-0.007, score=1.526, ntokens=860.8, nsentences=80, sample_size=860.8, wps=105.7, ups=0.12, wpb=860.8, bsz=80, num_updates=5180, lr=3.43846e-06, gnorm=1.952, clip=80, loss_scale=64, train_wall=81, gb_free=6.8, wall=67167
2022-05-20 16:04:24 - progress_bar.py[line:274] - INFO: epoch 001:   5198 / 7081 loss=-0.006, score=1.583, ntokens=868.2, nsentences=80, sample_size=868.2, wps=106, ups=0.12, wpb=868.2, bsz=80, num_updates=5190, lr=3.43485e-06, gnorm=2.055, clip=80, loss_scale=64, train_wall=82, gb_free=6.8, wall=67249
2022-05-20 16:05:46 - progress_bar.py[line:274] - INFO: epoch 001:   5208 / 7081 loss=-0.006, score=1.418, ntokens=883.8, nsentences=80, sample_size=883.8, wps=107.7, ups=0.12, wpb=883.8, bsz=80, num_updates=5200, lr=3.43125e-06, gnorm=1.696, clip=90, loss_scale=64, train_wall=82, gb_free=6.8, wall=67331
2022-05-20 16:07:08 - progress_bar.py[line:274] - INFO: epoch 001:   5218 / 7081 loss=-0.009, score=1.451, ntokens=876, nsentences=80, sample_size=876, wps=107.1, ups=0.12, wpb=876, bsz=80, num_updates=5210, lr=3.42764e-06, gnorm=1.431, clip=80, loss_scale=64, train_wall=82, gb_free=6.8, wall=67413
2022-05-20 16:08:30 - progress_bar.py[line:274] - INFO: epoch 001:   5228 / 7081 loss=-0.001, score=1.433, ntokens=879.9, nsentences=80, sample_size=879.9, wps=107.7, ups=0.12, wpb=879.9, bsz=80, num_updates=5220, lr=3.42404e-06, gnorm=1.816, clip=90, loss_scale=64, train_wall=82, gb_free=6.8, wall=67495
2022-05-20 16:09:52 - progress_bar.py[line:274] - INFO: epoch 001:   5238 / 7081 loss=-0.005, score=1.494, ntokens=874.1, nsentences=80, sample_size=874.1, wps=106.8, ups=0.12, wpb=874.1, bsz=80, num_updates=5230, lr=3.42043e-06, gnorm=1.887, clip=100, loss_scale=64, train_wall=82, gb_free=6.8, wall=67577
2022-05-20 16:11:13 - progress_bar.py[line:274] - INFO: epoch 001:   5248 / 7081 loss=-0.007, score=1.425, ntokens=872.2, nsentences=80, sample_size=872.2, wps=107.1, ups=0.12, wpb=872.2, bsz=80, num_updates=5240, lr=3.41683e-06, gnorm=2.17, clip=90, loss_scale=64, train_wall=81, gb_free=6.8, wall=67658
2022-05-20 16:12:35 - progress_bar.py[line:274] - INFO: epoch 001:   5258 / 7081 loss=-0.005, score=1.4, ntokens=880.4, nsentences=80, sample_size=880.4, wps=107.4, ups=0.12, wpb=880.4, bsz=80, num_updates=5250, lr=3.41322e-06, gnorm=1.492, clip=80, loss_scale=64, train_wall=82, gb_free=6.8, wall=67740
2022-05-20 16:13:58 - progress_bar.py[line:274] - INFO: epoch 001:   5268 / 7081 loss=-0.005, score=1.532, ntokens=881.9, nsentences=80, sample_size=881.9, wps=107.2, ups=0.12, wpb=881.9, bsz=80, num_updates=5260, lr=3.40961e-06, gnorm=1.439, clip=80, loss_scale=64, train_wall=82, gb_free=6.8, wall=67822
2022-05-20 16:15:19 - progress_bar.py[line:274] - INFO: epoch 001:   5278 / 7081 loss=-0.007, score=1.49, ntokens=881.7, nsentences=80, sample_size=881.7, wps=108.7, ups=0.12, wpb=881.7, bsz=80, num_updates=5270, lr=3.40601e-06, gnorm=1.751, clip=80, loss_scale=64, train_wall=81, gb_free=6.8, wall=67903
2022-05-20 16:16:40 - progress_bar.py[line:274] - INFO: epoch 001:   5288 / 7081 loss=-0.004, score=1.453, ntokens=868, nsentences=80, sample_size=868, wps=106.3, ups=0.12, wpb=868, bsz=80, num_updates=5280, lr=3.4024e-06, gnorm=2.029, clip=80, loss_scale=64, train_wall=82, gb_free=6.8, wall=67985
2022-05-20 16:18:02 - progress_bar.py[line:274] - INFO: epoch 001:   5298 / 7081 loss=-0.001, score=1.413, ntokens=883.9, nsentences=80, sample_size=883.9, wps=108.2, ups=0.12, wpb=883.9, bsz=80, num_updates=5290, lr=3.3988e-06, gnorm=1.573, clip=80, loss_scale=64, train_wall=82, gb_free=6.8, wall=68067
2022-05-20 16:19:20 - progress_bar.py[line:274] - INFO: epoch 001:   5308 / 7081 loss=-0.004, score=1.5, ntokens=891.7, nsentences=80, sample_size=891.7, wps=114.4, ups=0.13, wpb=891.7, bsz=80, num_updates=5300, lr=3.39519e-06, gnorm=1.885, clip=90, loss_scale=64, train_wall=78, gb_free=6.8, wall=68145
2022-05-20 16:20:37 - progress_bar.py[line:274] - INFO: epoch 001:   5318 / 7081 loss=-0.005, score=1.364, ntokens=881.5, nsentences=80, sample_size=881.5, wps=114.2, ups=0.13, wpb=881.5, bsz=80, num_updates=5310, lr=3.39159e-06, gnorm=1.787, clip=100, loss_scale=64, train_wall=77, gb_free=6.8, wall=68222
2022-05-20 16:21:57 - progress_bar.py[line:274] - INFO: epoch 001:   5328 / 7081 loss=-0.005, score=1.505, ntokens=877.2, nsentences=80, sample_size=877.2, wps=110.6, ups=0.13, wpb=877.2, bsz=80, num_updates=5320, lr=3.38798e-06, gnorm=2.153, clip=100, loss_scale=64, train_wall=79, gb_free=6.8, wall=68301
2022-05-20 16:23:19 - progress_bar.py[line:274] - INFO: epoch 001:   5338 / 7081 loss=-0.002, score=1.401, ntokens=886.2, nsentences=80, sample_size=886.2, wps=107.4, ups=0.12, wpb=886.2, bsz=80, num_updates=5330, lr=3.38438e-06, gnorm=1.73, clip=90, loss_scale=64, train_wall=82, gb_free=6.8, wall=68384
2022-05-20 16:24:41 - progress_bar.py[line:274] - INFO: epoch 001:   5348 / 7081 loss=-0.008, score=1.433, ntokens=875.3, nsentences=80, sample_size=875.3, wps=106.3, ups=0.12, wpb=875.3, bsz=80, num_updates=5340, lr=3.38077e-06, gnorm=1.806, clip=100, loss_scale=64, train_wall=82, gb_free=6.8, wall=68466
2022-05-20 16:26:04 - progress_bar.py[line:274] - INFO: epoch 001:   5358 / 7081 loss=-0.007, score=1.419, ntokens=879.6, nsentences=80, sample_size=879.6, wps=106.6, ups=0.12, wpb=879.6, bsz=80, num_updates=5350, lr=3.37717e-06, gnorm=2.832, clip=100, loss_scale=64, train_wall=82, gb_free=6.8, wall=68549
2022-05-20 16:27:27 - progress_bar.py[line:274] - INFO: epoch 001:   5368 / 7081 loss=-0.003, score=1.431, ntokens=884.2, nsentences=80, sample_size=884.2, wps=106.7, ups=0.12, wpb=884.2, bsz=80, num_updates=5360, lr=3.37356e-06, gnorm=1.679, clip=70, loss_scale=64, train_wall=83, gb_free=6.8, wall=68632
2022-05-20 16:28:49 - progress_bar.py[line:274] - INFO: epoch 001:   5378 / 7081 loss=-0.007, score=1.491, ntokens=882.2, nsentences=80, sample_size=882.2, wps=107.2, ups=0.12, wpb=882.2, bsz=80, num_updates=5370, lr=3.36995e-06, gnorm=1.622, clip=80, loss_scale=64, train_wall=82, gb_free=6.8, wall=68714
2022-05-20 16:30:12 - progress_bar.py[line:274] - INFO: epoch 001:   5388 / 7081 loss=-0.005, score=1.482, ntokens=892.6, nsentences=80, sample_size=892.6, wps=108.1, ups=0.12, wpb=892.6, bsz=80, num_updates=5380, lr=3.36635e-06, gnorm=1.817, clip=90, loss_scale=128, train_wall=82, gb_free=6.7, wall=68796
2022-05-20 16:31:33 - progress_bar.py[line:274] - INFO: epoch 001:   5398 / 7081 loss=-0.002, score=1.562, ntokens=869.5, nsentences=80, sample_size=869.5, wps=107, ups=0.12, wpb=869.5, bsz=80, num_updates=5390, lr=3.36274e-06, gnorm=1.896, clip=90, loss_scale=128, train_wall=81, gb_free=6.7, wall=68878
2022-05-20 16:32:56 - progress_bar.py[line:274] - INFO: epoch 001:   5408 / 7081 loss=-0.005, score=1.478, ntokens=877.1, nsentences=80, sample_size=877.1, wps=106.3, ups=0.12, wpb=877.1, bsz=80, num_updates=5400, lr=3.35914e-06, gnorm=1.85, clip=80, loss_scale=128, train_wall=82, gb_free=6.8, wall=68960
2022-05-20 16:34:17 - progress_bar.py[line:274] - INFO: epoch 001:   5418 / 7081 loss=-0.007, score=1.513, ntokens=885.3, nsentences=80, sample_size=885.3, wps=108.1, ups=0.12, wpb=885.3, bsz=80, num_updates=5410, lr=3.35553e-06, gnorm=2.412, clip=90, loss_scale=128, train_wall=82, gb_free=6.8, wall=69042
2022-05-20 16:35:40 - progress_bar.py[line:274] - INFO: epoch 001:   5428 / 7081 loss=-0.005, score=1.479, ntokens=894.9, nsentences=80, sample_size=894.9, wps=109, ups=0.12, wpb=894.9, bsz=80, num_updates=5420, lr=3.35193e-06, gnorm=1.384, clip=80, loss_scale=128, train_wall=82, gb_free=6.8, wall=69124
2022-05-20 16:37:01 - progress_bar.py[line:274] - INFO: epoch 001:   5438 / 7081 loss=-0.004, score=1.434, ntokens=875.9, nsentences=80, sample_size=875.9, wps=107.1, ups=0.12, wpb=875.9, bsz=80, num_updates=5430, lr=3.34832e-06, gnorm=1.663, clip=60, loss_scale=128, train_wall=82, gb_free=6.8, wall=69206
2022-05-20 16:38:23 - progress_bar.py[line:274] - INFO: epoch 001:   5448 / 7081 loss=-0.004, score=1.577, ntokens=896.2, nsentences=80, sample_size=896.2, wps=109.1, ups=0.12, wpb=896.2, bsz=80, num_updates=5440, lr=3.34472e-06, gnorm=2.254, clip=90, loss_scale=128, train_wall=82, gb_free=6.8, wall=69288
2022-05-20 16:39:45 - progress_bar.py[line:274] - INFO: epoch 001:   5458 / 7081 loss=-0.005, score=1.435, ntokens=883.5, nsentences=80, sample_size=883.5, wps=107.8, ups=0.12, wpb=883.5, bsz=80, num_updates=5450, lr=3.34111e-06, gnorm=1.415, clip=100, loss_scale=128, train_wall=82, gb_free=6.8, wall=69370
2022-05-20 16:41:07 - progress_bar.py[line:274] - INFO: epoch 001:   5468 / 7081 loss=-0.007, score=1.453, ntokens=881.2, nsentences=80, sample_size=881.2, wps=107.5, ups=0.12, wpb=881.2, bsz=80, num_updates=5460, lr=3.3375e-06, gnorm=1.55, clip=80, loss_scale=128, train_wall=82, gb_free=6.8, wall=69452
2022-05-20 16:42:30 - progress_bar.py[line:274] - INFO: epoch 001:   5478 / 7081 loss=-0.004, score=1.424, ntokens=892.5, nsentences=80, sample_size=892.5, wps=108.5, ups=0.12, wpb=892.5, bsz=80, num_updates=5470, lr=3.3339e-06, gnorm=1.425, clip=100, loss_scale=128, train_wall=82, gb_free=6.8, wall=69534
2022-05-20 16:43:52 - progress_bar.py[line:274] - INFO: epoch 001:   5488 / 7081 loss=-0.004, score=1.413, ntokens=875.8, nsentences=80, sample_size=875.8, wps=106.3, ups=0.12, wpb=875.8, bsz=80, num_updates=5480, lr=3.33029e-06, gnorm=1.337, clip=80, loss_scale=128, train_wall=82, gb_free=6.8, wall=69617
2022-05-20 16:45:12 - progress_bar.py[line:274] - INFO: epoch 001:   5498 / 7081 loss=-0.004, score=1.424, ntokens=896.6, nsentences=80, sample_size=896.6, wps=111.8, ups=0.12, wpb=896.6, bsz=80, num_updates=5490, lr=3.32669e-06, gnorm=1.462, clip=80, loss_scale=128, train_wall=80, gb_free=6.8, wall=69697
2022-05-20 16:46:29 - progress_bar.py[line:274] - INFO: epoch 001:   5508 / 7081 loss=-0.005, score=1.447, ntokens=886.8, nsentences=80, sample_size=886.8, wps=114.9, ups=0.13, wpb=886.8, bsz=80, num_updates=5500, lr=3.32308e-06, gnorm=1.651, clip=90, loss_scale=128, train_wall=77, gb_free=6.8, wall=69774
2022-05-20 16:46:29 - train.py[line:436] - INFO: begin validation on "valid" subset
slice_id 0 seek offset 0
slice_id 0 seek offset 0
slice_id 1 seek offset 2500
slice_id 1 seek offset 2500
2022-05-20 17:27:44 - progress_bar.py[line:282] - INFO: epoch 001 | valid on 'valid' subset | loss -0.005 | score 1.297 | ntokens 110.879 | nsentences 10 | sample_size 110.879 | cider 1.387 | wps 112 | wpb 110.9 | bsz 10 | num_updates 5500 | best_cider 1.387
2022-05-20 17:27:44 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 1 @ 5500 updates
2022-05-20 17:27:44 - trainer.py[line:431] - INFO: Saving checkpoint to /database/jhkim/stage2_checkpoints//5e-6_2/checkpoint_1_5500.pt
2022-05-20 17:27:52 - trainer.py[line:441] - INFO: Finished saving checkpoint to /database/jhkim/stage2_checkpoints//5e-6_2/checkpoint_1_5500.pt
2022-05-20 17:29:14 - checkpoint_utils.py[line:135] - INFO: Saved checkpoint /database/jhkim/stage2_checkpoints//5e-6_2/checkpoint_1_5500.pt (epoch 1 @ 5500 updates, score 1.387) (writing took 89.57854515686631 seconds)
2022-05-20 17:30:35 - progress_bar.py[line:274] - INFO: epoch 001:   5518 / 7081 loss=-0.006, score=1.495, ntokens=893.7, nsentences=80, sample_size=893.7, wps=3.4, ups=0, wpb=893.7, bsz=80, num_updates=5510, lr=3.31948e-06, gnorm=1.383, clip=80, loss_scale=128, train_wall=81, gb_free=6.8, wall=72420
2022-05-20 17:31:57 - progress_bar.py[line:274] - INFO: epoch 001:   5528 / 7081 loss=-0.005, score=1.404, ntokens=882.5, nsentences=80, sample_size=882.5, wps=108.2, ups=0.12, wpb=882.5, bsz=80, num_updates=5520, lr=3.31587e-06, gnorm=1.349, clip=70, loss_scale=128, train_wall=81, gb_free=6.8, wall=72501
2022-05-20 17:33:18 - progress_bar.py[line:274] - INFO: epoch 001:   5538 / 7081 loss=-0.009, score=1.536, ntokens=887, nsentences=80, sample_size=887, wps=109.6, ups=0.12, wpb=887, bsz=80, num_updates=5530, lr=3.31227e-06, gnorm=1.527, clip=90, loss_scale=128, train_wall=81, gb_free=6.8, wall=72582
2022-05-20 17:34:38 - progress_bar.py[line:274] - INFO: epoch 001:   5548 / 7081 loss=-0.003, score=1.41, ntokens=890.1, nsentences=80, sample_size=890.1, wps=110.3, ups=0.12, wpb=890.1, bsz=80, num_updates=5540, lr=3.30866e-06, gnorm=1.532, clip=90, loss_scale=128, train_wall=81, gb_free=6.8, wall=72663
2022-05-20 17:36:00 - progress_bar.py[line:274] - INFO: epoch 001:   5558 / 7081 loss=-0.008, score=1.44, ntokens=890.5, nsentences=80, sample_size=890.5, wps=109.2, ups=0.12, wpb=890.5, bsz=80, num_updates=5550, lr=3.30506e-06, gnorm=1.606, clip=100, loss_scale=128, train_wall=81, gb_free=6.8, wall=72744
2022-05-20 17:37:22 - progress_bar.py[line:274] - INFO: epoch 001:   5568 / 7081 loss=-0.006, score=1.399, ntokens=900.4, nsentences=80, sample_size=900.4, wps=110.1, ups=0.12, wpb=900.4, bsz=80, num_updates=5560, lr=3.30145e-06, gnorm=1.253, clip=80, loss_scale=128, train_wall=82, gb_free=6.8, wall=72826
2022-05-20 17:38:39 - progress_bar.py[line:274] - INFO: epoch 001:   5578 / 7081 loss=-0.004, score=1.489, ntokens=886, nsentences=80, sample_size=886, wps=113.9, ups=0.13, wpb=886, bsz=80, num_updates=5570, lr=3.29784e-06, gnorm=1.097, clip=60, loss_scale=128, train_wall=78, gb_free=6.8, wall=72904
2022-05-20 17:39:56 - progress_bar.py[line:274] - INFO: epoch 001:   5588 / 7081 loss=-0.005, score=1.496, ntokens=886.9, nsentences=80, sample_size=886.9, wps=116.3, ups=0.13, wpb=886.9, bsz=80, num_updates=5580, lr=3.29424e-06, gnorm=1.646, clip=90, loss_scale=128, train_wall=76, gb_free=6.8, wall=72980
2022-05-20 17:41:15 - progress_bar.py[line:274] - INFO: epoch 001:   5598 / 7081 loss=-0.011, score=1.457, ntokens=890.2, nsentences=80, sample_size=890.2, wps=111.6, ups=0.13, wpb=890.2, bsz=80, num_updates=5590, lr=3.29063e-06, gnorm=2.13, clip=70, loss_scale=128, train_wall=80, gb_free=6.8, wall=73060
2022-05-20 17:42:36 - progress_bar.py[line:274] - INFO: epoch 001:   5608 / 7081 loss=-0.008, score=1.464, ntokens=875.1, nsentences=80, sample_size=875.1, wps=108.1, ups=0.12, wpb=875.1, bsz=80, num_updates=5600, lr=3.28703e-06, gnorm=2.203, clip=100, loss_scale=128, train_wall=81, gb_free=6.8, wall=73141
2022-05-20 17:43:58 - progress_bar.py[line:274] - INFO: epoch 001:   5618 / 7081 loss=-0.003, score=1.463, ntokens=888.1, nsentences=80, sample_size=888.1, wps=109.3, ups=0.12, wpb=888.1, bsz=80, num_updates=5610, lr=3.28342e-06, gnorm=1.323, clip=70, loss_scale=128, train_wall=81, gb_free=6.8, wall=73222
2022-05-20 17:45:18 - progress_bar.py[line:274] - INFO: epoch 001:   5628 / 7081 loss=-0.005, score=1.492, ntokens=882.1, nsentences=80, sample_size=882.1, wps=109.4, ups=0.12, wpb=882.1, bsz=80, num_updates=5620, lr=3.27982e-06, gnorm=1.378, clip=80, loss_scale=128, train_wall=81, gb_free=6.8, wall=73303
2022-05-20 17:46:39 - progress_bar.py[line:274] - INFO: epoch 001:   5638 / 7081 loss=-0.008, score=1.426, ntokens=883, nsentences=80, sample_size=883, wps=109.3, ups=0.12, wpb=883, bsz=80, num_updates=5630, lr=3.27621e-06, gnorm=1.674, clip=80, loss_scale=128, train_wall=81, gb_free=6.8, wall=73384
2022-05-20 17:48:00 - progress_bar.py[line:274] - INFO: epoch 001:   5648 / 7081 loss=-0.006, score=1.389, ntokens=873.3, nsentences=80, sample_size=873.3, wps=107.6, ups=0.12, wpb=873.3, bsz=80, num_updates=5640, lr=3.27261e-06, gnorm=1.676, clip=80, loss_scale=128, train_wall=81, gb_free=6.8, wall=73465
2022-05-20 17:49:22 - progress_bar.py[line:274] - INFO: epoch 001:   5658 / 7081 loss=-0.009, score=1.561, ntokens=894.2, nsentences=80, sample_size=894.2, wps=109.9, ups=0.12, wpb=894.2, bsz=80, num_updates=5650, lr=3.269e-06, gnorm=1.683, clip=90, loss_scale=128, train_wall=81, gb_free=6.8, wall=73546
2022-05-20 17:50:43 - progress_bar.py[line:274] - INFO: epoch 001:   5668 / 7081 loss=-0.006, score=1.418, ntokens=881.7, nsentences=80, sample_size=881.7, wps=108.7, ups=0.12, wpb=881.7, bsz=80, num_updates=5660, lr=3.26539e-06, gnorm=1.642, clip=100, loss_scale=128, train_wall=81, gb_free=6.8, wall=73627
2022-05-20 17:52:04 - progress_bar.py[line:274] - INFO: epoch 001:   5678 / 7081 loss=-0.008, score=1.513, ntokens=886, nsentences=80, sample_size=886, wps=109.3, ups=0.12, wpb=886, bsz=80, num_updates=5670, lr=3.26179e-06, gnorm=1.325, clip=80, loss_scale=128, train_wall=81, gb_free=6.8, wall=73708
2022-05-20 17:53:24 - progress_bar.py[line:274] - INFO: epoch 001:   5688 / 7081 loss=-0.007, score=1.44, ntokens=881.6, nsentences=80, sample_size=881.6, wps=109.5, ups=0.12, wpb=881.6, bsz=80, num_updates=5680, lr=3.25818e-06, gnorm=1.194, clip=70, loss_scale=128, train_wall=80, gb_free=6.8, wall=73789
2022-05-20 17:54:45 - progress_bar.py[line:274] - INFO: epoch 001:   5698 / 7081 loss=-0.004, score=1.384, ntokens=893.5, nsentences=80, sample_size=893.5, wps=110.5, ups=0.12, wpb=893.5, bsz=80, num_updates=5690, lr=3.25458e-06, gnorm=1.2, clip=80, loss_scale=128, train_wall=81, gb_free=6.8, wall=73870
2022-05-20 17:56:06 - progress_bar.py[line:274] - INFO: epoch 001:   5708 / 7081 loss=-0.006, score=1.435, ntokens=892.3, nsentences=80, sample_size=892.3, wps=110, ups=0.12, wpb=892.3, bsz=80, num_updates=5700, lr=3.25097e-06, gnorm=1.854, clip=90, loss_scale=128, train_wall=81, gb_free=6.8, wall=73951
2022-05-20 17:57:27 - progress_bar.py[line:274] - INFO: epoch 001:   5718 / 7081 loss=-0.006, score=1.452, ntokens=885.9, nsentences=80, sample_size=885.9, wps=109.8, ups=0.12, wpb=885.9, bsz=80, num_updates=5710, lr=3.24737e-06, gnorm=1.484, clip=80, loss_scale=128, train_wall=81, gb_free=6.8, wall=74032
2022-05-20 17:58:48 - progress_bar.py[line:274] - INFO: epoch 001:   5728 / 7081 loss=-0.006, score=1.415, ntokens=874.9, nsentences=80, sample_size=874.9, wps=108.5, ups=0.12, wpb=874.9, bsz=80, num_updates=5720, lr=3.24376e-06, gnorm=1.589, clip=100, loss_scale=128, train_wall=81, gb_free=6.8, wall=74112
2022-05-20 18:00:10 - progress_bar.py[line:274] - INFO: epoch 001:   5738 / 7081 loss=-0.004, score=1.398, ntokens=895, nsentences=80, sample_size=895, wps=109.3, ups=0.12, wpb=895, bsz=80, num_updates=5730, lr=3.24016e-06, gnorm=1.764, clip=80, loss_scale=128, train_wall=82, gb_free=6.8, wall=74194
2022-05-20 18:01:31 - progress_bar.py[line:274] - INFO: epoch 001:   5748 / 7081 loss=-0.007, score=1.395, ntokens=896.5, nsentences=80, sample_size=896.5, wps=110.3, ups=0.12, wpb=896.5, bsz=80, num_updates=5740, lr=3.23655e-06, gnorm=1.441, clip=80, loss_scale=128, train_wall=81, gb_free=6.8, wall=74275
2022-05-20 18:01:39 - trainer.py[line:922] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-05-20 18:03:00 - progress_bar.py[line:274] - INFO: epoch 001:   5759 / 7081 loss=-0.004, score=1.327, ntokens=888.7, nsentences=80, sample_size=888.7, wps=99.6, ups=0.11, wpb=888.7, bsz=80, num_updates=5750, lr=3.23295e-06, gnorm=1.529, clip=70, loss_scale=64, train_wall=89, gb_free=6.8, wall=74365
2022-05-20 18:04:18 - progress_bar.py[line:274] - INFO: epoch 001:   5769 / 7081 loss=-0.006, score=1.481, ntokens=879.4, nsentences=80, sample_size=879.4, wps=112.7, ups=0.13, wpb=879.4, bsz=80, num_updates=5760, lr=3.22934e-06, gnorm=2.253, clip=80, loss_scale=64, train_wall=78, gb_free=6.8, wall=74443
2022-05-20 18:05:35 - progress_bar.py[line:274] - INFO: epoch 001:   5779 / 7081 loss=-0.004, score=1.436, ntokens=889.3, nsentences=80, sample_size=889.3, wps=115.7, ups=0.13, wpb=889.3, bsz=80, num_updates=5770, lr=3.22573e-06, gnorm=1.909, clip=90, loss_scale=64, train_wall=77, gb_free=6.8, wall=74520
2022-05-20 18:06:53 - progress_bar.py[line:274] - INFO: epoch 001:   5789 / 7081 loss=-0.005, score=1.429, ntokens=879, nsentences=80, sample_size=879, wps=112.4, ups=0.13, wpb=879, bsz=80, num_updates=5780, lr=3.22213e-06, gnorm=1.357, clip=80, loss_scale=64, train_wall=78, gb_free=6.8, wall=74598
2022-05-20 18:08:15 - progress_bar.py[line:274] - INFO: epoch 001:   5799 / 7081 loss=-0.008, score=1.44, ntokens=896.1, nsentences=80, sample_size=896.1, wps=109.5, ups=0.12, wpb=896.1, bsz=80, num_updates=5790, lr=3.21852e-06, gnorm=1.948, clip=100, loss_scale=64, train_wall=82, gb_free=6.8, wall=74680
2022-05-20 18:09:36 - progress_bar.py[line:274] - INFO: epoch 001:   5809 / 7081 loss=-0.007, score=1.489, ntokens=888.4, nsentences=80, sample_size=888.4, wps=109.8, ups=0.12, wpb=888.4, bsz=80, num_updates=5800, lr=3.21492e-06, gnorm=1.927, clip=100, loss_scale=64, train_wall=81, gb_free=6.8, wall=74761
2022-05-20 18:10:56 - progress_bar.py[line:274] - INFO: epoch 001:   5819 / 7081 loss=-0.008, score=1.498, ntokens=879.8, nsentences=80, sample_size=879.8, wps=109.2, ups=0.12, wpb=879.8, bsz=80, num_updates=5810, lr=3.21131e-06, gnorm=1.814, clip=90, loss_scale=64, train_wall=81, gb_free=6.8, wall=74841
2022-05-20 18:12:18 - progress_bar.py[line:274] - INFO: epoch 001:   5829 / 7081 loss=-0.005, score=1.321, ntokens=877.6, nsentences=80, sample_size=877.6, wps=107.9, ups=0.12, wpb=877.6, bsz=80, num_updates=5820, lr=3.20771e-06, gnorm=1.356, clip=70, loss_scale=64, train_wall=81, gb_free=6.8, wall=74922
2022-05-20 18:13:39 - progress_bar.py[line:274] - INFO: epoch 001:   5839 / 7081 loss=-0.006, score=1.507, ntokens=900.6, nsentences=80, sample_size=900.6, wps=110.9, ups=0.12, wpb=900.6, bsz=80, num_updates=5830, lr=3.2041e-06, gnorm=2.089, clip=100, loss_scale=64, train_wall=81, gb_free=6.8, wall=75004
2022-05-20 18:15:00 - progress_bar.py[line:274] - INFO: epoch 001:   5849 / 7081 loss=-0.004, score=1.393, ntokens=893.6, nsentences=80, sample_size=893.6, wps=110, ups=0.12, wpb=893.6, bsz=80, num_updates=5840, lr=3.2005e-06, gnorm=1.599, clip=90, loss_scale=64, train_wall=81, gb_free=6.8, wall=75085
2022-05-20 18:16:21 - progress_bar.py[line:274] - INFO: epoch 001:   5859 / 7081 loss=-0.004, score=1.457, ntokens=880, nsentences=80, sample_size=880, wps=108.9, ups=0.12, wpb=880, bsz=80, num_updates=5850, lr=3.19689e-06, gnorm=1.62, clip=100, loss_scale=64, train_wall=81, gb_free=6.8, wall=75166
2022-05-20 18:17:42 - progress_bar.py[line:274] - INFO: epoch 001:   5869 / 7081 loss=-0.005, score=1.479, ntokens=879.8, nsentences=80, sample_size=879.8, wps=108.8, ups=0.12, wpb=879.8, bsz=80, num_updates=5860, lr=3.19328e-06, gnorm=1.842, clip=100, loss_scale=64, train_wall=81, gb_free=6.8, wall=75247
2022-05-20 18:19:03 - progress_bar.py[line:274] - INFO: epoch 001:   5879 / 7081 loss=-0.004, score=1.44, ntokens=884.9, nsentences=80, sample_size=884.9, wps=109.1, ups=0.12, wpb=884.9, bsz=80, num_updates=5870, lr=3.18968e-06, gnorm=1.98, clip=100, loss_scale=64, train_wall=81, gb_free=6.8, wall=75328
2022-05-20 18:20:25 - progress_bar.py[line:274] - INFO: epoch 001:   5889 / 7081 loss=-0.003, score=1.445, ntokens=899.3, nsentences=80, sample_size=899.3, wps=110, ups=0.12, wpb=899.3, bsz=80, num_updates=5880, lr=3.18607e-06, gnorm=2.038, clip=80, loss_scale=64, train_wall=82, gb_free=6.8, wall=75409
2022-05-20 18:21:46 - progress_bar.py[line:274] - INFO: epoch 001:   5899 / 7081 loss=-0.008, score=1.422, ntokens=886.6, nsentences=80, sample_size=886.6, wps=109.3, ups=0.12, wpb=886.6, bsz=80, num_updates=5890, lr=3.18247e-06, gnorm=2.89, clip=100, loss_scale=64, train_wall=81, gb_free=6.8, wall=75491
2022-05-20 18:23:07 - progress_bar.py[line:274] - INFO: epoch 001:   5909 / 7081 loss=-0.006, score=1.44, ntokens=873.8, nsentences=80, sample_size=873.8, wps=108.2, ups=0.12, wpb=873.8, bsz=80, num_updates=5900, lr=3.17886e-06, gnorm=2.743, clip=100, loss_scale=64, train_wall=81, gb_free=6.8, wall=75571
2022-05-20 18:24:28 - progress_bar.py[line:274] - INFO: epoch 001:   5919 / 7081 loss=-0.008, score=1.476, ntokens=887.9, nsentences=80, sample_size=887.9, wps=109.5, ups=0.12, wpb=887.9, bsz=80, num_updates=5910, lr=3.17526e-06, gnorm=2.161, clip=80, loss_scale=64, train_wall=81, gb_free=6.8, wall=75652
2022-05-20 18:25:49 - progress_bar.py[line:274] - INFO: epoch 001:   5929 / 7081 loss=-0.005, score=1.463, ntokens=888.9, nsentences=80, sample_size=888.9, wps=109.3, ups=0.12, wpb=888.9, bsz=80, num_updates=5920, lr=3.17165e-06, gnorm=1.946, clip=80, loss_scale=64, train_wall=81, gb_free=6.8, wall=75734
2022-05-20 18:27:10 - progress_bar.py[line:274] - INFO: epoch 001:   5939 / 7081 loss=-0.008, score=1.548, ntokens=891.3, nsentences=80, sample_size=891.3, wps=110.2, ups=0.12, wpb=891.3, bsz=80, num_updates=5930, lr=3.16805e-06, gnorm=1.982, clip=80, loss_scale=64, train_wall=81, gb_free=6.8, wall=75815
2022-05-20 18:28:32 - progress_bar.py[line:274] - INFO: epoch 001:   5949 / 7081 loss=-0.006, score=1.473, ntokens=900, nsentences=80, sample_size=900, wps=110.3, ups=0.12, wpb=900, bsz=80, num_updates=5940, lr=3.16444e-06, gnorm=1.626, clip=90, loss_scale=64, train_wall=82, gb_free=6.8, wall=75896
2022-05-20 18:29:51 - progress_bar.py[line:274] - INFO: epoch 001:   5959 / 7081 loss=-0.004, score=1.488, ntokens=884.7, nsentences=80, sample_size=884.7, wps=111.3, ups=0.13, wpb=884.7, bsz=80, num_updates=5950, lr=3.16084e-06, gnorm=1.646, clip=90, loss_scale=64, train_wall=79, gb_free=6.8, wall=75976
2022-05-20 18:31:08 - progress_bar.py[line:274] - INFO: epoch 001:   5969 / 7081 loss=-0.006, score=1.406, ntokens=883.2, nsentences=80, sample_size=883.2, wps=115.1, ups=0.13, wpb=883.2, bsz=80, num_updates=5960, lr=3.15723e-06, gnorm=1.391, clip=100, loss_scale=64, train_wall=77, gb_free=6.7, wall=76052
2022-05-20 18:32:26 - progress_bar.py[line:274] - INFO: epoch 001:   5979 / 7081 loss=-0.005, score=1.357, ntokens=903.1, nsentences=80, sample_size=903.1, wps=115.9, ups=0.13, wpb=903.1, bsz=80, num_updates=5970, lr=3.15362e-06, gnorm=1.645, clip=80, loss_scale=64, train_wall=78, gb_free=6.8, wall=76130
2022-05-20 18:33:47 - progress_bar.py[line:274] - INFO: epoch 001:   5989 / 7081 loss=-0.005, score=1.386, ntokens=886.2, nsentences=80, sample_size=886.2, wps=108.8, ups=0.12, wpb=886.2, bsz=80, num_updates=5980, lr=3.15002e-06, gnorm=1.843, clip=100, loss_scale=64, train_wall=81, gb_free=6.8, wall=76212
2022-05-20 18:35:08 - progress_bar.py[line:274] - INFO: epoch 001:   5999 / 7081 loss=-0.007, score=1.326, ntokens=890.5, nsentences=80, sample_size=890.5, wps=109.6, ups=0.12, wpb=890.5, bsz=80, num_updates=5990, lr=3.14641e-06, gnorm=1.557, clip=90, loss_scale=64, train_wall=81, gb_free=6.8, wall=76293
2022-05-20 18:36:30 - progress_bar.py[line:274] - INFO: epoch 001:   6009 / 7081 loss=-0.005, score=1.409, ntokens=898.2, nsentences=80, sample_size=898.2, wps=110.1, ups=0.12, wpb=898.2, bsz=80, num_updates=6000, lr=3.14281e-06, gnorm=1.794, clip=90, loss_scale=64, train_wall=81, gb_free=6.8, wall=76375
2022-05-20 18:36:30 - train.py[line:436] - INFO: begin validation on "valid" subset
slice_id 0 seek offset 0
slice_id 0 seek offset 0
slice_id 1 seek offset 2500
slice_id 1 seek offset 2500
2022-05-20 19:16:32 - progress_bar.py[line:282] - INFO: epoch 001 | valid on 'valid' subset | loss -0.005 | score 1.296 | ntokens 111.054 | nsentences 10 | sample_size 111.054 | cider 1.388 | wps 115.6 | wpb 111.1 | bsz 10 | num_updates 6000 | best_cider 1.388
2022-05-20 19:16:32 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 1 @ 6000 updates
2022-05-20 19:16:32 - trainer.py[line:431] - INFO: Saving checkpoint to /database/jhkim/stage2_checkpoints//5e-6_2/checkpoint_1_6000.pt
2022-05-20 19:16:41 - trainer.py[line:441] - INFO: Finished saving checkpoint to /database/jhkim/stage2_checkpoints//5e-6_2/checkpoint_1_6000.pt
2022-05-20 19:18:03 - checkpoint_utils.py[line:135] - INFO: Saved checkpoint /database/jhkim/stage2_checkpoints//5e-6_2/checkpoint_1_6000.pt (epoch 1 @ 6000 updates, score 1.388) (writing took 91.32643890706822 seconds)
2022-05-20 19:19:24 - progress_bar.py[line:274] - INFO: epoch 001:   6019 / 7081 loss=-0.006, score=1.378, ntokens=886.5, nsentences=80, sample_size=886.5, wps=3.4, ups=0, wpb=886.5, bsz=80, num_updates=6010, lr=3.1392e-06, gnorm=2.103, clip=100, loss_scale=64, train_wall=80, gb_free=6.8, wall=78949
2022-05-20 19:20:45 - progress_bar.py[line:274] - INFO: epoch 001:   6029 / 7081 loss=-0.004, score=1.445, ntokens=871.7, nsentences=80, sample_size=871.7, wps=108.1, ups=0.12, wpb=871.7, bsz=80, num_updates=6020, lr=3.1356e-06, gnorm=1.91, clip=90, loss_scale=64, train_wall=81, gb_free=6.8, wall=79029
2022-05-20 19:22:03 - progress_bar.py[line:274] - INFO: epoch 001:   6039 / 7081 loss=-0.003, score=1.363, ntokens=894.6, nsentences=80, sample_size=894.6, wps=114.4, ups=0.13, wpb=894.6, bsz=80, num_updates=6030, lr=3.13199e-06, gnorm=1.855, clip=70, loss_scale=64, train_wall=78, gb_free=6.8, wall=79108
2022-05-20 19:23:19 - progress_bar.py[line:274] - INFO: epoch 001:   6049 / 7081 loss=-0.008, score=1.542, ntokens=883.7, nsentences=80, sample_size=883.7, wps=115.5, ups=0.13, wpb=883.7, bsz=80, num_updates=6040, lr=3.12839e-06, gnorm=1.764, clip=90, loss_scale=64, train_wall=76, gb_free=6.8, wall=79184
2022-05-20 19:24:38 - progress_bar.py[line:274] - INFO: epoch 001:   6059 / 7081 loss=-0.01, score=1.511, ntokens=887.4, nsentences=80, sample_size=887.4, wps=113.5, ups=0.13, wpb=887.4, bsz=80, num_updates=6050, lr=3.12478e-06, gnorm=1.825, clip=100, loss_scale=64, train_wall=78, gb_free=6.8, wall=79262
2022-05-20 19:25:59 - progress_bar.py[line:274] - INFO: epoch 001:   6069 / 7081 loss=-0.007, score=1.492, ntokens=886.3, nsentences=80, sample_size=886.3, wps=109.4, ups=0.12, wpb=886.3, bsz=80, num_updates=6060, lr=3.12117e-06, gnorm=1.708, clip=90, loss_scale=64, train_wall=81, gb_free=6.8, wall=79343
2022-05-20 19:27:20 - progress_bar.py[line:274] - INFO: epoch 001:   6079 / 7081 loss=-0.007, score=1.449, ntokens=892.8, nsentences=80, sample_size=892.8, wps=109.8, ups=0.12, wpb=892.8, bsz=80, num_updates=6070, lr=3.11757e-06, gnorm=1.891, clip=100, loss_scale=64, train_wall=81, gb_free=6.8, wall=79425
2022-05-20 19:28:42 - progress_bar.py[line:274] - INFO: epoch 001:   6089 / 7081 loss=-0.012, score=1.381, ntokens=893.6, nsentences=80, sample_size=893.6, wps=109.2, ups=0.12, wpb=893.6, bsz=80, num_updates=6080, lr=3.11396e-06, gnorm=2.236, clip=80, loss_scale=64, train_wall=82, gb_free=6.8, wall=79506
2022-05-20 19:30:02 - progress_bar.py[line:274] - INFO: epoch 001:   6099 / 7081 loss=-0.004, score=1.393, ntokens=879.1, nsentences=80, sample_size=879.1, wps=109.3, ups=0.12, wpb=879.1, bsz=80, num_updates=6090, lr=3.11036e-06, gnorm=2.241, clip=100, loss_scale=64, train_wall=80, gb_free=6.8, wall=79587
2022-05-20 19:31:24 - progress_bar.py[line:274] - INFO: epoch 001:   6109 / 7081 loss=-0.006, score=1.449, ntokens=898.1, nsentences=80, sample_size=898.1, wps=109.6, ups=0.12, wpb=898.1, bsz=80, num_updates=6100, lr=3.10675e-06, gnorm=1.67, clip=80, loss_scale=64, train_wall=82, gb_free=6.8, wall=79669
2022-05-20 19:32:45 - progress_bar.py[line:274] - INFO: epoch 001:   6119 / 7081 loss=-0.004, score=1.491, ntokens=889, nsentences=80, sample_size=889, wps=109.5, ups=0.12, wpb=889, bsz=80, num_updates=6110, lr=3.10315e-06, gnorm=2.1, clip=100, loss_scale=64, train_wall=81, gb_free=6.8, wall=79750
2022-05-20 19:34:07 - progress_bar.py[line:274] - INFO: epoch 001:   6129 / 7081 loss=-0.01, score=1.478, ntokens=902.2, nsentences=80, sample_size=902.2, wps=110.6, ups=0.12, wpb=902.2, bsz=80, num_updates=6120, lr=3.09954e-06, gnorm=1.741, clip=70, loss_scale=64, train_wall=81, gb_free=6.8, wall=79832
2022-05-20 19:35:28 - progress_bar.py[line:274] - INFO: epoch 001:   6139 / 7081 loss=-0.006, score=1.404, ntokens=888.4, nsentences=80, sample_size=888.4, wps=109.3, ups=0.12, wpb=888.4, bsz=80, num_updates=6130, lr=3.09594e-06, gnorm=1.256, clip=90, loss_scale=64, train_wall=81, gb_free=6.7, wall=79913
2022-05-20 19:36:49 - progress_bar.py[line:274] - INFO: epoch 001:   6149 / 7081 loss=-0.009, score=1.412, ntokens=883.1, nsentences=80, sample_size=883.1, wps=109.1, ups=0.12, wpb=883.1, bsz=80, num_updates=6140, lr=3.09233e-06, gnorm=1.68, clip=70, loss_scale=64, train_wall=81, gb_free=6.8, wall=79994
2022-05-20 19:38:11 - progress_bar.py[line:274] - INFO: epoch 001:   6159 / 7081 loss=-0, score=1.416, ntokens=892.2, nsentences=80, sample_size=892.2, wps=109.6, ups=0.12, wpb=892.2, bsz=80, num_updates=6150, lr=3.08873e-06, gnorm=1.356, clip=80, loss_scale=64, train_wall=81, gb_free=6.8, wall=80075
2022-05-20 19:39:31 - progress_bar.py[line:274] - INFO: epoch 001:   6169 / 7081 loss=-0.007, score=1.469, ntokens=885.2, nsentences=80, sample_size=885.2, wps=109.6, ups=0.12, wpb=885.2, bsz=80, num_updates=6160, lr=3.08512e-06, gnorm=1.976, clip=100, loss_scale=64, train_wall=81, gb_free=6.8, wall=80156
2022-05-20 19:40:52 - progress_bar.py[line:274] - INFO: epoch 001:   6179 / 7081 loss=-0.007, score=1.423, ntokens=879.4, nsentences=80, sample_size=879.4, wps=109.6, ups=0.12, wpb=879.4, bsz=80, num_updates=6170, lr=3.08151e-06, gnorm=1.243, clip=70, loss_scale=64, train_wall=80, gb_free=6.8, wall=80236
2022-05-20 19:42:13 - progress_bar.py[line:274] - INFO: epoch 001:   6189 / 7081 loss=-0.004, score=1.371, ntokens=891.6, nsentences=80, sample_size=891.6, wps=110.2, ups=0.12, wpb=891.6, bsz=80, num_updates=6180, lr=3.07791e-06, gnorm=1.86, clip=100, loss_scale=64, train_wall=81, gb_free=6.8, wall=80317
2022-05-20 19:43:34 - progress_bar.py[line:274] - INFO: epoch 001:   6199 / 7081 loss=-0.006, score=1.377, ntokens=886.5, nsentences=80, sample_size=886.5, wps=108.9, ups=0.12, wpb=886.5, bsz=80, num_updates=6190, lr=3.0743e-06, gnorm=1.981, clip=70, loss_scale=64, train_wall=81, gb_free=6.7, wall=80399
2022-05-20 19:44:55 - progress_bar.py[line:274] - INFO: epoch 001:   6209 / 7081 loss=-0.009, score=1.468, ntokens=897.4, nsentences=80, sample_size=897.4, wps=110.1, ups=0.12, wpb=897.4, bsz=80, num_updates=6200, lr=3.0707e-06, gnorm=1.685, clip=90, loss_scale=64, train_wall=81, gb_free=6.8, wall=80480
2022-05-20 19:46:16 - progress_bar.py[line:274] - INFO: epoch 001:   6219 / 7081 loss=-0.005, score=1.484, ntokens=884.4, nsentences=80, sample_size=884.4, wps=110.1, ups=0.12, wpb=884.4, bsz=80, num_updates=6210, lr=3.06709e-06, gnorm=1.826, clip=90, loss_scale=64, train_wall=80, gb_free=6.8, wall=80560
2022-05-20 19:47:35 - progress_bar.py[line:274] - INFO: epoch 001:   6229 / 7081 loss=-0.005, score=1.314, ntokens=885.5, nsentences=80, sample_size=885.5, wps=111.7, ups=0.13, wpb=885.5, bsz=80, num_updates=6220, lr=3.06349e-06, gnorm=1.281, clip=80, loss_scale=64, train_wall=79, gb_free=6.8, wall=80640
2022-05-20 19:48:52 - progress_bar.py[line:274] - INFO: epoch 001:   6239 / 7081 loss=-0.008, score=1.532, ntokens=885.8, nsentences=80, sample_size=885.8, wps=115.7, ups=0.13, wpb=885.8, bsz=80, num_updates=6230, lr=3.05988e-06, gnorm=2.089, clip=90, loss_scale=64, train_wall=76, gb_free=6.8, wall=80716
2022-05-20 19:50:09 - progress_bar.py[line:274] - INFO: epoch 001:   6249 / 7081 loss=-0.005, score=1.486, ntokens=893.7, nsentences=80, sample_size=893.7, wps=115.1, ups=0.13, wpb=893.7, bsz=80, num_updates=6240, lr=3.05628e-06, gnorm=1.846, clip=80, loss_scale=64, train_wall=78, gb_free=6.8, wall=80794
2022-05-20 19:51:30 - progress_bar.py[line:274] - INFO: epoch 001:   6259 / 7081 loss=-0.007, score=1.497, ntokens=891.1, nsentences=80, sample_size=891.1, wps=109.7, ups=0.12, wpb=891.1, bsz=80, num_updates=6250, lr=3.05267e-06, gnorm=1.696, clip=80, loss_scale=64, train_wall=81, gb_free=6.8, wall=80875
2022-05-20 19:52:51 - progress_bar.py[line:274] - INFO: epoch 001:   6269 / 7081 loss=-0.005, score=1.395, ntokens=882.6, nsentences=80, sample_size=882.6, wps=109.5, ups=0.12, wpb=882.6, bsz=80, num_updates=6260, lr=3.04906e-06, gnorm=1.544, clip=80, loss_scale=128, train_wall=81, gb_free=6.8, wall=80956
2022-05-20 19:54:12 - progress_bar.py[line:274] - INFO: epoch 001:   6279 / 7081 loss=-0.004, score=1.54, ntokens=871.9, nsentences=80, sample_size=871.9, wps=107.9, ups=0.12, wpb=871.9, bsz=80, num_updates=6270, lr=3.04546e-06, gnorm=1.784, clip=100, loss_scale=128, train_wall=81, gb_free=6.8, wall=81037
2022-05-20 19:55:33 - progress_bar.py[line:274] - INFO: epoch 001:   6289 / 7081 loss=-0.005, score=1.485, ntokens=873.2, nsentences=80, sample_size=873.2, wps=107.9, ups=0.12, wpb=873.2, bsz=80, num_updates=6280, lr=3.04185e-06, gnorm=1.876, clip=90, loss_scale=128, train_wall=81, gb_free=6.8, wall=81118
2022-05-20 19:56:54 - progress_bar.py[line:274] - INFO: epoch 001:   6299 / 7081 loss=-0.004, score=1.392, ntokens=885.7, nsentences=80, sample_size=885.7, wps=109.6, ups=0.12, wpb=885.7, bsz=80, num_updates=6290, lr=3.03825e-06, gnorm=1.821, clip=100, loss_scale=128, train_wall=81, gb_free=6.8, wall=81198
2022-05-20 19:58:16 - progress_bar.py[line:274] - INFO: epoch 001:   6309 / 7081 loss=-0.006, score=1.36, ntokens=889.8, nsentences=80, sample_size=889.8, wps=108.5, ups=0.12, wpb=889.8, bsz=80, num_updates=6300, lr=3.03464e-06, gnorm=1.727, clip=90, loss_scale=128, train_wall=82, gb_free=6.8, wall=81280
2022-05-20 19:59:20 - trainer.py[line:922] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-05-20 19:59:44 - progress_bar.py[line:274] - INFO: epoch 001:   6320 / 7081 loss=-0.006, score=1.462, ntokens=878.9, nsentences=80, sample_size=878.9, wps=99.4, ups=0.11, wpb=878.9, bsz=80, num_updates=6310, lr=3.03104e-06, gnorm=1.61, clip=100, loss_scale=64, train_wall=88, gb_free=6.8, wall=81369
2022-05-20 20:01:06 - progress_bar.py[line:274] - INFO: epoch 001:   6330 / 7081 loss=-0.003, score=1.468, ntokens=881.9, nsentences=80, sample_size=881.9, wps=107.9, ups=0.12, wpb=881.9, bsz=80, num_updates=6320, lr=3.02743e-06, gnorm=2.155, clip=100, loss_scale=64, train_wall=82, gb_free=6.8, wall=81450
2022-05-20 20:02:27 - progress_bar.py[line:274] - INFO: epoch 001:   6340 / 7081 loss=-0.005, score=1.563, ntokens=883.3, nsentences=80, sample_size=883.3, wps=108.8, ups=0.12, wpb=883.3, bsz=80, num_updates=6330, lr=3.02383e-06, gnorm=1.742, clip=100, loss_scale=64, train_wall=81, gb_free=6.8, wall=81532
2022-05-20 20:03:48 - progress_bar.py[line:274] - INFO: epoch 001:   6350 / 7081 loss=-0.006, score=1.502, ntokens=885.5, nsentences=80, sample_size=885.5, wps=109.5, ups=0.12, wpb=885.5, bsz=80, num_updates=6340, lr=3.02022e-06, gnorm=1.903, clip=100, loss_scale=64, train_wall=81, gb_free=6.8, wall=81613
2022-05-20 20:05:09 - progress_bar.py[line:274] - INFO: epoch 001:   6360 / 7081 loss=-0.008, score=1.336, ntokens=888.4, nsentences=80, sample_size=888.4, wps=109, ups=0.12, wpb=888.4, bsz=80, num_updates=6350, lr=3.01662e-06, gnorm=1.573, clip=80, loss_scale=64, train_wall=81, gb_free=6.8, wall=81694
2022-05-20 20:06:30 - progress_bar.py[line:274] - INFO: epoch 001:   6370 / 7081 loss=-0.009, score=1.408, ntokens=880.1, nsentences=80, sample_size=880.1, wps=108.9, ups=0.12, wpb=880.1, bsz=80, num_updates=6360, lr=3.01301e-06, gnorm=1.822, clip=100, loss_scale=64, train_wall=81, gb_free=6.8, wall=81775
2022-05-20 20:07:51 - progress_bar.py[line:274] - INFO: epoch 001:   6380 / 7081 loss=-0.008, score=1.516, ntokens=880.4, nsentences=80, sample_size=880.4, wps=109, ups=0.12, wpb=880.4, bsz=80, num_updates=6370, lr=3.0094e-06, gnorm=1.729, clip=100, loss_scale=64, train_wall=81, gb_free=6.8, wall=81856
2022-05-20 20:09:13 - progress_bar.py[line:274] - INFO: epoch 001:   6390 / 7081 loss=-0.008, score=1.479, ntokens=891.6, nsentences=80, sample_size=891.6, wps=109.2, ups=0.12, wpb=891.6, bsz=80, num_updates=6380, lr=3.0058e-06, gnorm=1.811, clip=100, loss_scale=64, train_wall=82, gb_free=6.8, wall=81937
2022-05-20 20:10:34 - progress_bar.py[line:274] - INFO: epoch 001:   6400 / 7081 loss=-0.006, score=1.322, ntokens=879.6, nsentences=80, sample_size=879.6, wps=108.5, ups=0.12, wpb=879.6, bsz=80, num_updates=6390, lr=3.00219e-06, gnorm=2.332, clip=80, loss_scale=64, train_wall=81, gb_free=6.8, wall=82018
2022-05-20 20:11:55 - progress_bar.py[line:274] - INFO: epoch 001:   6410 / 7081 loss=-0.004, score=1.379, ntokens=883.2, nsentences=80, sample_size=883.2, wps=108.9, ups=0.12, wpb=883.2, bsz=80, num_updates=6400, lr=2.99859e-06, gnorm=1.388, clip=80, loss_scale=64, train_wall=81, gb_free=6.8, wall=82100
2022-05-20 20:13:15 - progress_bar.py[line:274] - INFO: epoch 001:   6420 / 7081 loss=-0.007, score=1.47, ntokens=878.6, nsentences=80, sample_size=878.6, wps=109.1, ups=0.12, wpb=878.6, bsz=80, num_updates=6410, lr=2.99498e-06, gnorm=1.683, clip=90, loss_scale=64, train_wall=80, gb_free=6.8, wall=82180
2022-05-20 20:14:32 - progress_bar.py[line:274] - INFO: epoch 001:   6430 / 7081 loss=-0.006, score=1.464, ntokens=887.3, nsentences=80, sample_size=887.3, wps=116, ups=0.13, wpb=887.3, bsz=80, num_updates=6420, lr=2.99138e-06, gnorm=2.173, clip=90, loss_scale=64, train_wall=76, gb_free=6.8, wall=82257
2022-05-20 20:15:49 - progress_bar.py[line:274] - INFO: epoch 001:   6440 / 7081 loss=-0.002, score=1.414, ntokens=881.1, nsentences=80, sample_size=881.1, wps=114.6, ups=0.13, wpb=881.1, bsz=80, num_updates=6430, lr=2.98777e-06, gnorm=1.525, clip=70, loss_scale=64, train_wall=77, gb_free=6.7, wall=82333
2022-05-20 20:17:08 - progress_bar.py[line:274] - INFO: epoch 001:   6450 / 7081 loss=-0.007, score=1.418, ntokens=874.9, nsentences=80, sample_size=874.9, wps=109.9, ups=0.13, wpb=874.9, bsz=80, num_updates=6440, lr=2.98417e-06, gnorm=1.623, clip=70, loss_scale=64, train_wall=80, gb_free=6.8, wall=82413
2022-05-20 20:18:30 - progress_bar.py[line:274] - INFO: epoch 001:   6460 / 7081 loss=-0.008, score=1.477, ntokens=891.5, nsentences=80, sample_size=891.5, wps=109.7, ups=0.12, wpb=891.5, bsz=80, num_updates=6450, lr=2.98056e-06, gnorm=1.579, clip=100, loss_scale=64, train_wall=81, gb_free=6.8, wall=82494
2022-05-20 20:19:51 - progress_bar.py[line:274] - INFO: epoch 001:   6470 / 7081 loss=-0.006, score=1.437, ntokens=888, nsentences=80, sample_size=888, wps=109.7, ups=0.12, wpb=888, bsz=80, num_updates=6460, lr=2.97695e-06, gnorm=1.895, clip=80, loss_scale=64, train_wall=81, gb_free=6.8, wall=82575
2022-05-20 20:21:13 - progress_bar.py[line:274] - INFO: epoch 001:   6480 / 7081 loss=-0.007, score=1.477, ntokens=891.3, nsentences=80, sample_size=891.3, wps=108.6, ups=0.12, wpb=891.3, bsz=80, num_updates=6470, lr=2.97335e-06, gnorm=1.497, clip=80, loss_scale=64, train_wall=82, gb_free=6.8, wall=82657
2022-05-20 20:22:34 - progress_bar.py[line:274] - INFO: epoch 001:   6490 / 7081 loss=-0.008, score=1.564, ntokens=888.7, nsentences=80, sample_size=888.7, wps=109.6, ups=0.12, wpb=888.7, bsz=80, num_updates=6480, lr=2.96974e-06, gnorm=1.739, clip=90, loss_scale=64, train_wall=81, gb_free=6.8, wall=82738
2022-05-20 20:23:55 - progress_bar.py[line:274] - INFO: epoch 001:   6500 / 7081 loss=-0.007, score=1.475, ntokens=908.3, nsentences=80, sample_size=908.3, wps=111.2, ups=0.12, wpb=908.3, bsz=80, num_updates=6490, lr=2.96614e-06, gnorm=1.841, clip=90, loss_scale=64, train_wall=82, gb_free=6.8, wall=82820
slice_id 1 seek offset 2500
slice_id 1 seek offset 2500
2022-05-20 20:25:17 - progress_bar.py[line:274] - INFO: epoch 001:   6510 / 7081 loss=-0.008, score=1.542, ntokens=879.2, nsentences=80, sample_size=879.2, wps=108.2, ups=0.12, wpb=879.2, bsz=80, num_updates=6500, lr=2.96253e-06, gnorm=1.872, clip=80, loss_scale=64, train_wall=81, gb_free=6.8, wall=82901
2022-05-20 20:25:17 - train.py[line:436] - INFO: begin validation on "valid" subset
slice_id 0 seek offset 0
slice_id 0 seek offset 0
2022-05-20 21:05:21 - progress_bar.py[line:282] - INFO: epoch 001 | valid on 'valid' subset | loss -0.005 | score 1.294 | ntokens 111.074 | nsentences 10 | sample_size 111.074 | cider 1.387 | wps 115.5 | wpb 111.1 | bsz 10 | num_updates 6500 | best_cider 1.388
2022-05-20 21:05:21 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 1 @ 6500 updates
2022-05-20 21:05:21 - trainer.py[line:431] - INFO: Saving checkpoint to /database/jhkim/stage2_checkpoints//5e-6_2/checkpoint_1_6500.pt
2022-05-20 21:05:29 - trainer.py[line:441] - INFO: Finished saving checkpoint to /database/jhkim/stage2_checkpoints//5e-6_2/checkpoint_1_6500.pt
2022-05-20 21:05:56 - checkpoint_utils.py[line:135] - INFO: Saved checkpoint /database/jhkim/stage2_checkpoints//5e-6_2/checkpoint_1_6500.pt (epoch 1 @ 6500 updates, score 1.387) (writing took 34.828419176861644 seconds)
2022-05-20 21:07:11 - progress_bar.py[line:274] - INFO: epoch 001:   6520 / 7081 loss=-0.004, score=1.466, ntokens=881.2, nsentences=80, sample_size=881.2, wps=3.5, ups=0, wpb=881.2, bsz=80, num_updates=6510, lr=2.95893e-06, gnorm=1.764, clip=80, loss_scale=64, train_wall=76, gb_free=6.8, wall=85416
2022-05-20 21:08:30 - progress_bar.py[line:274] - INFO: epoch 001:   6530 / 7081 loss=-0.003, score=1.598, ntokens=878.2, nsentences=80, sample_size=878.2, wps=111.9, ups=0.13, wpb=878.2, bsz=80, num_updates=6520, lr=2.95532e-06, gnorm=1.738, clip=100, loss_scale=64, train_wall=78, gb_free=6.8, wall=85495
2022-05-20 21:09:51 - progress_bar.py[line:274] - INFO: epoch 001:   6540 / 7081 loss=-0.004, score=1.413, ntokens=877.3, nsentences=80, sample_size=877.3, wps=108.8, ups=0.12, wpb=877.3, bsz=80, num_updates=6530, lr=2.95172e-06, gnorm=1.525, clip=100, loss_scale=64, train_wall=81, gb_free=6.8, wall=85575
2022-05-20 21:11:12 - progress_bar.py[line:274] - INFO: epoch 001:   6550 / 7081 loss=-0.004, score=1.337, ntokens=896.7, nsentences=80, sample_size=896.7, wps=109.7, ups=0.12, wpb=896.7, bsz=80, num_updates=6540, lr=2.94811e-06, gnorm=1.597, clip=80, loss_scale=64, train_wall=82, gb_free=6.8, wall=85657
2022-05-20 21:12:34 - progress_bar.py[line:274] - INFO: epoch 001:   6560 / 7081 loss=-0.005, score=1.502, ntokens=881.9, nsentences=80, sample_size=881.9, wps=108.5, ups=0.12, wpb=881.9, bsz=80, num_updates=6550, lr=2.94451e-06, gnorm=2.519, clip=100, loss_scale=64, train_wall=81, gb_free=6.8, wall=85738
2022-05-20 21:13:56 - progress_bar.py[line:274] - INFO: epoch 001:   6570 / 7081 loss=-0.004, score=1.425, ntokens=899.1, nsentences=80, sample_size=899.1, wps=109.7, ups=0.12, wpb=899.1, bsz=80, num_updates=6560, lr=2.9409e-06, gnorm=1.724, clip=70, loss_scale=64, train_wall=82, gb_free=6.8, wall=85820
2022-05-20 21:15:16 - progress_bar.py[line:274] - INFO: epoch 001:   6580 / 7081 loss=-0.006, score=1.469, ntokens=880, nsentences=80, sample_size=880, wps=109, ups=0.12, wpb=880, bsz=80, num_updates=6570, lr=2.93729e-06, gnorm=2.118, clip=90, loss_scale=64, train_wall=81, gb_free=6.8, wall=85901
2022-05-20 21:16:37 - progress_bar.py[line:274] - INFO: epoch 001:   6590 / 7081 loss=-0.005, score=1.492, ntokens=887.1, nsentences=80, sample_size=887.1, wps=110, ups=0.12, wpb=887.1, bsz=80, num_updates=6580, lr=2.93369e-06, gnorm=1.618, clip=80, loss_scale=64, train_wall=81, gb_free=6.8, wall=85982
2022-05-20 21:17:58 - progress_bar.py[line:274] - INFO: epoch 001:   6600 / 7081 loss=-0.008, score=1.456, ntokens=884.4, nsentences=80, sample_size=884.4, wps=109.6, ups=0.12, wpb=884.4, bsz=80, num_updates=6590, lr=2.93008e-06, gnorm=1.752, clip=90, loss_scale=64, train_wall=81, gb_free=6.7, wall=86062
2022-05-20 21:19:19 - progress_bar.py[line:274] - INFO: epoch 001:   6610 / 7081 loss=-0.009, score=1.43, ntokens=884.6, nsentences=80, sample_size=884.6, wps=109.1, ups=0.12, wpb=884.6, bsz=80, num_updates=6600, lr=2.92648e-06, gnorm=2.551, clip=100, loss_scale=64, train_wall=81, gb_free=6.8, wall=86143
2022-05-20 21:20:39 - progress_bar.py[line:274] - INFO: epoch 001:   6620 / 7081 loss=-0.004, score=1.47, ntokens=890.6, nsentences=80, sample_size=890.6, wps=110.4, ups=0.12, wpb=890.6, bsz=80, num_updates=6610, lr=2.92287e-06, gnorm=1.689, clip=100, loss_scale=64, train_wall=81, gb_free=6.8, wall=86224
2022-05-20 21:22:00 - progress_bar.py[line:274] - INFO: epoch 001:   6630 / 7081 loss=-0.004, score=1.535, ntokens=893.7, nsentences=80, sample_size=893.7, wps=110.6, ups=0.12, wpb=893.7, bsz=80, num_updates=6620, lr=2.91927e-06, gnorm=1.83, clip=90, loss_scale=64, train_wall=81, gb_free=6.8, wall=86305
2022-05-20 21:23:21 - progress_bar.py[line:274] - INFO: epoch 001:   6640 / 7081 loss=-0.007, score=1.398, ntokens=883.8, nsentences=80, sample_size=883.8, wps=109, ups=0.12, wpb=883.8, bsz=80, num_updates=6630, lr=2.91566e-06, gnorm=1.354, clip=80, loss_scale=64, train_wall=81, gb_free=6.8, wall=86386
2022-05-20 21:24:42 - progress_bar.py[line:274] - INFO: epoch 001:   6650 / 7081 loss=-0.009, score=1.457, ntokens=886.5, nsentences=80, sample_size=886.5, wps=109.9, ups=0.12, wpb=886.5, bsz=80, num_updates=6640, lr=2.91206e-06, gnorm=1.643, clip=90, loss_scale=64, train_wall=81, gb_free=6.8, wall=86467
2022-05-20 21:26:03 - progress_bar.py[line:274] - INFO: epoch 001:   6660 / 7081 loss=-0.009, score=1.484, ntokens=890.9, nsentences=80, sample_size=890.9, wps=109.7, ups=0.12, wpb=890.9, bsz=80, num_updates=6650, lr=2.90845e-06, gnorm=2.046, clip=90, loss_scale=64, train_wall=81, gb_free=6.8, wall=86548
2022-05-20 21:27:24 - progress_bar.py[line:274] - INFO: epoch 001:   6670 / 7081 loss=-0.008, score=1.518, ntokens=887.5, nsentences=80, sample_size=887.5, wps=109.4, ups=0.12, wpb=887.5, bsz=80, num_updates=6660, lr=2.90484e-06, gnorm=1.695, clip=90, loss_scale=64, train_wall=81, gb_free=6.8, wall=86629
2022-05-20 21:27:33 - trainer.py[line:922] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-05-20 21:28:53 - progress_bar.py[line:274] - INFO: epoch 001:   6681 / 7081 loss=-0.006, score=1.439, ntokens=885.2, nsentences=80, sample_size=885.2, wps=99.6, ups=0.11, wpb=885.2, bsz=80, num_updates=6670, lr=2.90124e-06, gnorm=1.465, clip=80, loss_scale=32, train_wall=89, gb_free=6.8, wall=86718
2022-05-20 21:30:15 - progress_bar.py[line:274] - INFO: epoch 001:   6691 / 7081 loss=-0.005, score=1.387, ntokens=895.4, nsentences=80, sample_size=895.4, wps=109.7, ups=0.12, wpb=895.4, bsz=80, num_updates=6680, lr=2.89763e-06, gnorm=1.803, clip=90, loss_scale=32, train_wall=82, gb_free=6.8, wall=86799
2022-05-20 21:31:34 - progress_bar.py[line:274] - INFO: epoch 001:   6701 / 7081 loss=-0.007, score=1.393, ntokens=885.9, nsentences=80, sample_size=885.9, wps=112, ups=0.13, wpb=885.9, bsz=80, num_updates=6690, lr=2.89403e-06, gnorm=1.607, clip=90, loss_scale=32, train_wall=79, gb_free=6.8, wall=86879
2022-05-20 21:32:50 - progress_bar.py[line:274] - INFO: epoch 001:   6711 / 7081 loss=-0.002, score=1.356, ntokens=883.7, nsentences=80, sample_size=883.7, wps=115.6, ups=0.13, wpb=883.7, bsz=80, num_updates=6700, lr=2.89042e-06, gnorm=1.671, clip=90, loss_scale=32, train_wall=76, gb_free=6.8, wall=86955
2022-05-20 21:34:08 - progress_bar.py[line:274] - INFO: epoch 001:   6721 / 7081 loss=-0.008, score=1.492, ntokens=880, nsentences=80, sample_size=880, wps=113.7, ups=0.13, wpb=880, bsz=80, num_updates=6710, lr=2.88682e-06, gnorm=1.517, clip=90, loss_scale=32, train_wall=77, gb_free=6.8, wall=87032
2022-05-20 21:35:28 - progress_bar.py[line:274] - INFO: epoch 001:   6731 / 7081 loss=-0.005, score=1.47, ntokens=886.5, nsentences=80, sample_size=886.5, wps=109.9, ups=0.12, wpb=886.5, bsz=80, num_updates=6720, lr=2.88321e-06, gnorm=1.384, clip=90, loss_scale=32, train_wall=81, gb_free=6.8, wall=87113
2022-05-20 21:36:50 - progress_bar.py[line:274] - INFO: epoch 001:   6741 / 7081 loss=-0.005, score=1.502, ntokens=894.2, nsentences=80, sample_size=894.2, wps=110.2, ups=0.12, wpb=894.2, bsz=80, num_updates=6730, lr=2.87961e-06, gnorm=1.889, clip=100, loss_scale=32, train_wall=81, gb_free=6.8, wall=87194
2022-05-20 21:38:11 - progress_bar.py[line:274] - INFO: epoch 001:   6751 / 7081 loss=-0.003, score=1.44, ntokens=888.9, nsentences=80, sample_size=888.9, wps=108.9, ups=0.12, wpb=888.9, bsz=80, num_updates=6740, lr=2.876e-06, gnorm=1.527, clip=90, loss_scale=32, train_wall=82, gb_free=6.8, wall=87276
2022-05-20 21:39:32 - progress_bar.py[line:274] - INFO: epoch 001:   6761 / 7081 loss=-0.006, score=1.566, ntokens=892.2, nsentences=80, sample_size=892.2, wps=110.5, ups=0.12, wpb=892.2, bsz=80, num_updates=6750, lr=2.8724e-06, gnorm=1.855, clip=80, loss_scale=32, train_wall=81, gb_free=6.8, wall=87357
2022-05-20 21:40:53 - progress_bar.py[line:274] - INFO: epoch 001:   6771 / 7081 loss=-0.004, score=1.44, ntokens=884.1, nsentences=80, sample_size=884.1, wps=109.4, ups=0.12, wpb=884.1, bsz=80, num_updates=6760, lr=2.86879e-06, gnorm=1.707, clip=90, loss_scale=32, train_wall=81, gb_free=6.8, wall=87437
2022-05-20 21:42:14 - progress_bar.py[line:274] - INFO: epoch 001:   6781 / 7081 loss=-0.006, score=1.451, ntokens=892, nsentences=80, sample_size=892, wps=109.6, ups=0.12, wpb=892, bsz=80, num_updates=6770, lr=2.86518e-06, gnorm=1.932, clip=80, loss_scale=32, train_wall=81, gb_free=6.8, wall=87519
2022-05-20 21:43:35 - progress_bar.py[line:274] - INFO: epoch 001:   6791 / 7081 loss=-0.005, score=1.417, ntokens=883.6, nsentences=80, sample_size=883.6, wps=109.5, ups=0.12, wpb=883.6, bsz=80, num_updates=6780, lr=2.86158e-06, gnorm=1.986, clip=100, loss_scale=32, train_wall=81, gb_free=6.8, wall=87599
2022-05-20 21:44:56 - progress_bar.py[line:274] - INFO: epoch 001:   6801 / 7081 loss=-0.008, score=1.421, ntokens=881.6, nsentences=80, sample_size=881.6, wps=108.8, ups=0.12, wpb=881.6, bsz=80, num_updates=6790, lr=2.85797e-06, gnorm=1.503, clip=100, loss_scale=32, train_wall=81, gb_free=6.8, wall=87680
2022-05-20 21:46:17 - progress_bar.py[line:274] - INFO: epoch 001:   6811 / 7081 loss=-0.005, score=1.456, ntokens=887.9, nsentences=80, sample_size=887.9, wps=109.6, ups=0.12, wpb=887.9, bsz=80, num_updates=6800, lr=2.85437e-06, gnorm=1.231, clip=80, loss_scale=32, train_wall=81, gb_free=6.8, wall=87762
2022-05-20 21:47:38 - progress_bar.py[line:274] - INFO: epoch 001:   6821 / 7081 loss=-0.006, score=1.496, ntokens=883.4, nsentences=80, sample_size=883.4, wps=109.2, ups=0.12, wpb=883.4, bsz=80, num_updates=6810, lr=2.85076e-06, gnorm=1.817, clip=90, loss_scale=32, train_wall=81, gb_free=6.8, wall=87842
2022-05-20 21:48:59 - progress_bar.py[line:274] - INFO: epoch 001:   6831 / 7081 loss=-0.004, score=1.358, ntokens=877.6, nsentences=80, sample_size=877.6, wps=108.2, ups=0.12, wpb=877.6, bsz=80, num_updates=6820, lr=2.84716e-06, gnorm=1.479, clip=90, loss_scale=32, train_wall=81, gb_free=6.8, wall=87923
2022-05-20 21:50:20 - progress_bar.py[line:274] - INFO: epoch 001:   6841 / 7081 loss=-0.007, score=1.39, ntokens=882.5, nsentences=80, sample_size=882.5, wps=108.4, ups=0.12, wpb=882.5, bsz=80, num_updates=6830, lr=2.84355e-06, gnorm=1.81, clip=90, loss_scale=32, train_wall=81, gb_free=6.8, wall=88005
2022-05-20 21:51:42 - progress_bar.py[line:274] - INFO: epoch 001:   6851 / 7081 loss=-0.007, score=1.456, ntokens=907.6, nsentences=80, sample_size=907.6, wps=111, ups=0.12, wpb=907.6, bsz=80, num_updates=6840, lr=2.83995e-06, gnorm=1.236, clip=60, loss_scale=32, train_wall=82, gb_free=6.8, wall=88087
2022-05-20 21:53:02 - progress_bar.py[line:274] - INFO: epoch 001:   6861 / 7081 loss=-0.004, score=1.539, ntokens=875.1, nsentences=80, sample_size=875.1, wps=109, ups=0.12, wpb=875.1, bsz=80, num_updates=6850, lr=2.83634e-06, gnorm=2.252, clip=90, loss_scale=32, train_wall=80, gb_free=6.8, wall=88167
2022-05-20 21:54:24 - progress_bar.py[line:274] - INFO: epoch 001:   6871 / 7081 loss=-0.008, score=1.519, ntokens=891, nsentences=80, sample_size=891, wps=109.2, ups=0.12, wpb=891, bsz=80, num_updates=6860, lr=2.83273e-06, gnorm=2.429, clip=100, loss_scale=32, train_wall=82, gb_free=6.8, wall=88249
2022-05-20 21:55:46 - progress_bar.py[line:274] - INFO: epoch 001:   6881 / 7081 loss=-0.009, score=1.504, ntokens=899.8, nsentences=80, sample_size=899.8, wps=109.7, ups=0.12, wpb=899.8, bsz=80, num_updates=6870, lr=2.82913e-06, gnorm=1.764, clip=70, loss_scale=32, train_wall=82, gb_free=6.8, wall=88331
2022-05-20 21:57:07 - progress_bar.py[line:274] - INFO: epoch 001:   6891 / 7081 loss=-0.007, score=1.425, ntokens=894.5, nsentences=80, sample_size=894.5, wps=110.5, ups=0.12, wpb=894.5, bsz=80, num_updates=6880, lr=2.82552e-06, gnorm=1.656, clip=90, loss_scale=32, train_wall=81, gb_free=6.8, wall=88412
2022-05-20 21:58:24 - progress_bar.py[line:274] - INFO: epoch 001:   6901 / 7081 loss=-0.004, score=1.387, ntokens=889.7, nsentences=80, sample_size=889.7, wps=115.7, ups=0.13, wpb=889.7, bsz=80, num_updates=6890, lr=2.82192e-06, gnorm=1.89, clip=90, loss_scale=32, train_wall=77, gb_free=6.8, wall=88489
2022-05-20 21:59:40 - progress_bar.py[line:274] - INFO: epoch 001:   6911 / 7081 loss=-0.007, score=1.545, ntokens=890.1, nsentences=80, sample_size=890.1, wps=116.2, ups=0.13, wpb=890.1, bsz=80, num_updates=6900, lr=2.81831e-06, gnorm=2.315, clip=100, loss_scale=32, train_wall=77, gb_free=6.8, wall=88565
2022-05-20 22:01:00 - progress_bar.py[line:274] - INFO: epoch 001:   6921 / 7081 loss=-0.005, score=1.475, ntokens=898.5, nsentences=80, sample_size=898.5, wps=112.2, ups=0.12, wpb=898.5, bsz=80, num_updates=6910, lr=2.81471e-06, gnorm=1.6, clip=90, loss_scale=32, train_wall=80, gb_free=6.8, wall=88645
2022-05-20 22:02:22 - progress_bar.py[line:274] - INFO: epoch 001:   6931 / 7081 loss=-0.009, score=1.463, ntokens=895.5, nsentences=80, sample_size=895.5, wps=110.1, ups=0.12, wpb=895.5, bsz=80, num_updates=6920, lr=2.8111e-06, gnorm=1.453, clip=80, loss_scale=32, train_wall=81, gb_free=6.8, wall=88727
2022-05-20 22:03:43 - progress_bar.py[line:274] - INFO: epoch 001:   6941 / 7081 loss=-0.005, score=1.4, ntokens=878.7, nsentences=80, sample_size=878.7, wps=108.5, ups=0.12, wpb=878.7, bsz=80, num_updates=6930, lr=2.8075e-06, gnorm=1.345, clip=70, loss_scale=32, train_wall=81, gb_free=6.7, wall=88807
2022-05-20 22:05:03 - progress_bar.py[line:274] - INFO: epoch 001:   6951 / 7081 loss=-0.006, score=1.486, ntokens=881.1, nsentences=80, sample_size=881.1, wps=109.6, ups=0.12, wpb=881.1, bsz=80, num_updates=6940, lr=2.80389e-06, gnorm=1.803, clip=80, loss_scale=32, train_wall=80, gb_free=6.8, wall=88888
2022-05-20 22:06:23 - progress_bar.py[line:274] - INFO: epoch 001:   6961 / 7081 loss=-0.004, score=1.402, ntokens=871.9, nsentences=80, sample_size=871.9, wps=109.5, ups=0.13, wpb=871.9, bsz=80, num_updates=6950, lr=2.80029e-06, gnorm=1.846, clip=90, loss_scale=32, train_wall=80, gb_free=6.8, wall=88967
2022-05-20 22:07:43 - progress_bar.py[line:274] - INFO: epoch 001:   6971 / 7081 loss=-0.004, score=1.492, ntokens=878.3, nsentences=80, sample_size=878.3, wps=109.1, ups=0.12, wpb=878.3, bsz=80, num_updates=6960, lr=2.79668e-06, gnorm=1.712, clip=90, loss_scale=32, train_wall=80, gb_free=6.8, wall=89048
2022-05-20 22:09:05 - progress_bar.py[line:274] - INFO: epoch 001:   6981 / 7081 loss=-0.009, score=1.41, ntokens=886.8, nsentences=80, sample_size=886.8, wps=109.1, ups=0.12, wpb=886.8, bsz=80, num_updates=6970, lr=2.79307e-06, gnorm=1.713, clip=100, loss_scale=32, train_wall=81, gb_free=6.8, wall=89129
2022-05-20 22:10:26 - progress_bar.py[line:274] - INFO: epoch 001:   6991 / 7081 loss=-0.006, score=1.46, ntokens=884.8, nsentences=80, sample_size=884.8, wps=108.7, ups=0.12, wpb=884.8, bsz=80, num_updates=6980, lr=2.78947e-06, gnorm=1.468, clip=90, loss_scale=32, train_wall=81, gb_free=6.8, wall=89211
2022-05-20 22:11:47 - progress_bar.py[line:274] - INFO: epoch 001:   7001 / 7081 loss=-0.007, score=1.492, ntokens=888, nsentences=80, sample_size=888, wps=109.7, ups=0.12, wpb=888, bsz=80, num_updates=6990, lr=2.78586e-06, gnorm=1.803, clip=90, loss_scale=32, train_wall=81, gb_free=6.8, wall=89292
2022-05-20 22:13:08 - progress_bar.py[line:274] - INFO: epoch 001:   7011 / 7081 loss=-0.004, score=1.385, ntokens=898.9, nsentences=80, sample_size=898.9, wps=110.4, ups=0.12, wpb=898.9, bsz=80, num_updates=7000, lr=2.78226e-06, gnorm=1.538, clip=90, loss_scale=32, train_wall=81, gb_free=6.8, wall=89373
2022-05-20 22:13:08 - train.py[line:436] - INFO: begin validation on "valid" subset
slice_id 0 seek offset 0
slice_id 0 seek offset 0
slice_id 1 seek offset 2500
slice_id 1 seek offset 2500
2022-05-20 22:53:06 - progress_bar.py[line:282] - INFO: epoch 001 | valid on 'valid' subset | loss -0.005 | score 1.296 | ntokens 111.057 | nsentences 10 | sample_size 111.057 | cider 1.389 | wps 115.8 | wpb 111.1 | bsz 10 | num_updates 7000 | best_cider 1.389
2022-05-20 22:53:06 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 1 @ 7000 updates
2022-05-20 22:53:06 - trainer.py[line:431] - INFO: Saving checkpoint to /database/jhkim/stage2_checkpoints//5e-6_2/checkpoint_1_7000.pt
2022-05-20 22:53:15 - trainer.py[line:441] - INFO: Finished saving checkpoint to /database/jhkim/stage2_checkpoints//5e-6_2/checkpoint_1_7000.pt
2022-05-20 22:54:39 - checkpoint_utils.py[line:135] - INFO: Saved checkpoint /database/jhkim/stage2_checkpoints//5e-6_2/checkpoint_1_7000.pt (epoch 1 @ 7000 updates, score 1.389) (writing took 93.15963493008167 seconds)
2022-05-20 22:56:00 - progress_bar.py[line:274] - INFO: epoch 001:   7021 / 7081 loss=-0.005, score=1.507, ntokens=888.2, nsentences=80, sample_size=888.2, wps=3.5, ups=0, wpb=888.2, bsz=80, num_updates=7010, lr=2.77865e-06, gnorm=1.524, clip=80, loss_scale=32, train_wall=80, gb_free=6.8, wall=91945
2022-05-20 22:57:20 - progress_bar.py[line:274] - INFO: epoch 001:   7031 / 7081 loss=-0.007, score=1.431, ntokens=886.3, nsentences=80, sample_size=886.3, wps=110.7, ups=0.12, wpb=886.3, bsz=80, num_updates=7020, lr=2.77505e-06, gnorm=1.576, clip=80, loss_scale=32, train_wall=80, gb_free=6.8, wall=92025
2022-05-20 22:58:41 - progress_bar.py[line:274] - INFO: epoch 001:   7041 / 7081 loss=-0.006, score=1.36, ntokens=890.5, nsentences=80, sample_size=890.5, wps=110.5, ups=0.12, wpb=890.5, bsz=80, num_updates=7030, lr=2.77144e-06, gnorm=1.512, clip=80, loss_scale=32, train_wall=81, gb_free=6.8, wall=92105
2022-05-20 23:00:02 - progress_bar.py[line:274] - INFO: epoch 001:   7051 / 7081 loss=-0.007, score=1.445, ntokens=889.2, nsentences=80, sample_size=889.2, wps=109, ups=0.12, wpb=889.2, bsz=80, num_updates=7040, lr=2.76784e-06, gnorm=1.693, clip=100, loss_scale=32, train_wall=82, gb_free=6.8, wall=92187
2022-05-20 23:01:23 - progress_bar.py[line:274] - INFO: epoch 001:   7061 / 7081 loss=-0.005, score=1.409, ntokens=898, nsentences=80, sample_size=898, wps=110.7, ups=0.12, wpb=898, bsz=80, num_updates=7050, lr=2.76423e-06, gnorm=1.307, clip=70, loss_scale=32, train_wall=81, gb_free=6.8, wall=92268
2022-05-20 23:02:44 - progress_bar.py[line:274] - INFO: epoch 001:   7071 / 7081 loss=-0.006, score=1.577, ntokens=878.9, nsentences=80, sample_size=878.9, wps=108.6, ups=0.12, wpb=878.9, bsz=80, num_updates=7060, lr=2.76062e-06, gnorm=1.539, clip=90, loss_scale=32, train_wall=81, gb_free=6.8, wall=92349
2022-05-20 23:04:01 - progress_bar.py[line:274] - INFO: epoch 001:   7081 / 7081 loss=-0.004, score=1.513, ntokens=840, nsentences=76, sample_size=840, wps=109.8, ups=0.13, wpb=840, bsz=76, num_updates=7070, lr=2.75702e-06, gnorm=1.629, clip=100, loss_scale=32, train_wall=76, gb_free=6.8, wall=92425
2022-05-20 23:04:01 - train.py[line:436] - INFO: begin validation on "valid" subset
slice_id 0 seek offset 0
slice_id 0 seek offset 0
slice_id 1 seek offset 2500
slice_id 1 seek offset 2500
2022-05-20 23:43:59 - progress_bar.py[line:282] - INFO: epoch 001 | valid on 'valid' subset | loss -0.005 | score 1.296 | ntokens 111.063 | nsentences 10 | sample_size 111.063 | cider 1.389 | wps 115.8 | wpb 111.1 | bsz 10 | num_updates 7070 | best_cider 1.389
2022-05-20 23:43:59 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 1 @ 7070 updates
local datafile ../../dataset/caption_data/caption_stage1_train_ct2.tsv slice_id 1 begin to initialize row_count and line_idx-to-offset mapping
2022-05-20 23:43:59 - trainer.py[line:431] - INFO: Saving checkpoint to /database/jhkim/stage2_checkpoints//5e-6_2/checkpoint_best.pt
local datafile ../../dataset/caption_data/caption_stage1_train_ct2.tsv slice_id 1 finished initializing row_count and line_idx-to-offset mapping
file ../../dataset/caption_data/caption_stage1_train_ct2.tsv slice_id 1 row count 56643 total row count 113287
slice_id 1 seek offset 56644
2022-05-20 23:44:34 - trainer.py[line:441] - INFO: Finished saving checkpoint to /database/jhkim/stage2_checkpoints//5e-6_2/checkpoint_best.pt
2022-05-20 23:45:34 - checkpoint_utils.py[line:135] - INFO: Saved checkpoint /database/jhkim/stage2_checkpoints//5e-6_2/checkpoint_best.pt (epoch 1 @ 7070 updates, score 1.389) (writing took 95.46535028610379 seconds)
2022-05-20 23:45:34 - train.py[line:323] - INFO: end of epoch 1 (average epoch stats below)
2022-05-20 23:45:34 - progress_bar.py[line:282] - INFO: epoch 001 | loss -0.006 | score 1.443 | ntokens 885.139 | nsentences 79.994 | sample_size 885.139 | wps 65.9 | ups 0.07 | wpb 885.1 | bsz 80 | num_updates 7070 | lr 2.75702e-06 | gnorm 1.663 | clip 84.2 | loss_scale 32 | train_wall 57244 | gb_free 6.8 | wall 94919
2022-05-20 23:45:34 - trainer.py[line:639] - INFO: loading train data for epoch 2
local datafile ../../dataset/caption_data/caption_stage1_train_ct2.tsv slice_id 0 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../dataset/caption_data/caption_stage1_train_ct2.tsv slice_id 0 finished initializing row_count and line_idx-to-offset mapping
file ../../dataset/caption_data/caption_stage1_train_ct2.tsv slice_id 0 row count 56644 total row count 113287
slice_id 0 seek offset 0
2022-05-20 23:45:37 - trainer.py[line:703] - INFO: begin training epoch 2
2022-05-20 23:45:37 - train.py[line:296] - INFO: Start iterating over samples
2022-05-20 23:46:58 - progress_bar.py[line:274] - INFO: epoch 002:     10 / 7081 loss=-0.001, score=1.338, ntokens=902.1, nsentences=80, sample_size=902.1, wps=3.5, ups=0, wpb=902.1, bsz=80, num_updates=7080, lr=2.75341e-06, gnorm=1.843, clip=90, loss_scale=32, train_wall=81, gb_free=6.8, wall=95003
2022-05-20 23:48:19 - progress_bar.py[line:274] - INFO: epoch 002:     20 / 7081 loss=-0.006, score=1.426, ntokens=882.4, nsentences=80, sample_size=882.4, wps=109, ups=0.12, wpb=882.4, bsz=80, num_updates=7090, lr=2.74981e-06, gnorm=1.275, clip=80, loss_scale=32, train_wall=81, gb_free=6.8, wall=95084
2022-05-20 23:49:40 - progress_bar.py[line:274] - INFO: epoch 002:     30 / 7081 loss=-0.008, score=1.427, ntokens=872.6, nsentences=80, sample_size=872.6, wps=108.3, ups=0.12, wpb=872.6, bsz=80, num_updates=7100, lr=2.7462e-06, gnorm=1.669, clip=80, loss_scale=32, train_wall=81, gb_free=6.8, wall=95164
2022-05-20 23:51:01 - progress_bar.py[line:274] - INFO: epoch 002:     40 / 7081 loss=-0.005, score=1.351, ntokens=882.5, nsentences=80, sample_size=882.5, wps=108.9, ups=0.12, wpb=882.5, bsz=80, num_updates=7110, lr=2.7426e-06, gnorm=1.942, clip=100, loss_scale=32, train_wall=81, gb_free=6.8, wall=95246
2022-05-20 23:52:22 - progress_bar.py[line:274] - INFO: epoch 002:     50 / 7081 loss=-0.007, score=1.43, ntokens=882.1, nsentences=80, sample_size=882.1, wps=108.7, ups=0.12, wpb=882.1, bsz=80, num_updates=7120, lr=2.73899e-06, gnorm=1.619, clip=90, loss_scale=32, train_wall=81, gb_free=6.8, wall=95327
2022-05-20 23:53:43 - progress_bar.py[line:274] - INFO: epoch 002:     60 / 7081 loss=-0.004, score=1.426, ntokens=880.6, nsentences=80, sample_size=880.6, wps=108.8, ups=0.12, wpb=880.6, bsz=80, num_updates=7130, lr=2.73539e-06, gnorm=1.87, clip=100, loss_scale=32, train_wall=81, gb_free=6.8, wall=95408
2022-05-20 23:55:04 - progress_bar.py[line:274] - INFO: epoch 002:     70 / 7081 loss=-0.003, score=1.433, ntokens=895.8, nsentences=80, sample_size=895.8, wps=109.9, ups=0.12, wpb=895.8, bsz=80, num_updates=7140, lr=2.73178e-06, gnorm=1.389, clip=90, loss_scale=32, train_wall=81, gb_free=6.8, wall=95489
2022-05-20 23:56:26 - progress_bar.py[line:274] - INFO: epoch 002:     80 / 7081 loss=-0.006, score=1.517, ntokens=885.1, nsentences=80, sample_size=885.1, wps=108.3, ups=0.12, wpb=885.1, bsz=80, num_updates=7150, lr=2.72818e-06, gnorm=1.53, clip=80, loss_scale=32, train_wall=82, gb_free=6.8, wall=95571
2022-05-20 23:57:47 - progress_bar.py[line:274] - INFO: epoch 002:     90 / 7081 loss=-0.005, score=1.517, ntokens=885.1, nsentences=80, sample_size=885.1, wps=109.6, ups=0.12, wpb=885.1, bsz=80, num_updates=7160, lr=2.72457e-06, gnorm=2.467, clip=100, loss_scale=32, train_wall=81, gb_free=6.8, wall=95652
2022-05-20 23:59:08 - progress_bar.py[line:274] - INFO: epoch 002:    100 / 7081 loss=-0.005, score=1.443, ntokens=882.2, nsentences=80, sample_size=882.2, wps=108.5, ups=0.12, wpb=882.2, bsz=80, num_updates=7170, lr=2.72096e-06, gnorm=2.046, clip=80, loss_scale=32, train_wall=81, gb_free=6.8, wall=95733
2022-05-21 00:00:29 - progress_bar.py[line:274] - INFO: epoch 002:    110 / 7081 loss=-0.004, score=1.459, ntokens=884.5, nsentences=80, sample_size=884.5, wps=109.5, ups=0.12, wpb=884.5, bsz=80, num_updates=7180, lr=2.71736e-06, gnorm=2.408, clip=100, loss_scale=64, train_wall=81, gb_free=6.8, wall=95814
2022-05-21 00:01:51 - progress_bar.py[line:274] - INFO: epoch 002:    120 / 7081 loss=-0.005, score=1.411, ntokens=900, nsentences=80, sample_size=900, wps=110.1, ups=0.12, wpb=900, bsz=80, num_updates=7190, lr=2.71375e-06, gnorm=1.711, clip=60, loss_scale=64, train_wall=82, gb_free=6.8, wall=95895
2022-05-21 00:03:12 - progress_bar.py[line:274] - INFO: epoch 002:    130 / 7081 loss=-0.007, score=1.406, ntokens=881, nsentences=80, sample_size=881, wps=108.6, ups=0.12, wpb=881, bsz=80, num_updates=7200, lr=2.71015e-06, gnorm=1.726, clip=80, loss_scale=64, train_wall=81, gb_free=6.8, wall=95977
2022-05-21 00:04:33 - progress_bar.py[line:274] - INFO: epoch 002:    140 / 7081 loss=-0.005, score=1.378, ntokens=886.9, nsentences=80, sample_size=886.9, wps=109.2, ups=0.12, wpb=886.9, bsz=80, num_updates=7210, lr=2.70654e-06, gnorm=2.05, clip=100, loss_scale=64, train_wall=81, gb_free=6.8, wall=96058
2022-05-21 00:05:54 - progress_bar.py[line:274] - INFO: epoch 002:    150 / 7081 loss=-0.004, score=1.494, ntokens=886.9, nsentences=80, sample_size=886.9, wps=109.2, ups=0.12, wpb=886.9, bsz=80, num_updates=7220, lr=2.70294e-06, gnorm=1.809, clip=90, loss_scale=64, train_wall=81, gb_free=6.8, wall=96139
2022-05-21 00:07:15 - progress_bar.py[line:274] - INFO: epoch 002:    160 / 7081 loss=-0.005, score=1.342, ntokens=876.5, nsentences=80, sample_size=876.5, wps=108.2, ups=0.12, wpb=876.5, bsz=80, num_updates=7230, lr=2.69933e-06, gnorm=1.494, clip=60, loss_scale=64, train_wall=81, gb_free=6.8, wall=96220
2022-05-21 00:08:34 - progress_bar.py[line:274] - INFO: epoch 002:    170 / 7081 loss=-0.003, score=1.434, ntokens=895, nsentences=80, sample_size=895, wps=114.2, ups=0.13, wpb=895, bsz=80, num_updates=7240, lr=2.69573e-06, gnorm=1.438, clip=70, loss_scale=64, train_wall=78, gb_free=6.8, wall=96298
2022-05-21 00:09:51 - progress_bar.py[line:274] - INFO: epoch 002:    180 / 7081 loss=-0.007, score=1.444, ntokens=888.9, nsentences=80, sample_size=888.9, wps=115, ups=0.13, wpb=888.9, bsz=80, num_updates=7250, lr=2.69212e-06, gnorm=1.54, clip=80, loss_scale=64, train_wall=77, gb_free=6.8, wall=96376
2022-05-21 00:11:10 - progress_bar.py[line:274] - INFO: epoch 002:    190 / 7081 loss=-0.003, score=1.371, ntokens=894.9, nsentences=80, sample_size=894.9, wps=113.9, ups=0.13, wpb=894.9, bsz=80, num_updates=7260, lr=2.68851e-06, gnorm=2.042, clip=80, loss_scale=64, train_wall=78, gb_free=6.8, wall=96454
2022-05-21 00:12:31 - progress_bar.py[line:274] - INFO: epoch 002:    200 / 7081 loss=-0.007, score=1.416, ntokens=881.4, nsentences=80, sample_size=881.4, wps=108.5, ups=0.12, wpb=881.4, bsz=80, num_updates=7270, lr=2.68491e-06, gnorm=2.146, clip=90, loss_scale=64, train_wall=81, gb_free=6.8, wall=96535
2022-05-21 00:13:52 - progress_bar.py[line:274] - INFO: epoch 002:    210 / 7081 loss=-0.004, score=1.477, ntokens=897.6, nsentences=80, sample_size=897.6, wps=110.6, ups=0.12, wpb=897.6, bsz=80, num_updates=7280, lr=2.6813e-06, gnorm=1.739, clip=70, loss_scale=64, train_wall=81, gb_free=6.8, wall=96617
2022-05-21 00:15:13 - progress_bar.py[line:274] - INFO: epoch 002:    220 / 7081 loss=-0.004, score=1.374, ntokens=894.3, nsentences=80, sample_size=894.3, wps=109.8, ups=0.12, wpb=894.3, bsz=80, num_updates=7290, lr=2.6777e-06, gnorm=1.191, clip=70, loss_scale=64, train_wall=81, gb_free=6.8, wall=96698
2022-05-21 00:16:34 - progress_bar.py[line:274] - INFO: epoch 002:    230 / 7081 loss=-0.004, score=1.512, ntokens=902.2, nsentences=80, sample_size=902.2, wps=111.4, ups=0.12, wpb=902.2, bsz=80, num_updates=7300, lr=2.67409e-06, gnorm=1.802, clip=100, loss_scale=64, train_wall=81, gb_free=6.8, wall=96779
2022-05-21 00:17:55 - progress_bar.py[line:274] - INFO: epoch 002:    240 / 7081 loss=-0.006, score=1.479, ntokens=885.2, nsentences=80, sample_size=885.2, wps=109.4, ups=0.12, wpb=885.2, bsz=80, num_updates=7310, lr=2.67049e-06, gnorm=1.576, clip=80, loss_scale=64, train_wall=81, gb_free=6.8, wall=96860
2022-05-21 00:19:16 - progress_bar.py[line:274] - INFO: epoch 002:    250 / 7081 loss=-0.004, score=1.388, ntokens=884.6, nsentences=80, sample_size=884.6, wps=109.1, ups=0.12, wpb=884.6, bsz=80, num_updates=7320, lr=2.66688e-06, gnorm=1.39, clip=90, loss_scale=64, train_wall=81, gb_free=6.8, wall=96941
2022-05-21 00:20:38 - progress_bar.py[line:274] - INFO: epoch 002:    260 / 7081 loss=-0.008, score=1.435, ntokens=890.4, nsentences=80, sample_size=890.4, wps=109.8, ups=0.12, wpb=890.4, bsz=80, num_updates=7330, lr=2.66328e-06, gnorm=1.895, clip=90, loss_scale=64, train_wall=81, gb_free=6.8, wall=97022
2022-05-21 00:21:58 - progress_bar.py[line:274] - INFO: epoch 002:    270 / 7081 loss=-0.006, score=1.566, ntokens=875.4, nsentences=80, sample_size=875.4, wps=108.5, ups=0.12, wpb=875.4, bsz=80, num_updates=7340, lr=2.65967e-06, gnorm=1.471, clip=70, loss_scale=64, train_wall=81, gb_free=6.8, wall=97103
2022-05-21 00:23:19 - progress_bar.py[line:274] - INFO: epoch 002:    280 / 7081 loss=-0.005, score=1.331, ntokens=891.5, nsentences=80, sample_size=891.5, wps=110.6, ups=0.12, wpb=891.5, bsz=80, num_updates=7350, lr=2.65607e-06, gnorm=1.717, clip=100, loss_scale=64, train_wall=81, gb_free=6.8, wall=97183
2022-05-21 00:24:40 - progress_bar.py[line:274] - INFO: epoch 002:    290 / 7081 loss=-0.004, score=1.421, ntokens=884.6, nsentences=80, sample_size=884.6, wps=109.4, ups=0.12, wpb=884.6, bsz=80, num_updates=7360, lr=2.65246e-06, gnorm=1.66, clip=100, loss_scale=64, train_wall=81, gb_free=6.8, wall=97264
2022-05-21 00:26:01 - progress_bar.py[line:274] - INFO: epoch 002:    300 / 7081 loss=-0.012, score=1.447, ntokens=899.5, nsentences=80, sample_size=899.5, wps=110.2, ups=0.12, wpb=899.5, bsz=80, num_updates=7370, lr=2.64885e-06, gnorm=1.597, clip=70, loss_scale=64, train_wall=82, gb_free=6.7, wall=97346
2022-05-21 00:27:22 - progress_bar.py[line:274] - INFO: epoch 002:    310 / 7081 loss=-0.007, score=1.527, ntokens=887.8, nsentences=80, sample_size=887.8, wps=109.5, ups=0.12, wpb=887.8, bsz=80, num_updates=7380, lr=2.64525e-06, gnorm=1.261, clip=60, loss_scale=64, train_wall=81, gb_free=6.7, wall=97427
2022-05-21 00:28:43 - progress_bar.py[line:274] - INFO: epoch 002:    320 / 7081 loss=-0.007, score=1.367, ntokens=890.3, nsentences=80, sample_size=890.3, wps=110.1, ups=0.12, wpb=890.3, bsz=80, num_updates=7390, lr=2.64164e-06, gnorm=1.519, clip=60, loss_scale=64, train_wall=81, gb_free=6.8, wall=97508
2022-05-21 00:30:05 - progress_bar.py[line:274] - INFO: epoch 002:    330 / 7081 loss=-0.007, score=1.454, ntokens=887.1, nsentences=80, sample_size=887.1, wps=108.9, ups=0.12, wpb=887.1, bsz=80, num_updates=7400, lr=2.63804e-06, gnorm=1.591, clip=90, loss_scale=64, train_wall=81, gb_free=6.8, wall=97589
2022-05-21 00:31:26 - progress_bar.py[line:274] - INFO: epoch 002:    340 / 7081 loss=-0.005, score=1.415, ntokens=896, nsentences=80, sample_size=896, wps=110.3, ups=0.12, wpb=896, bsz=80, num_updates=7410, lr=2.63443e-06, gnorm=1.522, clip=100, loss_scale=64, train_wall=81, gb_free=6.8, wall=97671
2022-05-21 00:32:47 - progress_bar.py[line:274] - INFO: epoch 002:    350 / 7081 loss=-0.003, score=1.408, ntokens=887.8, nsentences=80, sample_size=887.8, wps=108.9, ups=0.12, wpb=887.8, bsz=80, num_updates=7420, lr=2.63083e-06, gnorm=1.617, clip=100, loss_scale=64, train_wall=81, gb_free=6.8, wall=97752
2022-05-21 00:34:07 - progress_bar.py[line:274] - INFO: epoch 002:    360 / 7081 loss=-0.004, score=1.429, ntokens=889.8, nsentences=80, sample_size=889.8, wps=111.3, ups=0.13, wpb=889.8, bsz=80, num_updates=7430, lr=2.62722e-06, gnorm=1.641, clip=100, loss_scale=64, train_wall=80, gb_free=6.8, wall=97832
2022-05-21 00:35:24 - progress_bar.py[line:274] - INFO: epoch 002:    370 / 7081 loss=-0.004, score=1.4, ntokens=878.6, nsentences=80, sample_size=878.6, wps=114.3, ups=0.13, wpb=878.6, bsz=80, num_updates=7440, lr=2.62362e-06, gnorm=1.551, clip=90, loss_scale=64, train_wall=77, gb_free=6.8, wall=97909
2022-05-21 00:36:41 - progress_bar.py[line:274] - INFO: epoch 002:    380 / 7081 loss=-0.005, score=1.521, ntokens=890.2, nsentences=80, sample_size=890.2, wps=116.3, ups=0.13, wpb=890.2, bsz=80, num_updates=7450, lr=2.62001e-06, gnorm=1.473, clip=80, loss_scale=64, train_wall=76, gb_free=6.8, wall=97986
2022-05-21 00:38:02 - progress_bar.py[line:274] - INFO: epoch 002:    390 / 7081 loss=-0.006, score=1.535, ntokens=889.6, nsentences=80, sample_size=889.6, wps=109.4, ups=0.12, wpb=889.6, bsz=80, num_updates=7460, lr=2.61641e-06, gnorm=1.766, clip=80, loss_scale=64, train_wall=81, gb_free=6.8, wall=98067
2022-05-21 00:39:24 - progress_bar.py[line:274] - INFO: epoch 002:    400 / 7081 loss=-0.005, score=1.624, ntokens=909.5, nsentences=80, sample_size=909.5, wps=111, ups=0.12, wpb=909.5, bsz=80, num_updates=7470, lr=2.6128e-06, gnorm=1.396, clip=70, loss_scale=64, train_wall=82, gb_free=6.8, wall=98149
2022-05-21 00:40:46 - progress_bar.py[line:274] - INFO: epoch 002:    410 / 7081 loss=-0.009, score=1.44, ntokens=886.8, nsentences=80, sample_size=886.8, wps=108.9, ups=0.12, wpb=886.8, bsz=80, num_updates=7480, lr=2.60919e-06, gnorm=1.381, clip=90, loss_scale=64, train_wall=81, gb_free=6.8, wall=98230
2022-05-21 00:42:06 - progress_bar.py[line:274] - INFO: epoch 002:    420 / 7081 loss=-0.005, score=1.319, ntokens=879, nsentences=80, sample_size=879, wps=108.9, ups=0.12, wpb=879, bsz=80, num_updates=7490, lr=2.60559e-06, gnorm=1.238, clip=70, loss_scale=64, train_wall=81, gb_free=6.8, wall=98311
2022-05-21 00:43:27 - progress_bar.py[line:274] - INFO: epoch 002:    430 / 7081 loss=-0.008, score=1.449, ntokens=893.4, nsentences=80, sample_size=893.4, wps=110.3, ups=0.12, wpb=893.4, bsz=80, num_updates=7500, lr=2.60198e-06, gnorm=1.782, clip=80, loss_scale=64, train_wall=81, gb_free=6.8, wall=98392
2022-05-21 00:43:27 - train.py[line:436] - INFO: begin validation on "valid" subset
slice_id 0 seek offset 0
slice_id 1 seek offset 2500
slice_id 1 seek offset 2500
slice_id 0 seek offset 0
2022-05-21 01:23:37 - progress_bar.py[line:282] - INFO: epoch 002 | valid on 'valid' subset | loss -0.005 | score 1.296 | ntokens 111.423 | nsentences 10 | sample_size 111.423 | cider 1.39 | wps 115.6 | wpb 111.4 | bsz 10 | num_updates 7500 | best_cider 1.39
2022-05-21 01:23:37 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 2 @ 7500 updates
2022-05-21 01:23:37 - trainer.py[line:431] - INFO: Saving checkpoint to /database/jhkim/stage2_checkpoints//5e-6_2/checkpoint_2_7500.pt
2022-05-21 01:23:46 - trainer.py[line:441] - INFO: Finished saving checkpoint to /database/jhkim/stage2_checkpoints//5e-6_2/checkpoint_2_7500.pt
2022-05-21 01:25:16 - checkpoint_utils.py[line:135] - INFO: Saved checkpoint /database/jhkim/stage2_checkpoints//5e-6_2/checkpoint_2_7500.pt (epoch 2 @ 7500 updates, score 1.39) (writing took 98.91422584606335 seconds)
2022-05-21 01:26:34 - progress_bar.py[line:274] - INFO: epoch 002:    440 / 7081 loss=-0.005, score=1.305, ntokens=875.4, nsentences=80, sample_size=875.4, wps=3.4, ups=0, wpb=875.4, bsz=80, num_updates=7510, lr=2.59838e-06, gnorm=1.771, clip=80, loss_scale=64, train_wall=76, gb_free=6.7, wall=100978
2022-05-21 01:27:51 - progress_bar.py[line:274] - INFO: epoch 002:    450 / 7081 loss=-0.007, score=1.544, ntokens=902.4, nsentences=80, sample_size=902.4, wps=116.2, ups=0.13, wpb=902.4, bsz=80, num_updates=7520, lr=2.59477e-06, gnorm=1.832, clip=90, loss_scale=64, train_wall=78, gb_free=6.8, wall=101056
2022-05-21 01:29:11 - progress_bar.py[line:274] - INFO: epoch 002:    460 / 7081 loss=-0.005, score=1.425, ntokens=898.3, nsentences=80, sample_size=898.3, wps=112.9, ups=0.13, wpb=898.3, bsz=80, num_updates=7530, lr=2.59117e-06, gnorm=1.432, clip=90, loss_scale=64, train_wall=79, gb_free=6.8, wall=101135
2022-05-21 01:30:31 - progress_bar.py[line:274] - INFO: epoch 002:    470 / 7081 loss=-0.007, score=1.308, ntokens=883.2, nsentences=80, sample_size=883.2, wps=109.7, ups=0.12, wpb=883.2, bsz=80, num_updates=7540, lr=2.58756e-06, gnorm=1.526, clip=70, loss_scale=64, train_wall=80, gb_free=6.7, wall=101216
2022-05-21 01:31:52 - progress_bar.py[line:274] - INFO: epoch 002:    480 / 7081 loss=-0.005, score=1.509, ntokens=880.8, nsentences=80, sample_size=880.8, wps=108.9, ups=0.12, wpb=880.8, bsz=80, num_updates=7550, lr=2.58396e-06, gnorm=1.774, clip=90, loss_scale=64, train_wall=81, gb_free=6.8, wall=101297
2022-05-21 01:33:13 - progress_bar.py[line:274] - INFO: epoch 002:    490 / 7081 loss=-0.007, score=1.396, ntokens=894.3, nsentences=80, sample_size=894.3, wps=110.1, ups=0.12, wpb=894.3, bsz=80, num_updates=7560, lr=2.58035e-06, gnorm=1.386, clip=90, loss_scale=64, train_wall=81, gb_free=6.8, wall=101378
2022-05-21 01:34:34 - progress_bar.py[line:274] - INFO: epoch 002:    500 / 7081 loss=-0.007, score=1.473, ntokens=884.4, nsentences=80, sample_size=884.4, wps=109.2, ups=0.12, wpb=884.4, bsz=80, num_updates=7570, lr=2.57674e-06, gnorm=1.589, clip=80, loss_scale=64, train_wall=81, gb_free=6.7, wall=101459
2022-05-21 01:35:55 - progress_bar.py[line:274] - INFO: epoch 002:    510 / 7081 loss=-0.007, score=1.5, ntokens=886.2, nsentences=80, sample_size=886.2, wps=109.8, ups=0.12, wpb=886.2, bsz=80, num_updates=7580, lr=2.57314e-06, gnorm=1.583, clip=100, loss_scale=64, train_wall=81, gb_free=6.8, wall=101540
2022-05-21 01:37:16 - progress_bar.py[line:274] - INFO: epoch 002:    520 / 7081 loss=-0.006, score=1.323, ntokens=895.6, nsentences=80, sample_size=895.6, wps=111, ups=0.12, wpb=895.6, bsz=80, num_updates=7590, lr=2.56953e-06, gnorm=1.482, clip=80, loss_scale=64, train_wall=81, gb_free=6.8, wall=101621
2022-05-21 01:38:37 - progress_bar.py[line:274] - INFO: epoch 002:    530 / 7081 loss=-0.006, score=1.391, ntokens=892.2, nsentences=80, sample_size=892.2, wps=109.5, ups=0.12, wpb=892.2, bsz=80, num_updates=7600, lr=2.56593e-06, gnorm=1.532, clip=90, loss_scale=64, train_wall=81, gb_free=6.8, wall=101702
2022-05-21 01:39:59 - progress_bar.py[line:274] - INFO: epoch 002:    540 / 7081 loss=-0.004, score=1.415, ntokens=883.2, nsentences=80, sample_size=883.2, wps=108.9, ups=0.12, wpb=883.2, bsz=80, num_updates=7610, lr=2.56232e-06, gnorm=1.58, clip=80, loss_scale=64, train_wall=81, gb_free=6.8, wall=101783
2022-05-21 01:41:19 - progress_bar.py[line:274] - INFO: epoch 002:    550 / 7081 loss=-0.006, score=1.391, ntokens=881.5, nsentences=80, sample_size=881.5, wps=109.2, ups=0.12, wpb=881.5, bsz=80, num_updates=7620, lr=2.55872e-06, gnorm=1.6, clip=100, loss_scale=64, train_wall=81, gb_free=6.8, wall=101864
2022-05-21 01:42:41 - progress_bar.py[line:274] - INFO: epoch 002:    560 / 7081 loss=-0.005, score=1.456, ntokens=893.1, nsentences=80, sample_size=893.1, wps=109.8, ups=0.12, wpb=893.1, bsz=80, num_updates=7630, lr=2.55511e-06, gnorm=1.438, clip=70, loss_scale=64, train_wall=81, gb_free=6.8, wall=101945
2022-05-21 01:44:02 - progress_bar.py[line:274] - INFO: epoch 002:    570 / 7081 loss=-0.006, score=1.47, ntokens=901.7, nsentences=80, sample_size=901.7, wps=111.2, ups=0.12, wpb=901.7, bsz=80, num_updates=7640, lr=2.55151e-06, gnorm=1.76, clip=100, loss_scale=64, train_wall=81, gb_free=6.8, wall=102026
2022-05-21 01:45:23 - progress_bar.py[line:274] - INFO: epoch 002:    580 / 7081 loss=-0.006, score=1.506, ntokens=898.1, nsentences=80, sample_size=898.1, wps=110.2, ups=0.12, wpb=898.1, bsz=80, num_updates=7650, lr=2.5479e-06, gnorm=1.65, clip=80, loss_scale=64, train_wall=81, gb_free=6.7, wall=102108
2022-05-21 01:46:45 - progress_bar.py[line:274] - INFO: epoch 002:    590 / 7081 loss=-0.008, score=1.448, ntokens=899.1, nsentences=80, sample_size=899.1, wps=110.2, ups=0.12, wpb=899.1, bsz=80, num_updates=7660, lr=2.5443e-06, gnorm=1.589, clip=90, loss_scale=64, train_wall=82, gb_free=6.8, wall=102189
2022-05-21 01:48:06 - progress_bar.py[line:274] - INFO: epoch 002:    600 / 7081 loss=-0.006, score=1.53, ntokens=890.8, nsentences=80, sample_size=890.8, wps=109.2, ups=0.12, wpb=890.8, bsz=80, num_updates=7670, lr=2.54069e-06, gnorm=1.943, clip=90, loss_scale=64, train_wall=82, gb_free=6.8, wall=102271
2022-05-21 01:49:28 - progress_bar.py[line:274] - INFO: epoch 002:    610 / 7081 loss=-0.006, score=1.443, ntokens=899.5, nsentences=80, sample_size=899.5, wps=110.5, ups=0.12, wpb=899.5, bsz=80, num_updates=7680, lr=2.53708e-06, gnorm=1.863, clip=90, loss_scale=64, train_wall=81, gb_free=6.8, wall=102352
2022-05-21 01:50:49 - progress_bar.py[line:274] - INFO: epoch 002:    620 / 7081 loss=-0.006, score=1.569, ntokens=895.9, nsentences=80, sample_size=895.9, wps=110.1, ups=0.12, wpb=895.9, bsz=80, num_updates=7690, lr=2.53348e-06, gnorm=1.444, clip=90, loss_scale=128, train_wall=81, gb_free=6.8, wall=102434
2022-05-21 01:51:22 - trainer.py[line:922] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-05-21 01:52:17 - progress_bar.py[line:274] - INFO: epoch 002:    631 / 7081 loss=-0.003, score=1.474, ntokens=903.7, nsentences=80, sample_size=903.7, wps=102.7, ups=0.11, wpb=903.7, bsz=80, num_updates=7700, lr=2.52987e-06, gnorm=1.711, clip=100, loss_scale=64, train_wall=88, gb_free=6.8, wall=102522
2022-05-21 01:53:34 - progress_bar.py[line:274] - INFO: epoch 002:    641 / 7081 loss=-0.005, score=1.472, ntokens=892.7, nsentences=80, sample_size=892.7, wps=116.3, ups=0.13, wpb=892.7, bsz=80, num_updates=7710, lr=2.52627e-06, gnorm=2.098, clip=90, loss_scale=64, train_wall=77, gb_free=6.7, wall=102599
2022-05-21 01:54:52 - progress_bar.py[line:274] - INFO: epoch 002:    651 / 7081 loss=-0.005, score=1.451, ntokens=896.8, nsentences=80, sample_size=896.8, wps=115.6, ups=0.13, wpb=896.8, bsz=80, num_updates=7720, lr=2.52266e-06, gnorm=1.362, clip=70, loss_scale=64, train_wall=77, gb_free=6.8, wall=102676
2022-05-21 01:56:13 - progress_bar.py[line:274] - INFO: epoch 002:    661 / 7081 loss=-0.005, score=1.369, ntokens=889, nsentences=80, sample_size=889, wps=109.5, ups=0.12, wpb=889, bsz=80, num_updates=7730, lr=2.51906e-06, gnorm=1.424, clip=100, loss_scale=64, train_wall=81, gb_free=6.8, wall=102757
2022-05-21 01:57:34 - progress_bar.py[line:274] - INFO: epoch 002:    671 / 7081 loss=-0.004, score=1.478, ntokens=884.7, nsentences=80, sample_size=884.7, wps=109.5, ups=0.12, wpb=884.7, bsz=80, num_updates=7740, lr=2.51545e-06, gnorm=1.71, clip=80, loss_scale=64, train_wall=81, gb_free=6.8, wall=102838
2022-05-21 01:58:56 - progress_bar.py[line:274] - INFO: epoch 002:    681 / 7081 loss=-0.004, score=1.472, ntokens=890.8, nsentences=80, sample_size=890.8, wps=108.5, ups=0.12, wpb=890.8, bsz=80, num_updates=7750, lr=2.51185e-06, gnorm=1.511, clip=80, loss_scale=64, train_wall=82, gb_free=6.8, wall=102920
2022-05-21 02:00:17 - progress_bar.py[line:274] - INFO: epoch 002:    691 / 7081 loss=-0.005, score=1.412, ntokens=891.1, nsentences=80, sample_size=891.1, wps=109.6, ups=0.12, wpb=891.1, bsz=80, num_updates=7760, lr=2.50824e-06, gnorm=1.71, clip=100, loss_scale=64, train_wall=81, gb_free=6.8, wall=103002
2022-05-21 02:01:38 - progress_bar.py[line:274] - INFO: epoch 002:    701 / 7081 loss=-0.006, score=1.444, ntokens=897.8, nsentences=80, sample_size=897.8, wps=110.5, ups=0.12, wpb=897.8, bsz=80, num_updates=7770, lr=2.50463e-06, gnorm=1.773, clip=90, loss_scale=64, train_wall=81, gb_free=6.8, wall=103083
2022-05-21 02:03:00 - progress_bar.py[line:274] - INFO: epoch 002:    711 / 7081 loss=-0.005, score=1.383, ntokens=896.5, nsentences=80, sample_size=896.5, wps=110, ups=0.12, wpb=896.5, bsz=80, num_updates=7780, lr=2.50103e-06, gnorm=1.241, clip=90, loss_scale=64, train_wall=81, gb_free=6.8, wall=103164
2022-05-21 02:04:21 - progress_bar.py[line:274] - INFO: epoch 002:    721 / 7081 loss=-0.003, score=1.416, ntokens=909.4, nsentences=80, sample_size=909.4, wps=111.1, ups=0.12, wpb=909.4, bsz=80, num_updates=7790, lr=2.49742e-06, gnorm=1.431, clip=100, loss_scale=64, train_wall=82, gb_free=6.8, wall=103246
2022-05-21 02:05:43 - progress_bar.py[line:274] - INFO: epoch 002:    731 / 7081 loss=-0.005, score=1.371, ntokens=898.7, nsentences=80, sample_size=898.7, wps=110.1, ups=0.12, wpb=898.7, bsz=80, num_updates=7800, lr=2.49382e-06, gnorm=1.319, clip=80, loss_scale=64, train_wall=82, gb_free=6.8, wall=103328
2022-05-21 02:07:05 - progress_bar.py[line:274] - INFO: epoch 002:    741 / 7081 loss=-0.005, score=1.396, ntokens=897.9, nsentences=80, sample_size=897.9, wps=109.9, ups=0.12, wpb=897.9, bsz=80, num_updates=7810, lr=2.49021e-06, gnorm=1.161, clip=70, loss_scale=64, train_wall=82, gb_free=6.8, wall=103409
2022-05-21 02:08:26 - progress_bar.py[line:274] - INFO: epoch 002:    751 / 7081 loss=-0.006, score=1.552, ntokens=896.7, nsentences=80, sample_size=896.7, wps=110.5, ups=0.12, wpb=896.7, bsz=80, num_updates=7820, lr=2.48661e-06, gnorm=1.379, clip=80, loss_scale=64, train_wall=81, gb_free=6.8, wall=103491
2022-05-21 02:09:47 - progress_bar.py[line:274] - INFO: epoch 002:    761 / 7081 loss=-0.006, score=1.5, ntokens=887.2, nsentences=80, sample_size=887.2, wps=108.9, ups=0.12, wpb=887.2, bsz=80, num_updates=7830, lr=2.483e-06, gnorm=1.527, clip=100, loss_scale=64, train_wall=81, gb_free=6.8, wall=103572
2022-05-21 02:11:08 - progress_bar.py[line:274] - INFO: epoch 002:    771 / 7081 loss=-0.007, score=1.39, ntokens=891.1, nsentences=80, sample_size=891.1, wps=110.2, ups=0.12, wpb=891.1, bsz=80, num_updates=7840, lr=2.4794e-06, gnorm=1.514, clip=100, loss_scale=64, train_wall=81, gb_free=6.8, wall=103653
2022-05-21 02:12:29 - progress_bar.py[line:274] - INFO: epoch 002:    781 / 7081 loss=-0.007, score=1.416, ntokens=888.8, nsentences=80, sample_size=888.8, wps=110.1, ups=0.12, wpb=888.8, bsz=80, num_updates=7850, lr=2.47579e-06, gnorm=1.617, clip=80, loss_scale=64, train_wall=81, gb_free=6.8, wall=103734
2022-05-21 02:13:51 - progress_bar.py[line:274] - INFO: epoch 002:    791 / 7081 loss=-0.006, score=1.467, ntokens=888.6, nsentences=80, sample_size=888.6, wps=109, ups=0.12, wpb=888.6, bsz=80, num_updates=7860, lr=2.47219e-06, gnorm=1.709, clip=90, loss_scale=64, train_wall=81, gb_free=6.8, wall=103815
2022-05-21 02:15:11 - progress_bar.py[line:274] - INFO: epoch 002:    801 / 7081 loss=-0.005, score=1.397, ntokens=886.9, nsentences=80, sample_size=886.9, wps=109.7, ups=0.12, wpb=886.9, bsz=80, num_updates=7870, lr=2.46858e-06, gnorm=1.269, clip=70, loss_scale=64, train_wall=81, gb_free=6.8, wall=103896
2022-05-21 02:16:33 - progress_bar.py[line:274] - INFO: epoch 002:    811 / 7081 loss=-0.005, score=1.41, ntokens=887.1, nsentences=80, sample_size=887.1, wps=109.2, ups=0.12, wpb=887.1, bsz=80, num_updates=7880, lr=2.46497e-06, gnorm=1.935, clip=100, loss_scale=64, train_wall=81, gb_free=6.8, wall=103977
2022-05-21 02:17:53 - progress_bar.py[line:274] - INFO: epoch 002:    821 / 7081 loss=-0.006, score=1.505, ntokens=888.6, nsentences=80, sample_size=888.6, wps=109.9, ups=0.12, wpb=888.6, bsz=80, num_updates=7890, lr=2.46137e-06, gnorm=3.11, clip=90, loss_scale=64, train_wall=81, gb_free=6.8, wall=104058
2022-05-21 02:19:11 - progress_bar.py[line:274] - INFO: epoch 002:    831 / 7081 loss=-0.006, score=1.435, ntokens=891.6, nsentences=80, sample_size=891.6, wps=115.5, ups=0.13, wpb=891.6, bsz=80, num_updates=7900, lr=2.45776e-06, gnorm=1.337, clip=80, loss_scale=64, train_wall=77, gb_free=6.8, wall=104135
2022-05-21 02:20:28 - progress_bar.py[line:274] - INFO: epoch 002:    841 / 7081 loss=-0.009, score=1.577, ntokens=899.6, nsentences=80, sample_size=899.6, wps=116, ups=0.13, wpb=899.6, bsz=80, num_updates=7910, lr=2.45416e-06, gnorm=1.352, clip=80, loss_scale=64, train_wall=77, gb_free=6.7, wall=104213
2022-05-21 02:21:48 - progress_bar.py[line:274] - INFO: epoch 002:    851 / 7081 loss=-0.006, score=1.444, ntokens=894.3, nsentences=80, sample_size=894.3, wps=111.7, ups=0.12, wpb=894.3, bsz=80, num_updates=7920, lr=2.45055e-06, gnorm=1.362, clip=70, loss_scale=64, train_wall=80, gb_free=6.8, wall=104293
2022-05-21 02:23:10 - progress_bar.py[line:274] - INFO: epoch 002:    861 / 7081 loss=-0.006, score=1.397, ntokens=900.2, nsentences=80, sample_size=900.2, wps=110.7, ups=0.12, wpb=900.2, bsz=80, num_updates=7930, lr=2.44695e-06, gnorm=2.055, clip=100, loss_scale=64, train_wall=81, gb_free=6.8, wall=104374
2022-05-21 02:24:32 - progress_bar.py[line:274] - INFO: epoch 002:    871 / 7081 loss=-0.006, score=1.538, ntokens=899.3, nsentences=80, sample_size=899.3, wps=109.7, ups=0.12, wpb=899.3, bsz=80, num_updates=7940, lr=2.44334e-06, gnorm=1.382, clip=70, loss_scale=64, train_wall=82, gb_free=6.7, wall=104456
2022-05-21 02:25:52 - progress_bar.py[line:274] - INFO: epoch 002:    881 / 7081 loss=-0.007, score=1.453, ntokens=875.7, nsentences=80, sample_size=875.7, wps=108.5, ups=0.12, wpb=875.7, bsz=80, num_updates=7950, lr=2.43974e-06, gnorm=1.581, clip=100, loss_scale=64, train_wall=81, gb_free=6.8, wall=104537
2022-05-21 02:27:14 - progress_bar.py[line:274] - INFO: epoch 002:    891 / 7081 loss=-0.004, score=1.468, ntokens=889.4, nsentences=80, sample_size=889.4, wps=109.3, ups=0.12, wpb=889.4, bsz=80, num_updates=7960, lr=2.43613e-06, gnorm=1.742, clip=90, loss_scale=64, train_wall=81, gb_free=6.8, wall=104618
2022-05-21 02:28:34 - progress_bar.py[line:274] - INFO: epoch 002:    901 / 7081 loss=-0.006, score=1.374, ntokens=879.9, nsentences=80, sample_size=879.9, wps=109, ups=0.12, wpb=879.9, bsz=80, num_updates=7970, lr=2.43252e-06, gnorm=1.199, clip=60, loss_scale=64, train_wall=81, gb_free=6.8, wall=104699
2022-05-21 02:29:55 - progress_bar.py[line:274] - INFO: epoch 002:    911 / 7081 loss=-0.009, score=1.475, ntokens=879.5, nsentences=80, sample_size=879.5, wps=108.3, ups=0.12, wpb=879.5, bsz=80, num_updates=7980, lr=2.42892e-06, gnorm=1.389, clip=70, loss_scale=64, train_wall=81, gb_free=6.8, wall=104780
2022-05-21 02:31:16 - progress_bar.py[line:274] - INFO: epoch 002:    921 / 7081 loss=-0.006, score=1.488, ntokens=888.5, nsentences=80, sample_size=888.5, wps=110.1, ups=0.12, wpb=888.5, bsz=80, num_updates=7990, lr=2.42531e-06, gnorm=1.483, clip=80, loss_scale=64, train_wall=81, gb_free=6.8, wall=104861
slice_id 1 seek offset 2500
2022-05-21 02:32:37 - progress_bar.py[line:274] - INFO: epoch 002:    931 / 7081 loss=-0.002, score=1.449, ntokens=878.6, nsentences=80, sample_size=878.6, wps=108.5, ups=0.12, wpb=878.6, bsz=80, num_updates=8000, lr=2.42171e-06, gnorm=1.552, clip=70, loss_scale=64, train_wall=81, gb_free=6.8, wall=104942
2022-05-21 02:32:37 - train.py[line:436] - INFO: begin validation on "valid" subset
slice_id 0 seek offset 0
slice_id 1 seek offset 2500
slice_id 0 seek offset 0
2022-05-21 03:12:43 - progress_bar.py[line:282] - INFO: epoch 002 | valid on 'valid' subset | loss -0.005 | score 1.298 | ntokens 111.292 | nsentences 10 | sample_size 111.292 | cider 1.391 | wps 115.6 | wpb 111.3 | bsz 10 | num_updates 8000 | best_cider 1.391
2022-05-21 03:12:43 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 2 @ 8000 updates
2022-05-21 03:12:43 - trainer.py[line:431] - INFO: Saving checkpoint to /database/jhkim/stage2_checkpoints//5e-6_2/checkpoint_2_8000.pt
2022-05-21 03:12:51 - trainer.py[line:441] - INFO: Finished saving checkpoint to /database/jhkim/stage2_checkpoints//5e-6_2/checkpoint_2_8000.pt
2022-05-21 03:14:15 - checkpoint_utils.py[line:135] - INFO: Saved checkpoint /database/jhkim/stage2_checkpoints//5e-6_2/checkpoint_2_8000.pt (epoch 2 @ 8000 updates, score 1.391) (writing took 92.09883578494191 seconds)
2022-05-21 03:15:37 - progress_bar.py[line:274] - INFO: epoch 002:    941 / 7081 loss=-0.005, score=1.441, ntokens=897.2, nsentences=80, sample_size=897.2, wps=3.5, ups=0, wpb=897.2, bsz=80, num_updates=8010, lr=2.4181e-06, gnorm=1.597, clip=90, loss_scale=64, train_wall=80, gb_free=6.8, wall=107521
2022-05-21 03:16:57 - progress_bar.py[line:274] - INFO: epoch 002:    951 / 7081 loss=-0.006, score=1.478, ntokens=885.1, nsentences=80, sample_size=885.1, wps=110, ups=0.12, wpb=885.1, bsz=80, num_updates=8020, lr=2.4145e-06, gnorm=1.755, clip=100, loss_scale=64, train_wall=80, gb_free=6.8, wall=107602
2022-05-21 03:18:18 - progress_bar.py[line:274] - INFO: epoch 002:    961 / 7081 loss=-0.009, score=1.481, ntokens=885.7, nsentences=80, sample_size=885.7, wps=110, ups=0.12, wpb=885.7, bsz=80, num_updates=8030, lr=2.41089e-06, gnorm=1.448, clip=90, loss_scale=64, train_wall=80, gb_free=6.8, wall=107682
2022-05-21 03:19:38 - progress_bar.py[line:274] - INFO: epoch 002:    971 / 7081 loss=-0.007, score=1.578, ntokens=893.2, nsentences=80, sample_size=893.2, wps=110.4, ups=0.12, wpb=893.2, bsz=80, num_updates=8040, lr=2.40729e-06, gnorm=1.373, clip=60, loss_scale=64, train_wall=81, gb_free=6.8, wall=107763
2022-05-21 03:21:00 - progress_bar.py[line:274] - INFO: epoch 002:    981 / 7081 loss=-0.005, score=1.397, ntokens=891.5, nsentences=80, sample_size=891.5, wps=109.7, ups=0.12, wpb=891.5, bsz=80, num_updates=8050, lr=2.40368e-06, gnorm=1.454, clip=70, loss_scale=64, train_wall=81, gb_free=6.8, wall=107844
2022-05-21 03:22:21 - progress_bar.py[line:274] - INFO: epoch 002:    991 / 7081 loss=-0.007, score=1.451, ntokens=902, nsentences=80, sample_size=902, wps=110.6, ups=0.12, wpb=902, bsz=80, num_updates=8060, lr=2.40008e-06, gnorm=1.776, clip=80, loss_scale=64, train_wall=81, gb_free=6.8, wall=107926
2022-05-21 03:23:43 - progress_bar.py[line:274] - INFO: epoch 002:   1001 / 7081 loss=-0.009, score=1.542, ntokens=893.7, nsentences=80, sample_size=893.7, wps=109.8, ups=0.12, wpb=893.7, bsz=80, num_updates=8070, lr=2.39647e-06, gnorm=2.157, clip=100, loss_scale=64, train_wall=81, gb_free=6.7, wall=108007
2022-05-21 03:25:04 - progress_bar.py[line:274] - INFO: epoch 002:   1011 / 7081 loss=-0.008, score=1.47, ntokens=884.8, nsentences=80, sample_size=884.8, wps=108.8, ups=0.12, wpb=884.8, bsz=80, num_updates=8080, lr=2.39286e-06, gnorm=1.696, clip=100, loss_scale=64, train_wall=81, gb_free=6.8, wall=108089
2022-05-21 03:26:25 - progress_bar.py[line:274] - INFO: epoch 002:   1021 / 7081 loss=-0.004, score=1.495, ntokens=896.6, nsentences=80, sample_size=896.6, wps=110.8, ups=0.12, wpb=896.6, bsz=80, num_updates=8090, lr=2.38926e-06, gnorm=1.796, clip=100, loss_scale=64, train_wall=81, gb_free=6.8, wall=108170
2022-05-21 03:27:46 - progress_bar.py[line:274] - INFO: epoch 002:   1031 / 7081 loss=-0.005, score=1.438, ntokens=897.5, nsentences=80, sample_size=897.5, wps=110.4, ups=0.12, wpb=897.5, bsz=80, num_updates=8100, lr=2.38565e-06, gnorm=3.03, clip=90, loss_scale=64, train_wall=81, gb_free=6.8, wall=108251
2022-05-21 03:29:07 - progress_bar.py[line:274] - INFO: epoch 002:   1041 / 7081 loss=-0.005, score=1.51, ntokens=890.1, nsentences=80, sample_size=890.1, wps=109.7, ups=0.12, wpb=890.1, bsz=80, num_updates=8110, lr=2.38205e-06, gnorm=1.534, clip=90, loss_scale=64, train_wall=81, gb_free=6.7, wall=108332
2022-05-21 03:30:28 - progress_bar.py[line:274] - INFO: epoch 002:   1051 / 7081 loss=-0.009, score=1.436, ntokens=879.6, nsentences=80, sample_size=879.6, wps=109.4, ups=0.12, wpb=879.6, bsz=80, num_updates=8120, lr=2.37844e-06, gnorm=1.859, clip=90, loss_scale=64, train_wall=80, gb_free=6.8, wall=108412
2022-05-21 03:31:49 - progress_bar.py[line:274] - INFO: epoch 002:   1061 / 7081 loss=-0.004, score=1.511, ntokens=885, nsentences=80, sample_size=885, wps=108.8, ups=0.12, wpb=885, bsz=80, num_updates=8130, lr=2.37484e-06, gnorm=2.201, clip=90, loss_scale=64, train_wall=81, gb_free=6.8, wall=108494
2022-05-21 03:33:11 - progress_bar.py[line:274] - INFO: epoch 002:   1071 / 7081 loss=-0.006, score=1.471, ntokens=903.3, nsentences=80, sample_size=903.3, wps=110.6, ups=0.12, wpb=903.3, bsz=80, num_updates=8140, lr=2.37123e-06, gnorm=1.767, clip=100, loss_scale=64, train_wall=82, gb_free=6.8, wall=108576
2022-05-21 03:34:32 - progress_bar.py[line:274] - INFO: epoch 002:   1081 / 7081 loss=-0.007, score=1.426, ntokens=894.9, nsentences=80, sample_size=894.9, wps=110.1, ups=0.12, wpb=894.9, bsz=80, num_updates=8150, lr=2.36763e-06, gnorm=1.354, clip=90, loss_scale=64, train_wall=81, gb_free=6.8, wall=108657
2022-05-21 03:35:53 - progress_bar.py[line:274] - INFO: epoch 002:   1091 / 7081 loss=-0.006, score=1.471, ntokens=876.1, nsentences=80, sample_size=876.1, wps=108.5, ups=0.12, wpb=876.1, bsz=80, num_updates=8160, lr=2.36402e-06, gnorm=1.288, clip=60, loss_scale=64, train_wall=81, gb_free=6.8, wall=108738
2022-05-21 03:37:11 - progress_bar.py[line:274] - INFO: epoch 002:   1101 / 7081 loss=-0.006, score=1.516, ntokens=884.9, nsentences=80, sample_size=884.9, wps=113.6, ups=0.13, wpb=884.9, bsz=80, num_updates=8170, lr=2.36041e-06, gnorm=1.504, clip=80, loss_scale=64, train_wall=78, gb_free=6.8, wall=108815
2022-05-21 03:38:27 - progress_bar.py[line:274] - INFO: epoch 002:   1111 / 7081 loss=-0.007, score=1.501, ntokens=884.1, nsentences=80, sample_size=884.1, wps=116.3, ups=0.13, wpb=884.1, bsz=80, num_updates=8180, lr=2.35681e-06, gnorm=1.676, clip=80, loss_scale=64, train_wall=76, gb_free=6.8, wall=108892
2022-05-21 03:39:45 - progress_bar.py[line:274] - INFO: epoch 002:   1121 / 7081 loss=-0.003, score=1.436, ntokens=894.6, nsentences=80, sample_size=894.6, wps=114.4, ups=0.13, wpb=894.6, bsz=80, num_updates=8190, lr=2.3532e-06, gnorm=1.961, clip=90, loss_scale=64, train_wall=78, gb_free=6.7, wall=108970
2022-05-21 03:41:06 - progress_bar.py[line:274] - INFO: epoch 002:   1131 / 7081 loss=-0.006, score=1.517, ntokens=882, nsentences=80, sample_size=882, wps=109.3, ups=0.12, wpb=882, bsz=80, num_updates=8200, lr=2.3496e-06, gnorm=1.871, clip=100, loss_scale=64, train_wall=81, gb_free=6.8, wall=109050
2022-05-21 03:42:27 - progress_bar.py[line:274] - INFO: epoch 002:   1141 / 7081 loss=-0.003, score=1.498, ntokens=887.1, nsentences=80, sample_size=887.1, wps=109.8, ups=0.12, wpb=887.1, bsz=80, num_updates=8210, lr=2.34599e-06, gnorm=1.309, clip=70, loss_scale=128, train_wall=81, gb_free=6.8, wall=109131
2022-05-21 03:43:48 - progress_bar.py[line:274] - INFO: epoch 002:   1151 / 7081 loss=-0.007, score=1.472, ntokens=889.9, nsentences=80, sample_size=889.9, wps=109.1, ups=0.12, wpb=889.9, bsz=80, num_updates=8220, lr=2.34239e-06, gnorm=1.734, clip=100, loss_scale=128, train_wall=82, gb_free=6.8, wall=109213
2022-05-21 03:45:10 - progress_bar.py[line:274] - INFO: epoch 002:   1161 / 7081 loss=-0.005, score=1.515, ntokens=896.1, nsentences=80, sample_size=896.1, wps=110.1, ups=0.12, wpb=896.1, bsz=80, num_updates=8230, lr=2.33878e-06, gnorm=1.348, clip=70, loss_scale=128, train_wall=81, gb_free=6.8, wall=109294
2022-05-21 03:45:42 - trainer.py[line:922] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-05-21 03:46:40 - progress_bar.py[line:274] - INFO: epoch 002:   1172 / 7081 loss=-0.006, score=1.469, ntokens=903.2, nsentences=80, sample_size=903.2, wps=100.2, ups=0.11, wpb=903.2, bsz=80, num_updates=8240, lr=2.33518e-06, gnorm=1.918, clip=70, loss_scale=64, train_wall=90, gb_free=6.8, wall=109384
2022-05-21 03:48:02 - progress_bar.py[line:274] - INFO: epoch 002:   1182 / 7081 loss=-0.006, score=1.526, ntokens=892.6, nsentences=80, sample_size=892.6, wps=108.8, ups=0.12, wpb=892.6, bsz=80, num_updates=8250, lr=2.33157e-06, gnorm=1.622, clip=90, loss_scale=64, train_wall=82, gb_free=6.8, wall=109466
2022-05-21 03:49:23 - progress_bar.py[line:274] - INFO: epoch 002:   1192 / 7081 loss=-0.006, score=1.354, ntokens=896.9, nsentences=80, sample_size=896.9, wps=110.2, ups=0.12, wpb=896.9, bsz=80, num_updates=8260, lr=2.32797e-06, gnorm=1.468, clip=70, loss_scale=64, train_wall=81, gb_free=6.8, wall=109548
2022-05-21 03:50:44 - progress_bar.py[line:274] - INFO: epoch 002:   1202 / 7081 loss=-0.006, score=1.457, ntokens=890.1, nsentences=80, sample_size=890.1, wps=110.2, ups=0.12, wpb=890.1, bsz=80, num_updates=8270, lr=2.32436e-06, gnorm=2.422, clip=80, loss_scale=64, train_wall=81, gb_free=6.8, wall=109629
2022-05-21 03:52:05 - progress_bar.py[line:274] - INFO: epoch 002:   1212 / 7081 loss=-0.006, score=1.459, ntokens=875.6, nsentences=80, sample_size=875.6, wps=108.6, ups=0.12, wpb=875.6, bsz=80, num_updates=8280, lr=2.32075e-06, gnorm=1.779, clip=100, loss_scale=64, train_wall=81, gb_free=6.8, wall=109709
2022-05-21 03:53:25 - progress_bar.py[line:274] - INFO: epoch 002:   1222 / 7081 loss=-0.008, score=1.567, ntokens=886, nsentences=80, sample_size=886, wps=110, ups=0.12, wpb=886, bsz=80, num_updates=8290, lr=2.31715e-06, gnorm=1.389, clip=80, loss_scale=64, train_wall=80, gb_free=6.8, wall=109790
2022-05-21 03:54:47 - progress_bar.py[line:274] - INFO: epoch 002:   1232 / 7081 loss=-0.007, score=1.567, ntokens=879.3, nsentences=80, sample_size=879.3, wps=107.7, ups=0.12, wpb=879.3, bsz=80, num_updates=8300, lr=2.31354e-06, gnorm=1.643, clip=90, loss_scale=64, train_wall=82, gb_free=6.8, wall=109871
2022-05-21 03:56:08 - progress_bar.py[line:274] - INFO: epoch 002:   1242 / 7081 loss=-0.003, score=1.31, ntokens=898.9, nsentences=80, sample_size=898.9, wps=110.3, ups=0.12, wpb=898.9, bsz=80, num_updates=8310, lr=2.30994e-06, gnorm=1.104, clip=50, loss_scale=64, train_wall=81, gb_free=6.8, wall=109953
2022-05-21 03:57:30 - progress_bar.py[line:274] - INFO: epoch 002:   1252 / 7081 loss=-0.007, score=1.437, ntokens=891.3, nsentences=80, sample_size=891.3, wps=109.7, ups=0.12, wpb=891.3, bsz=80, num_updates=8320, lr=2.30633e-06, gnorm=1.348, clip=80, loss_scale=64, train_wall=81, gb_free=6.8, wall=110034
2022-05-21 03:58:51 - progress_bar.py[line:274] - INFO: epoch 002:   1262 / 7081 loss=-0.007, score=1.516, ntokens=909.2, nsentences=80, sample_size=909.2, wps=111.6, ups=0.12, wpb=909.2, bsz=80, num_updates=8330, lr=2.30273e-06, gnorm=1.623, clip=100, loss_scale=64, train_wall=81, gb_free=6.8, wall=110116
2022-05-21 04:00:12 - progress_bar.py[line:274] - INFO: epoch 002:   1272 / 7081 loss=-0.009, score=1.45, ntokens=891.4, nsentences=80, sample_size=891.4, wps=110.2, ups=0.12, wpb=891.4, bsz=80, num_updates=8340, lr=2.29912e-06, gnorm=1.344, clip=50, loss_scale=64, train_wall=81, gb_free=6.8, wall=110197
2022-05-21 04:01:34 - progress_bar.py[line:274] - INFO: epoch 002:   1282 / 7081 loss=-0.006, score=1.586, ntokens=893.8, nsentences=80, sample_size=893.8, wps=109.1, ups=0.12, wpb=893.8, bsz=80, num_updates=8350, lr=2.29552e-06, gnorm=1.43, clip=80, loss_scale=64, train_wall=82, gb_free=6.8, wall=110279
2022-05-21 04:02:54 - progress_bar.py[line:274] - INFO: epoch 002:   1292 / 7081 loss=-0.006, score=1.456, ntokens=883.5, nsentences=80, sample_size=883.5, wps=110.7, ups=0.13, wpb=883.5, bsz=80, num_updates=8360, lr=2.29191e-06, gnorm=1.703, clip=90, loss_scale=64, train_wall=80, gb_free=6.8, wall=110358
2022-05-21 04:04:09 - progress_bar.py[line:274] - INFO: epoch 002:   1302 / 7081 loss=-0.007, score=1.513, ntokens=869.2, nsentences=80, sample_size=869.2, wps=114.7, ups=0.13, wpb=869.2, bsz=80, num_updates=8370, lr=2.2883e-06, gnorm=1.488, clip=90, loss_scale=64, train_wall=76, gb_free=6.8, wall=110434
2022-05-21 04:05:27 - progress_bar.py[line:274] - INFO: epoch 002:   1312 / 7081 loss=-0.003, score=1.37, ntokens=890.4, nsentences=80, sample_size=890.4, wps=114.9, ups=0.13, wpb=890.4, bsz=80, num_updates=8380, lr=2.2847e-06, gnorm=1.352, clip=60, loss_scale=64, train_wall=77, gb_free=6.8, wall=110512
2022-05-21 04:06:48 - progress_bar.py[line:274] - INFO: epoch 002:   1322 / 7081 loss=-0.006, score=1.31, ntokens=898.7, nsentences=80, sample_size=898.7, wps=111.1, ups=0.12, wpb=898.7, bsz=80, num_updates=8390, lr=2.28109e-06, gnorm=2.058, clip=100, loss_scale=64, train_wall=81, gb_free=6.8, wall=110592
2022-05-21 04:08:09 - progress_bar.py[line:274] - INFO: epoch 002:   1332 / 7081 loss=-0.003, score=1.428, ntokens=890, nsentences=80, sample_size=890, wps=110.3, ups=0.12, wpb=890, bsz=80, num_updates=8400, lr=2.27749e-06, gnorm=1.541, clip=80, loss_scale=64, train_wall=81, gb_free=6.8, wall=110673
2022-05-21 04:09:29 - progress_bar.py[line:274] - INFO: epoch 002:   1342 / 7081 loss=-0.004, score=1.428, ntokens=888.4, nsentences=80, sample_size=888.4, wps=109.8, ups=0.12, wpb=888.4, bsz=80, num_updates=8410, lr=2.27388e-06, gnorm=1.632, clip=80, loss_scale=64, train_wall=81, gb_free=6.8, wall=110754
2022-05-21 04:10:50 - progress_bar.py[line:274] - INFO: epoch 002:   1352 / 7081 loss=-0.007, score=1.433, ntokens=884.8, nsentences=80, sample_size=884.8, wps=110.1, ups=0.12, wpb=884.8, bsz=80, num_updates=8420, lr=2.27028e-06, gnorm=1.589, clip=100, loss_scale=64, train_wall=80, gb_free=6.8, wall=110834
2022-05-21 04:12:10 - progress_bar.py[line:274] - INFO: epoch 002:   1362 / 7081 loss=-0.008, score=1.491, ntokens=883, nsentences=80, sample_size=883, wps=109.7, ups=0.12, wpb=883, bsz=80, num_updates=8430, lr=2.26667e-06, gnorm=1.235, clip=60, loss_scale=64, train_wall=80, gb_free=6.8, wall=110915
2022-05-21 04:13:32 - progress_bar.py[line:274] - INFO: epoch 002:   1372 / 7081 loss=-0.009, score=1.424, ntokens=898.6, nsentences=80, sample_size=898.6, wps=110.4, ups=0.12, wpb=898.6, bsz=80, num_updates=8440, lr=2.26307e-06, gnorm=1.828, clip=90, loss_scale=64, train_wall=81, gb_free=6.8, wall=110996
2022-05-21 04:14:53 - progress_bar.py[line:274] - INFO: epoch 002:   1382 / 7081 loss=-0.008, score=1.555, ntokens=883.1, nsentences=80, sample_size=883.1, wps=109.1, ups=0.12, wpb=883.1, bsz=80, num_updates=8450, lr=2.25946e-06, gnorm=1.583, clip=100, loss_scale=64, train_wall=81, gb_free=6.8, wall=111077
2022-05-21 04:16:13 - progress_bar.py[line:274] - INFO: epoch 002:   1392 / 7081 loss=-0.006, score=1.417, ntokens=888.6, nsentences=80, sample_size=888.6, wps=110, ups=0.12, wpb=888.6, bsz=80, num_updates=8460, lr=2.25586e-06, gnorm=1.618, clip=80, loss_scale=64, train_wall=81, gb_free=6.8, wall=111158
2022-05-21 04:17:35 - progress_bar.py[line:274] - INFO: epoch 002:   1402 / 7081 loss=-0.008, score=1.471, ntokens=895.4, nsentences=80, sample_size=895.4, wps=109.6, ups=0.12, wpb=895.4, bsz=80, num_updates=8470, lr=2.25225e-06, gnorm=1.98, clip=80, loss_scale=64, train_wall=82, gb_free=6.8, wall=111240
2022-05-21 04:18:56 - progress_bar.py[line:274] - INFO: epoch 002:   1412 / 7081 loss=-0.007, score=1.41, ntokens=893, nsentences=80, sample_size=893, wps=110.4, ups=0.12, wpb=893, bsz=80, num_updates=8480, lr=2.24864e-06, gnorm=1.664, clip=70, loss_scale=64, train_wall=81, gb_free=6.7, wall=111321
2022-05-21 04:20:17 - progress_bar.py[line:274] - INFO: epoch 002:   1422 / 7081 loss=-0.007, score=1.588, ntokens=883.8, nsentences=80, sample_size=883.8, wps=109.2, ups=0.12, wpb=883.8, bsz=80, num_updates=8490, lr=2.24504e-06, gnorm=1.739, clip=70, loss_scale=64, train_wall=81, gb_free=6.8, wall=111401
2022-05-21 04:21:38 - progress_bar.py[line:274] - INFO: epoch 002:   1432 / 7081 loss=-0.006, score=1.5, ntokens=881.7, nsentences=80, sample_size=881.7, wps=108.9, ups=0.12, wpb=881.7, bsz=80, num_updates=8500, lr=2.24143e-06, gnorm=1.486, clip=70, loss_scale=64, train_wall=81, gb_free=6.8, wall=111482
2022-05-21 04:21:38 - train.py[line:436] - INFO: begin validation on "valid" subset
slice_id 0 seek offset 0
slice_id 1 seek offset 2500
slice_id 0 seek offset 0
slice_id 1 seek offset 2500
2022-05-21 05:01:29 - progress_bar.py[line:282] - INFO: epoch 002 | valid on 'valid' subset | loss -0.005 | score 1.297 | ntokens 111.048 | nsentences 10 | sample_size 111.048 | cider 1.391 | wps 116.1 | wpb 111 | bsz 10 | num_updates 8500 | best_cider 1.391
2022-05-21 05:01:29 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 2 @ 8500 updates
2022-05-21 05:01:29 - trainer.py[line:431] - INFO: Saving checkpoint to /database/jhkim/stage2_checkpoints//5e-6_2/checkpoint_2_8500.pt
2022-05-21 05:01:38 - trainer.py[line:441] - INFO: Finished saving checkpoint to /database/jhkim/stage2_checkpoints//5e-6_2/checkpoint_2_8500.pt
2022-05-21 05:03:25 - checkpoint_utils.py[line:135] - INFO: Saved checkpoint /database/jhkim/stage2_checkpoints//5e-6_2/checkpoint_2_8500.pt (epoch 2 @ 8500 updates, score 1.391) (writing took 115.44716058624908 seconds)
2022-05-21 05:04:44 - progress_bar.py[line:274] - INFO: epoch 002:   1442 / 7081 loss=-0.005, score=1.466, ntokens=877.6, nsentences=80, sample_size=877.6, wps=3.4, ups=0, wpb=877.6, bsz=80, num_updates=8510, lr=2.23783e-06, gnorm=1.861, clip=80, loss_scale=64, train_wall=79, gb_free=6.8, wall=114069
2022-05-21 05:06:06 - progress_bar.py[line:274] - INFO: epoch 002:   1452 / 7081 loss=-0.007, score=1.552, ntokens=889.6, nsentences=80, sample_size=889.6, wps=109, ups=0.12, wpb=889.6, bsz=80, num_updates=8520, lr=2.23422e-06, gnorm=1.484, clip=80, loss_scale=64, train_wall=82, gb_free=6.8, wall=114150
2022-05-21 05:07:26 - progress_bar.py[line:274] - INFO: epoch 002:   1462 / 7081 loss=-0.009, score=1.476, ntokens=885.5, nsentences=80, sample_size=885.5, wps=109.8, ups=0.12, wpb=885.5, bsz=80, num_updates=8530, lr=2.23062e-06, gnorm=2.157, clip=100, loss_scale=64, train_wall=81, gb_free=6.8, wall=114231
2022-05-21 05:08:47 - progress_bar.py[line:274] - INFO: epoch 002:   1472 / 7081 loss=-0.006, score=1.449, ntokens=884.2, nsentences=80, sample_size=884.2, wps=109.3, ups=0.12, wpb=884.2, bsz=80, num_updates=8540, lr=2.22701e-06, gnorm=1.836, clip=80, loss_scale=64, train_wall=81, gb_free=6.8, wall=114312
2022-05-21 05:10:09 - progress_bar.py[line:274] - INFO: epoch 002:   1482 / 7081 loss=-0.007, score=1.536, ntokens=898.9, nsentences=80, sample_size=898.9, wps=110.3, ups=0.12, wpb=898.9, bsz=80, num_updates=8550, lr=2.22341e-06, gnorm=1.652, clip=80, loss_scale=64, train_wall=81, gb_free=6.7, wall=114394
2022-05-21 05:11:30 - progress_bar.py[line:274] - INFO: epoch 002:   1492 / 7081 loss=-0.003, score=1.39, ntokens=886.5, nsentences=80, sample_size=886.5, wps=109.7, ups=0.12, wpb=886.5, bsz=80, num_updates=8560, lr=2.2198e-06, gnorm=1.503, clip=80, loss_scale=64, train_wall=81, gb_free=6.8, wall=114474
2022-05-21 05:12:50 - progress_bar.py[line:274] - INFO: epoch 002:   1502 / 7081 loss=-0.006, score=1.565, ntokens=883.1, nsentences=80, sample_size=883.1, wps=110.3, ups=0.12, wpb=883.1, bsz=80, num_updates=8570, lr=2.21619e-06, gnorm=1.611, clip=80, loss_scale=64, train_wall=80, gb_free=6.8, wall=114554
2022-05-21 05:14:11 - progress_bar.py[line:274] - INFO: epoch 002:   1512 / 7081 loss=-0.006, score=1.435, ntokens=897.1, nsentences=80, sample_size=897.1, wps=110.2, ups=0.12, wpb=897.1, bsz=80, num_updates=8580, lr=2.21259e-06, gnorm=1.548, clip=60, loss_scale=64, train_wall=81, gb_free=6.8, wall=114636
2022-05-21 05:15:32 - progress_bar.py[line:274] - INFO: epoch 002:   1522 / 7081 loss=-0.003, score=1.487, ntokens=886.2, nsentences=80, sample_size=886.2, wps=109.4, ups=0.12, wpb=886.2, bsz=80, num_updates=8590, lr=2.20898e-06, gnorm=1.561, clip=80, loss_scale=64, train_wall=81, gb_free=6.8, wall=114717
2022-05-21 05:16:53 - progress_bar.py[line:274] - INFO: epoch 002:   1532 / 7081 loss=-0.007, score=1.429, ntokens=880.9, nsentences=80, sample_size=880.9, wps=109, ups=0.12, wpb=880.9, bsz=80, num_updates=8600, lr=2.20538e-06, gnorm=1.663, clip=90, loss_scale=64, train_wall=81, gb_free=6.8, wall=114798
2022-05-21 05:18:14 - progress_bar.py[line:274] - INFO: epoch 002:   1542 / 7081 loss=-0.004, score=1.533, ntokens=890, nsentences=80, sample_size=890, wps=109.2, ups=0.12, wpb=890, bsz=80, num_updates=8610, lr=2.20177e-06, gnorm=1.999, clip=80, loss_scale=64, train_wall=81, gb_free=6.8, wall=114879
2022-05-21 05:19:36 - progress_bar.py[line:274] - INFO: epoch 002:   1552 / 7081 loss=-0.005, score=1.385, ntokens=899.2, nsentences=80, sample_size=899.2, wps=110.5, ups=0.12, wpb=899.2, bsz=80, num_updates=8620, lr=2.19817e-06, gnorm=1.708, clip=80, loss_scale=64, train_wall=81, gb_free=6.8, wall=114961
2022-05-21 05:20:55 - progress_bar.py[line:274] - INFO: epoch 002:   1562 / 7081 loss=-0.004, score=1.442, ntokens=899.7, nsentences=80, sample_size=899.7, wps=113.7, ups=0.13, wpb=899.7, bsz=80, num_updates=8630, lr=2.19456e-06, gnorm=1.393, clip=90, loss_scale=64, train_wall=79, gb_free=6.7, wall=115040
2022-05-21 05:22:12 - progress_bar.py[line:274] - INFO: epoch 002:   1572 / 7081 loss=-0.004, score=1.537, ntokens=889, nsentences=80, sample_size=889, wps=115.5, ups=0.13, wpb=889, bsz=80, num_updates=8640, lr=2.19096e-06, gnorm=1.419, clip=90, loss_scale=64, train_wall=77, gb_free=6.8, wall=115117
2022-05-21 05:23:30 - progress_bar.py[line:274] - INFO: epoch 002:   1582 / 7081 loss=-0.004, score=1.46, ntokens=885.6, nsentences=80, sample_size=885.6, wps=113.6, ups=0.13, wpb=885.6, bsz=80, num_updates=8650, lr=2.18735e-06, gnorm=1.362, clip=80, loss_scale=64, train_wall=78, gb_free=6.8, wall=115195
2022-05-21 05:24:52 - progress_bar.py[line:274] - INFO: epoch 002:   1592 / 7081 loss=-0.008, score=1.456, ntokens=888.2, nsentences=80, sample_size=888.2, wps=108.4, ups=0.12, wpb=888.2, bsz=80, num_updates=8660, lr=2.18375e-06, gnorm=1.464, clip=90, loss_scale=64, train_wall=82, gb_free=6.8, wall=115277
2022-05-21 05:26:13 - progress_bar.py[line:274] - INFO: epoch 002:   1602 / 7081 loss=-0.008, score=1.437, ntokens=880.1, nsentences=80, sample_size=880.1, wps=108.9, ups=0.12, wpb=880.1, bsz=80, num_updates=8670, lr=2.18014e-06, gnorm=2.134, clip=80, loss_scale=64, train_wall=81, gb_free=6.8, wall=115357
2022-05-21 05:27:34 - progress_bar.py[line:274] - INFO: epoch 002:   1612 / 7081 loss=-0.004, score=1.468, ntokens=868, nsentences=80, sample_size=868, wps=107.3, ups=0.12, wpb=868, bsz=80, num_updates=8680, lr=2.17653e-06, gnorm=1.586, clip=90, loss_scale=64, train_wall=81, gb_free=6.8, wall=115438
2022-05-21 05:28:54 - progress_bar.py[line:274] - INFO: epoch 002:   1622 / 7081 loss=-0.005, score=1.474, ntokens=863.9, nsentences=80, sample_size=863.9, wps=107.5, ups=0.12, wpb=863.9, bsz=80, num_updates=8690, lr=2.17293e-06, gnorm=2.429, clip=100, loss_scale=64, train_wall=80, gb_free=6.8, wall=115519
2022-05-21 05:30:15 - progress_bar.py[line:274] - INFO: epoch 002:   1632 / 7081 loss=-0.005, score=1.457, ntokens=889.9, nsentences=80, sample_size=889.9, wps=110, ups=0.12, wpb=889.9, bsz=80, num_updates=8700, lr=2.16932e-06, gnorm=1.407, clip=70, loss_scale=64, train_wall=81, gb_free=6.8, wall=115599
2022-05-21 05:31:36 - progress_bar.py[line:274] - INFO: epoch 002:   1642 / 7081 loss=-0.007, score=1.414, ntokens=889.3, nsentences=80, sample_size=889.3, wps=109.9, ups=0.12, wpb=889.3, bsz=80, num_updates=8710, lr=2.16572e-06, gnorm=1.595, clip=80, loss_scale=64, train_wall=81, gb_free=6.8, wall=115680
2022-05-21 05:32:57 - progress_bar.py[line:274] - INFO: epoch 002:   1652 / 7081 loss=-0.005, score=1.512, ntokens=880.2, nsentences=80, sample_size=880.2, wps=108.3, ups=0.12, wpb=880.2, bsz=80, num_updates=8720, lr=2.16211e-06, gnorm=2.91, clip=100, loss_scale=64, train_wall=81, gb_free=6.8, wall=115762
2022-05-21 05:34:18 - progress_bar.py[line:274] - INFO: epoch 002:   1662 / 7081 loss=-0.006, score=1.487, ntokens=878.2, nsentences=80, sample_size=878.2, wps=109.1, ups=0.12, wpb=878.2, bsz=80, num_updates=8730, lr=2.15851e-06, gnorm=1.709, clip=90, loss_scale=64, train_wall=80, gb_free=6.8, wall=115842
2022-05-21 05:35:39 - progress_bar.py[line:274] - INFO: epoch 002:   1672 / 7081 loss=-0.003, score=1.382, ntokens=893, nsentences=80, sample_size=893, wps=109.7, ups=0.12, wpb=893, bsz=80, num_updates=8740, lr=2.1549e-06, gnorm=1.345, clip=70, loss_scale=64, train_wall=81, gb_free=6.8, wall=115924
2022-05-21 05:37:00 - progress_bar.py[line:274] - INFO: epoch 002:   1682 / 7081 loss=-0.01, score=1.528, ntokens=881.5, nsentences=80, sample_size=881.5, wps=108.9, ups=0.12, wpb=881.5, bsz=80, num_updates=8750, lr=2.1513e-06, gnorm=1.758, clip=80, loss_scale=128, train_wall=81, gb_free=6.8, wall=116005
2022-05-21 05:38:20 - progress_bar.py[line:274] - INFO: epoch 002:   1692 / 7081 loss=-0.006, score=1.43, ntokens=883.6, nsentences=80, sample_size=883.6, wps=109.8, ups=0.12, wpb=883.6, bsz=80, num_updates=8760, lr=2.14769e-06, gnorm=2.424, clip=100, loss_scale=128, train_wall=80, gb_free=6.8, wall=116085
2022-05-21 05:39:42 - progress_bar.py[line:274] - INFO: epoch 002:   1702 / 7081 loss=-0.005, score=1.432, ntokens=891.7, nsentences=80, sample_size=891.7, wps=109.1, ups=0.12, wpb=891.7, bsz=80, num_updates=8770, lr=2.14408e-06, gnorm=1.942, clip=100, loss_scale=128, train_wall=82, gb_free=6.8, wall=116167
2022-05-21 05:41:03 - progress_bar.py[line:274] - INFO: epoch 002:   1712 / 7081 loss=-0.005, score=1.466, ntokens=892.5, nsentences=80, sample_size=892.5, wps=110.1, ups=0.12, wpb=892.5, bsz=80, num_updates=8780, lr=2.14048e-06, gnorm=1.561, clip=90, loss_scale=128, train_wall=81, gb_free=6.8, wall=116248
2022-05-21 05:41:27 - trainer.py[line:922] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-05-21 05:42:33 - progress_bar.py[line:274] - INFO: epoch 002:   1723 / 7081 loss=-0.006, score=1.417, ntokens=899, nsentences=80, sample_size=899, wps=99.5, ups=0.11, wpb=899, bsz=80, num_updates=8790, lr=2.13687e-06, gnorm=1.974, clip=90, loss_scale=64, train_wall=90, gb_free=6.8, wall=116338
2022-05-21 05:43:55 - progress_bar.py[line:274] - INFO: epoch 002:   1733 / 7081 loss=-0.003, score=1.477, ntokens=895, nsentences=80, sample_size=895, wps=109.7, ups=0.12, wpb=895, bsz=80, num_updates=8800, lr=2.13327e-06, gnorm=1.953, clip=80, loss_scale=64, train_wall=81, gb_free=6.8, wall=116420
2022-05-21 05:45:16 - progress_bar.py[line:274] - INFO: epoch 002:   1743 / 7081 loss=-0.004, score=1.472, ntokens=894, nsentences=80, sample_size=894, wps=109.7, ups=0.12, wpb=894, bsz=80, num_updates=8810, lr=2.12966e-06, gnorm=2.073, clip=100, loss_scale=64, train_wall=81, gb_free=6.8, wall=116501
2022-05-21 05:46:37 - progress_bar.py[line:274] - INFO: epoch 002:   1753 / 7081 loss=-0.007, score=1.542, ntokens=876.4, nsentences=80, sample_size=876.4, wps=108.5, ups=0.12, wpb=876.4, bsz=80, num_updates=8820, lr=2.12606e-06, gnorm=1.846, clip=100, loss_scale=64, train_wall=81, gb_free=6.8, wall=116582
2022-05-21 05:47:54 - progress_bar.py[line:274] - INFO: epoch 002:   1763 / 7081 loss=-0.003, score=1.547, ntokens=887.8, nsentences=80, sample_size=887.8, wps=116.4, ups=0.13, wpb=887.8, bsz=80, num_updates=8830, lr=2.12245e-06, gnorm=1.936, clip=80, loss_scale=64, train_wall=76, gb_free=6.8, wall=116658
2022-05-21 05:49:10 - progress_bar.py[line:274] - INFO: epoch 002:   1773 / 7081 loss=-0.007, score=1.443, ntokens=893, nsentences=80, sample_size=893, wps=116.1, ups=0.13, wpb=893, bsz=80, num_updates=8840, lr=2.11885e-06, gnorm=1.393, clip=80, loss_scale=64, train_wall=77, gb_free=6.8, wall=116735
2022-05-21 05:50:32 - progress_bar.py[line:274] - INFO: epoch 002:   1783 / 7081 loss=-0.005, score=1.366, ntokens=879.6, nsentences=80, sample_size=879.6, wps=108.2, ups=0.12, wpb=879.6, bsz=80, num_updates=8850, lr=2.11524e-06, gnorm=1.742, clip=80, loss_scale=64, train_wall=81, gb_free=6.8, wall=116816
2022-05-21 05:51:53 - progress_bar.py[line:274] - INFO: epoch 002:   1793 / 7081 loss=-0.007, score=1.437, ntokens=895.4, nsentences=80, sample_size=895.4, wps=110.9, ups=0.12, wpb=895.4, bsz=80, num_updates=8860, lr=2.11164e-06, gnorm=2.031, clip=90, loss_scale=64, train_wall=81, gb_free=6.8, wall=116897
2022-05-21 05:53:15 - progress_bar.py[line:274] - INFO: epoch 002:   1803 / 7081 loss=-0.003, score=1.453, ntokens=895.2, nsentences=80, sample_size=895.2, wps=109, ups=0.12, wpb=895.2, bsz=80, num_updates=8870, lr=2.10803e-06, gnorm=1.451, clip=70, loss_scale=64, train_wall=82, gb_free=6.8, wall=116979
2022-05-21 05:54:36 - progress_bar.py[line:274] - INFO: epoch 002:   1813 / 7081 loss=-0.005, score=1.406, ntokens=897.9, nsentences=80, sample_size=897.9, wps=110.5, ups=0.12, wpb=897.9, bsz=80, num_updates=8880, lr=2.10442e-06, gnorm=1.689, clip=90, loss_scale=64, train_wall=81, gb_free=6.8, wall=117061
2022-05-21 05:55:56 - progress_bar.py[line:274] - INFO: epoch 002:   1823 / 7081 loss=-0.006, score=1.391, ntokens=874.7, nsentences=80, sample_size=874.7, wps=108.5, ups=0.12, wpb=874.7, bsz=80, num_updates=8890, lr=2.10082e-06, gnorm=1.759, clip=100, loss_scale=64, train_wall=81, gb_free=6.8, wall=117141
2022-05-21 05:57:18 - progress_bar.py[line:274] - INFO: epoch 002:   1833 / 7081 loss=-0.006, score=1.378, ntokens=892.5, nsentences=80, sample_size=892.5, wps=109.3, ups=0.12, wpb=892.5, bsz=80, num_updates=8900, lr=2.09721e-06, gnorm=1.588, clip=90, loss_scale=64, train_wall=82, gb_free=6.8, wall=117223
2022-05-21 05:58:38 - progress_bar.py[line:274] - INFO: epoch 002:   1843 / 7081 loss=-0.009, score=1.579, ntokens=877.3, nsentences=80, sample_size=877.3, wps=109.5, ups=0.12, wpb=877.3, bsz=80, num_updates=8910, lr=2.09361e-06, gnorm=1.883, clip=100, loss_scale=64, train_wall=80, gb_free=6.8, wall=117303
2022-05-21 06:00:00 - progress_bar.py[line:274] - INFO: epoch 002:   1853 / 7081 loss=-0.006, score=1.473, ntokens=902.8, nsentences=80, sample_size=902.8, wps=110.7, ups=0.12, wpb=902.8, bsz=80, num_updates=8920, lr=2.09e-06, gnorm=1.568, clip=80, loss_scale=64, train_wall=81, gb_free=6.8, wall=117385
2022-05-21 06:01:21 - progress_bar.py[line:274] - INFO: epoch 002:   1863 / 7081 loss=-0.008, score=1.551, ntokens=881.5, nsentences=80, sample_size=881.5, wps=108.3, ups=0.12, wpb=881.5, bsz=80, num_updates=8930, lr=2.0864e-06, gnorm=1.92, clip=90, loss_scale=64, train_wall=81, gb_free=6.8, wall=117466
2022-05-21 06:02:42 - progress_bar.py[line:274] - INFO: epoch 002:   1873 / 7081 loss=-0.008, score=1.46, ntokens=880, nsentences=80, sample_size=880, wps=109.7, ups=0.12, wpb=880, bsz=80, num_updates=8940, lr=2.08279e-06, gnorm=1.921, clip=70, loss_scale=64, train_wall=80, gb_free=6.8, wall=117546
2022-05-21 06:04:03 - progress_bar.py[line:274] - INFO: epoch 002:   1883 / 7081 loss=-0.007, score=1.526, ntokens=898.8, nsentences=80, sample_size=898.8, wps=110.8, ups=0.12, wpb=898.8, bsz=80, num_updates=8950, lr=2.07919e-06, gnorm=1.716, clip=90, loss_scale=64, train_wall=81, gb_free=6.8, wall=117627
2022-05-21 06:05:23 - progress_bar.py[line:274] - INFO: epoch 002:   1893 / 7081 loss=-0.003, score=1.408, ntokens=876.3, nsentences=80, sample_size=876.3, wps=108.5, ups=0.12, wpb=876.3, bsz=80, num_updates=8960, lr=2.07558e-06, gnorm=2.16, clip=90, loss_scale=64, train_wall=81, gb_free=6.8, wall=117708
2022-05-21 06:06:45 - progress_bar.py[line:274] - INFO: epoch 002:   1903 / 7081 loss=-0.004, score=1.41, ntokens=891.3, nsentences=80, sample_size=891.3, wps=109.4, ups=0.12, wpb=891.3, bsz=80, num_updates=8970, lr=2.07197e-06, gnorm=1.87, clip=90, loss_scale=64, train_wall=81, gb_free=6.8, wall=117790
2022-05-21 06:08:06 - progress_bar.py[line:274] - INFO: epoch 002:   1913 / 7081 loss=-0.004, score=1.462, ntokens=879.5, nsentences=80, sample_size=879.5, wps=108.3, ups=0.12, wpb=879.5, bsz=80, num_updates=8980, lr=2.06837e-06, gnorm=1.648, clip=80, loss_scale=64, train_wall=81, gb_free=6.8, wall=117871
2022-05-21 06:09:27 - progress_bar.py[line:274] - INFO: epoch 002:   1923 / 7081 loss=-0.007, score=1.447, ntokens=876, nsentences=80, sample_size=876, wps=108.2, ups=0.12, wpb=876, bsz=80, num_updates=8990, lr=2.06476e-06, gnorm=1.714, clip=90, loss_scale=64, train_wall=81, gb_free=6.8, wall=117952
2022-05-21 06:10:49 - progress_bar.py[line:274] - INFO: epoch 002:   1933 / 7081 loss=-0.007, score=1.488, ntokens=890.3, nsentences=80, sample_size=890.3, wps=109.1, ups=0.12, wpb=890.3, bsz=80, num_updates=9000, lr=2.06116e-06, gnorm=2.082, clip=80, loss_scale=64, train_wall=82, gb_free=6.8, wall=118033
2022-05-21 06:10:49 - train.py[line:436] - INFO: begin validation on "valid" subset
slice_id 0 seek offset 0
slice_id 1 seek offset 2500
slice_id 0 seek offset 0
slice_id 1 seek offset 2500
2022-05-21 06:50:52 - progress_bar.py[line:282] - INFO: epoch 002 | valid on 'valid' subset | loss -0.005 | score 1.297 | ntokens 111.386 | nsentences 10 | sample_size 111.386 | cider 1.394 | wps 115.9 | wpb 111.4 | bsz 10 | num_updates 9000 | best_cider 1.394
2022-05-21 06:50:52 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 2 @ 9000 updates
2022-05-21 06:50:52 - trainer.py[line:431] - INFO: Saving checkpoint to /database/jhkim/stage2_checkpoints//5e-6_2/checkpoint_2_9000.pt
2022-05-21 06:51:01 - trainer.py[line:441] - INFO: Finished saving checkpoint to /database/jhkim/stage2_checkpoints//5e-6_2/checkpoint_2_9000.pt
2022-05-21 06:52:25 - checkpoint_utils.py[line:135] - INFO: Saved checkpoint /database/jhkim/stage2_checkpoints//5e-6_2/checkpoint_2_9000.pt (epoch 2 @ 9000 updates, score 1.394) (writing took 93.38225645618513 seconds)
2022-05-21 06:53:46 - progress_bar.py[line:274] - INFO: epoch 002:   1943 / 7081 loss=-0.005, score=1.446, ntokens=885.1, nsentences=80, sample_size=885.1, wps=3.4, ups=0, wpb=885.1, bsz=80, num_updates=9010, lr=2.05755e-06, gnorm=1.757, clip=90, loss_scale=64, train_wall=80, gb_free=6.7, wall=120611
2022-05-21 06:55:07 - progress_bar.py[line:274] - INFO: epoch 002:   1953 / 7081 loss=-0.008, score=1.443, ntokens=892.6, nsentences=80, sample_size=892.6, wps=110.5, ups=0.12, wpb=892.6, bsz=80, num_updates=9020, lr=2.05395e-06, gnorm=1.627, clip=90, loss_scale=64, train_wall=81, gb_free=6.8, wall=120691
2022-05-21 06:56:29 - progress_bar.py[line:274] - INFO: epoch 002:   1963 / 7081 loss=-0.008, score=1.377, ntokens=896.6, nsentences=80, sample_size=896.6, wps=109.6, ups=0.12, wpb=896.6, bsz=80, num_updates=9030, lr=2.05034e-06, gnorm=2.628, clip=100, loss_scale=64, train_wall=82, gb_free=6.8, wall=120773
2022-05-21 06:57:50 - progress_bar.py[line:274] - INFO: epoch 002:   1973 / 7081 loss=-0.006, score=1.413, ntokens=899.9, nsentences=80, sample_size=899.9, wps=110.4, ups=0.12, wpb=899.9, bsz=80, num_updates=9040, lr=2.04674e-06, gnorm=1.749, clip=90, loss_scale=64, train_wall=81, gb_free=6.7, wall=120855
2022-05-21 06:59:12 - progress_bar.py[line:274] - INFO: epoch 002:   1983 / 7081 loss=-0.005, score=1.562, ntokens=885.3, nsentences=80, sample_size=885.3, wps=108.7, ups=0.12, wpb=885.3, bsz=80, num_updates=9050, lr=2.04313e-06, gnorm=1.483, clip=90, loss_scale=64, train_wall=81, gb_free=6.8, wall=120936
2022-05-21 07:00:32 - progress_bar.py[line:274] - INFO: epoch 002:   1993 / 7081 loss=-0.006, score=1.559, ntokens=889.9, nsentences=80, sample_size=889.9, wps=109.9, ups=0.12, wpb=889.9, bsz=80, num_updates=9060, lr=2.03953e-06, gnorm=1.651, clip=90, loss_scale=64, train_wall=81, gb_free=6.8, wall=121017
2022-05-21 07:01:53 - progress_bar.py[line:274] - INFO: epoch 002:   2003 / 7081 loss=-0.006, score=1.504, ntokens=873.3, nsentences=80, sample_size=873.3, wps=108.2, ups=0.12, wpb=873.3, bsz=80, num_updates=9070, lr=2.03592e-06, gnorm=2.593, clip=100, loss_scale=64, train_wall=81, gb_free=6.8, wall=121098
2022-05-21 07:03:14 - progress_bar.py[line:274] - INFO: epoch 002:   2013 / 7081 loss=-0.006, score=1.441, ntokens=887.2, nsentences=80, sample_size=887.2, wps=109.8, ups=0.12, wpb=887.2, bsz=80, num_updates=9080, lr=2.03231e-06, gnorm=1.729, clip=100, loss_scale=64, train_wall=81, gb_free=6.8, wall=121179
2022-05-21 07:04:35 - progress_bar.py[line:274] - INFO: epoch 002:   2023 / 7081 loss=-0.004, score=1.49, ntokens=900.6, nsentences=80, sample_size=900.6, wps=111.4, ups=0.12, wpb=900.6, bsz=80, num_updates=9090, lr=2.02871e-06, gnorm=2.66, clip=100, loss_scale=64, train_wall=81, gb_free=6.8, wall=121260
2022-05-21 07:05:51 - progress_bar.py[line:274] - INFO: epoch 002:   2033 / 7081 loss=-0.003, score=1.384, ntokens=884.5, nsentences=80, sample_size=884.5, wps=116.1, ups=0.13, wpb=884.5, bsz=80, num_updates=9100, lr=2.0251e-06, gnorm=1.561, clip=100, loss_scale=64, train_wall=76, gb_free=6.8, wall=121336
2022-05-21 07:07:08 - progress_bar.py[line:274] - INFO: epoch 002:   2043 / 7081 loss=-0.007, score=1.435, ntokens=887, nsentences=80, sample_size=887, wps=114.7, ups=0.13, wpb=887, bsz=80, num_updates=9110, lr=2.0215e-06, gnorm=1.592, clip=70, loss_scale=64, train_wall=77, gb_free=6.8, wall=121413
2022-05-21 07:08:29 - progress_bar.py[line:274] - INFO: epoch 002:   2053 / 7081 loss=-0.006, score=1.453, ntokens=890.9, nsentences=80, sample_size=890.9, wps=110.4, ups=0.12, wpb=890.9, bsz=80, num_updates=9120, lr=2.01789e-06, gnorm=1.947, clip=90, loss_scale=64, train_wall=81, gb_free=6.7, wall=121494
2022-05-21 07:09:52 - progress_bar.py[line:274] - INFO: epoch 002:   2063 / 7081 loss=-0.004, score=1.441, ntokens=910.9, nsentences=80, sample_size=910.9, wps=110.3, ups=0.12, wpb=910.9, bsz=80, num_updates=9130, lr=2.01429e-06, gnorm=1.479, clip=90, loss_scale=64, train_wall=82, gb_free=6.8, wall=121576
2022-05-21 07:11:12 - progress_bar.py[line:274] - INFO: epoch 002:   2073 / 7081 loss=-0.007, score=1.395, ntokens=874.4, nsentences=80, sample_size=874.4, wps=108.3, ups=0.12, wpb=874.4, bsz=80, num_updates=9140, lr=2.01068e-06, gnorm=1.522, clip=60, loss_scale=64, train_wall=81, gb_free=6.8, wall=121657
2022-05-21 07:12:33 - progress_bar.py[line:274] - INFO: epoch 002:   2083 / 7081 loss=-0.005, score=1.474, ntokens=898.8, nsentences=80, sample_size=898.8, wps=110.8, ups=0.12, wpb=898.8, bsz=80, num_updates=9150, lr=2.00708e-06, gnorm=1.623, clip=80, loss_scale=64, train_wall=81, gb_free=6.8, wall=121738
2022-05-21 07:13:54 - progress_bar.py[line:274] - INFO: epoch 002:   2093 / 7081 loss=-0.007, score=1.46, ntokens=876.9, nsentences=80, sample_size=876.9, wps=108.4, ups=0.12, wpb=876.9, bsz=80, num_updates=9160, lr=2.00347e-06, gnorm=2.441, clip=90, loss_scale=64, train_wall=81, gb_free=6.8, wall=121819
2022-05-21 07:15:16 - progress_bar.py[line:274] - INFO: epoch 002:   2103 / 7081 loss=-0.005, score=1.433, ntokens=911.9, nsentences=80, sample_size=911.9, wps=111.6, ups=0.12, wpb=911.9, bsz=80, num_updates=9170, lr=1.99986e-06, gnorm=1.56, clip=90, loss_scale=64, train_wall=82, gb_free=6.8, wall=121901
2022-05-21 07:16:37 - progress_bar.py[line:274] - INFO: epoch 002:   2113 / 7081 loss=-0.006, score=1.466, ntokens=893.5, nsentences=80, sample_size=893.5, wps=109.8, ups=0.12, wpb=893.5, bsz=80, num_updates=9180, lr=1.99626e-06, gnorm=1.665, clip=100, loss_scale=64, train_wall=81, gb_free=6.8, wall=121982
2022-05-21 07:17:59 - progress_bar.py[line:274] - INFO: epoch 002:   2123 / 7081 loss=-0.007, score=1.471, ntokens=883.2, nsentences=80, sample_size=883.2, wps=108.5, ups=0.12, wpb=883.2, bsz=80, num_updates=9190, lr=1.99265e-06, gnorm=2.418, clip=90, loss_scale=64, train_wall=81, gb_free=6.8, wall=122064
2022-05-21 07:19:20 - progress_bar.py[line:274] - INFO: epoch 002:   2133 / 7081 loss=-0.004, score=1.388, ntokens=916, nsentences=80, sample_size=916, wps=112.4, ups=0.12, wpb=916, bsz=80, num_updates=9200, lr=1.98905e-06, gnorm=1.525, clip=100, loss_scale=64, train_wall=81, gb_free=6.8, wall=122145
2022-05-21 07:20:41 - progress_bar.py[line:274] - INFO: epoch 002:   2143 / 7081 loss=-0.008, score=1.446, ntokens=874, nsentences=80, sample_size=874, wps=107.9, ups=0.12, wpb=874, bsz=80, num_updates=9210, lr=1.98544e-06, gnorm=1.673, clip=90, loss_scale=64, train_wall=81, gb_free=6.8, wall=122226
2022-05-21 07:22:03 - progress_bar.py[line:274] - INFO: epoch 002:   2153 / 7081 loss=-0.006, score=1.405, ntokens=892.4, nsentences=80, sample_size=892.4, wps=109.9, ups=0.12, wpb=892.4, bsz=80, num_updates=9220, lr=1.98184e-06, gnorm=1.634, clip=90, loss_scale=64, train_wall=81, gb_free=6.8, wall=122307
2022-05-21 07:23:24 - progress_bar.py[line:274] - INFO: epoch 002:   2163 / 7081 loss=-0.008, score=1.346, ntokens=887.7, nsentences=80, sample_size=887.7, wps=109.1, ups=0.12, wpb=887.7, bsz=80, num_updates=9230, lr=1.97823e-06, gnorm=1.948, clip=90, loss_scale=64, train_wall=81, gb_free=6.7, wall=122389
2022-05-21 07:24:45 - progress_bar.py[line:274] - INFO: epoch 002:   2173 / 7081 loss=-0.008, score=1.607, ntokens=900.4, nsentences=80, sample_size=900.4, wps=111, ups=0.12, wpb=900.4, bsz=80, num_updates=9240, lr=1.97463e-06, gnorm=1.789, clip=100, loss_scale=64, train_wall=81, gb_free=6.8, wall=122470
2022-05-21 07:26:06 - progress_bar.py[line:274] - INFO: epoch 002:   2183 / 7081 loss=-0.006, score=1.343, ntokens=886.1, nsentences=80, sample_size=886.1, wps=110.1, ups=0.12, wpb=886.1, bsz=80, num_updates=9250, lr=1.97102e-06, gnorm=1.356, clip=70, loss_scale=64, train_wall=80, gb_free=6.8, wall=122550
2022-05-21 07:27:27 - progress_bar.py[line:274] - INFO: epoch 002:   2193 / 7081 loss=-0.007, score=1.519, ntokens=893.3, nsentences=80, sample_size=893.3, wps=110.1, ups=0.12, wpb=893.3, bsz=80, num_updates=9260, lr=1.96742e-06, gnorm=1.932, clip=90, loss_scale=64, train_wall=81, gb_free=6.8, wall=122631
2022-05-21 07:28:48 - progress_bar.py[line:274] - INFO: epoch 002:   2203 / 7081 loss=-0.008, score=1.501, ntokens=890.3, nsentences=80, sample_size=890.3, wps=109.1, ups=0.12, wpb=890.3, bsz=80, num_updates=9270, lr=1.96381e-06, gnorm=1.952, clip=90, loss_scale=64, train_wall=81, gb_free=6.8, wall=122713
2022-05-21 07:30:10 - progress_bar.py[line:274] - INFO: epoch 002:   2213 / 7081 loss=-0.006, score=1.416, ntokens=896.9, nsentences=80, sample_size=896.9, wps=110.2, ups=0.12, wpb=896.9, bsz=80, num_updates=9280, lr=1.9602e-06, gnorm=1.918, clip=100, loss_scale=64, train_wall=81, gb_free=6.8, wall=122794
2022-05-21 07:31:27 - progress_bar.py[line:274] - INFO: epoch 002:   2223 / 7081 loss=-0.006, score=1.488, ntokens=883.5, nsentences=80, sample_size=883.5, wps=113.9, ups=0.13, wpb=883.5, bsz=80, num_updates=9290, lr=1.9566e-06, gnorm=1.32, clip=80, loss_scale=64, train_wall=78, gb_free=6.8, wall=122872
2022-05-21 07:32:44 - progress_bar.py[line:274] - INFO: epoch 002:   2233 / 7081 loss=-0.006, score=1.428, ntokens=893.3, nsentences=80, sample_size=893.3, wps=115.9, ups=0.13, wpb=893.3, bsz=80, num_updates=9300, lr=1.95299e-06, gnorm=1.856, clip=100, loss_scale=128, train_wall=77, gb_free=6.8, wall=122949
2022-05-21 07:34:03 - progress_bar.py[line:274] - INFO: epoch 002:   2243 / 7081 loss=-0.008, score=1.439, ntokens=882.2, nsentences=80, sample_size=882.2, wps=111.7, ups=0.13, wpb=882.2, bsz=80, num_updates=9310, lr=1.94939e-06, gnorm=1.396, clip=70, loss_scale=128, train_wall=79, gb_free=6.8, wall=123028
2022-05-21 07:35:24 - progress_bar.py[line:274] - INFO: epoch 002:   2253 / 7081 loss=-0.009, score=1.495, ntokens=891.9, nsentences=80, sample_size=891.9, wps=109.9, ups=0.12, wpb=891.9, bsz=80, num_updates=9320, lr=1.94578e-06, gnorm=1.626, clip=80, loss_scale=128, train_wall=81, gb_free=6.7, wall=123109
2022-05-21 07:36:45 - progress_bar.py[line:274] - INFO: epoch 002:   2263 / 7081 loss=-0.009, score=1.547, ntokens=889.1, nsentences=80, sample_size=889.1, wps=110, ups=0.12, wpb=889.1, bsz=80, num_updates=9330, lr=1.94218e-06, gnorm=1.823, clip=90, loss_scale=128, train_wall=81, gb_free=6.8, wall=123190
2022-05-21 07:38:07 - progress_bar.py[line:274] - INFO: epoch 002:   2273 / 7081 loss=-0.005, score=1.405, ntokens=903.6, nsentences=80, sample_size=903.6, wps=111, ups=0.12, wpb=903.6, bsz=80, num_updates=9340, lr=1.93857e-06, gnorm=1.29, clip=70, loss_scale=128, train_wall=81, gb_free=6.8, wall=123271
2022-05-21 07:39:28 - progress_bar.py[line:274] - INFO: epoch 002:   2283 / 7081 loss=-0.006, score=1.518, ntokens=888.6, nsentences=80, sample_size=888.6, wps=109.6, ups=0.12, wpb=888.6, bsz=80, num_updates=9350, lr=1.93497e-06, gnorm=1.647, clip=100, loss_scale=128, train_wall=81, gb_free=6.8, wall=123352
2022-05-21 07:40:49 - progress_bar.py[line:274] - INFO: epoch 002:   2293 / 7081 loss=-0.005, score=1.434, ntokens=895.3, nsentences=80, sample_size=895.3, wps=110.2, ups=0.12, wpb=895.3, bsz=80, num_updates=9360, lr=1.93136e-06, gnorm=1.599, clip=100, loss_scale=128, train_wall=81, gb_free=6.8, wall=123434
2022-05-21 07:42:09 - progress_bar.py[line:274] - INFO: epoch 002:   2303 / 7081 loss=-0.01, score=1.463, ntokens=885.6, nsentences=80, sample_size=885.6, wps=110.4, ups=0.12, wpb=885.6, bsz=80, num_updates=9370, lr=1.92775e-06, gnorm=2.058, clip=80, loss_scale=128, train_wall=80, gb_free=6.8, wall=123514
2022-05-21 07:43:30 - progress_bar.py[line:274] - INFO: epoch 002:   2313 / 7081 loss=-0.008, score=1.446, ntokens=893, nsentences=80, sample_size=893, wps=110.9, ups=0.12, wpb=893, bsz=80, num_updates=9380, lr=1.92415e-06, gnorm=1.562, clip=90, loss_scale=128, train_wall=80, gb_free=6.8, wall=123594
2022-05-21 07:44:50 - progress_bar.py[line:274] - INFO: epoch 002:   2323 / 7081 loss=-0.004, score=1.45, ntokens=882.7, nsentences=80, sample_size=882.7, wps=109.5, ups=0.12, wpb=882.7, bsz=80, num_updates=9390, lr=1.92054e-06, gnorm=2.038, clip=90, loss_scale=128, train_wall=81, gb_free=6.8, wall=123675
2022-05-21 07:46:11 - progress_bar.py[line:274] - INFO: epoch 002:   2333 / 7081 loss=-0.006, score=1.514, ntokens=890.5, nsentences=80, sample_size=890.5, wps=110.2, ups=0.12, wpb=890.5, bsz=80, num_updates=9400, lr=1.91694e-06, gnorm=2.014, clip=100, loss_scale=128, train_wall=81, gb_free=6.8, wall=123756
2022-05-21 07:47:32 - progress_bar.py[line:274] - INFO: epoch 002:   2343 / 7081 loss=-0.003, score=1.507, ntokens=896.6, nsentences=80, sample_size=896.6, wps=110.4, ups=0.12, wpb=896.6, bsz=80, num_updates=9410, lr=1.91333e-06, gnorm=1.765, clip=80, loss_scale=128, train_wall=81, gb_free=6.8, wall=123837
2022-05-21 07:48:05 - trainer.py[line:922] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-05-21 07:49:01 - progress_bar.py[line:274] - INFO: epoch 002:   2354 / 7081 loss=-0.007, score=1.444, ntokens=875.4, nsentences=80, sample_size=875.4, wps=98.4, ups=0.11, wpb=875.4, bsz=80, num_updates=9420, lr=1.90973e-06, gnorm=1.526, clip=100, loss_scale=64, train_wall=89, gb_free=6.8, wall=123926
2022-05-21 07:50:23 - progress_bar.py[line:274] - INFO: epoch 002:   2364 / 7081 loss=-0.008, score=1.398, ntokens=887.9, nsentences=80, sample_size=887.9, wps=108.5, ups=0.12, wpb=887.9, bsz=80, num_updates=9430, lr=1.90612e-06, gnorm=2.033, clip=70, loss_scale=64, train_wall=82, gb_free=6.8, wall=124008
2022-05-21 07:51:45 - progress_bar.py[line:274] - INFO: epoch 002:   2374 / 7081 loss=-0.004, score=1.42, ntokens=890.7, nsentences=80, sample_size=890.7, wps=109.2, ups=0.12, wpb=890.7, bsz=80, num_updates=9440, lr=1.90252e-06, gnorm=1.533, clip=90, loss_scale=64, train_wall=81, gb_free=6.8, wall=124090
2022-05-21 07:53:06 - progress_bar.py[line:274] - INFO: epoch 002:   2384 / 7081 loss=-0.008, score=1.455, ntokens=884.5, nsentences=80, sample_size=884.5, wps=109.3, ups=0.12, wpb=884.5, bsz=80, num_updates=9450, lr=1.89891e-06, gnorm=1.841, clip=90, loss_scale=64, train_wall=81, gb_free=6.7, wall=124170
2022-05-21 07:54:27 - progress_bar.py[line:274] - INFO: epoch 002:   2394 / 7081 loss=-0.005, score=1.471, ntokens=877.7, nsentences=80, sample_size=877.7, wps=108.5, ups=0.12, wpb=877.7, bsz=80, num_updates=9460, lr=1.89531e-06, gnorm=1.477, clip=70, loss_scale=64, train_wall=81, gb_free=6.8, wall=124251
2022-05-21 07:55:48 - progress_bar.py[line:274] - INFO: epoch 002:   2404 / 7081 loss=-0.004, score=1.398, ntokens=885.1, nsentences=80, sample_size=885.1, wps=109.4, ups=0.12, wpb=885.1, bsz=80, num_updates=9470, lr=1.8917e-06, gnorm=1.262, clip=80, loss_scale=64, train_wall=81, gb_free=6.8, wall=124332
2022-05-21 07:57:08 - progress_bar.py[line:274] - INFO: epoch 002:   2414 / 7081 loss=-0.006, score=1.341, ntokens=903.6, nsentences=80, sample_size=903.6, wps=112.9, ups=0.12, wpb=903.6, bsz=80, num_updates=9480, lr=1.88809e-06, gnorm=1.398, clip=80, loss_scale=64, train_wall=80, gb_free=6.8, wall=124412
2022-05-21 07:58:24 - progress_bar.py[line:274] - INFO: epoch 002:   2424 / 7081 loss=-0.006, score=1.49, ntokens=893, nsentences=80, sample_size=893, wps=116.7, ups=0.13, wpb=893, bsz=80, num_updates=9490, lr=1.88449e-06, gnorm=1.941, clip=100, loss_scale=64, train_wall=76, gb_free=6.8, wall=124489
2022-05-21 07:59:42 - progress_bar.py[line:274] - INFO: epoch 002:   2434 / 7081 loss=-0.009, score=1.421, ntokens=913.9, nsentences=80, sample_size=913.9, wps=117.3, ups=0.13, wpb=913.9, bsz=80, num_updates=9500, lr=1.88088e-06, gnorm=1.78, clip=100, loss_scale=64, train_wall=78, gb_free=6.8, wall=124567
2022-05-21 07:59:42 - train.py[line:436] - INFO: begin validation on "valid" subset
slice_id 0 seek offset 0
slice_id 1 seek offset 2500
slice_id 0 seek offset 0
slice_id 1 seek offset 2500
2022-05-21 08:39:51 - progress_bar.py[line:282] - INFO: epoch 002 | valid on 'valid' subset | loss -0.005 | score 1.297 | ntokens 111.43 | nsentences 10 | sample_size 111.43 | cider 1.392 | wps 115.6 | wpb 111.4 | bsz 10 | num_updates 9500 | best_cider 1.394
2022-05-21 08:39:51 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 2 @ 9500 updates
2022-05-21 08:39:51 - trainer.py[line:431] - INFO: Saving checkpoint to /database/jhkim/stage2_checkpoints//5e-6_2/checkpoint_2_9500.pt
2022-05-21 08:40:00 - trainer.py[line:441] - INFO: Finished saving checkpoint to /database/jhkim/stage2_checkpoints//5e-6_2/checkpoint_2_9500.pt
2022-05-21 08:40:44 - checkpoint_utils.py[line:135] - INFO: Saved checkpoint /database/jhkim/stage2_checkpoints//5e-6_2/checkpoint_2_9500.pt (epoch 2 @ 9500 updates, score 1.392) (writing took 53.42320984089747 seconds)
2022-05-21 08:42:04 - progress_bar.py[line:274] - INFO: epoch 002:   2444 / 7081 loss=-0.005, score=1.362, ntokens=888.8, nsentences=80, sample_size=888.8, wps=3.5, ups=0, wpb=888.8, bsz=80, num_updates=9510, lr=1.87728e-06, gnorm=1.622, clip=100, loss_scale=64, train_wall=79, gb_free=6.8, wall=127109
2022-05-21 08:43:25 - progress_bar.py[line:274] - INFO: epoch 002:   2454 / 7081 loss=-0.004, score=1.424, ntokens=887.8, nsentences=80, sample_size=887.8, wps=109.1, ups=0.12, wpb=887.8, bsz=80, num_updates=9520, lr=1.87367e-06, gnorm=1.332, clip=70, loss_scale=64, train_wall=81, gb_free=6.8, wall=127190
2022-05-21 08:44:46 - progress_bar.py[line:274] - INFO: epoch 002:   2464 / 7081 loss=-0.006, score=1.469, ntokens=878.4, nsentences=80, sample_size=878.4, wps=109.1, ups=0.12, wpb=878.4, bsz=80, num_updates=9530, lr=1.87007e-06, gnorm=1.713, clip=80, loss_scale=64, train_wall=80, gb_free=6.8, wall=127271
2022-05-21 08:46:07 - progress_bar.py[line:274] - INFO: epoch 002:   2474 / 7081 loss=-0.007, score=1.542, ntokens=893.2, nsentences=80, sample_size=893.2, wps=109.7, ups=0.12, wpb=893.2, bsz=80, num_updates=9540, lr=1.86646e-06, gnorm=1.217, clip=70, loss_scale=64, train_wall=81, gb_free=6.8, wall=127352
2022-05-21 08:47:29 - progress_bar.py[line:274] - INFO: epoch 002:   2484 / 7081 loss=-0.005, score=1.387, ntokens=904, nsentences=80, sample_size=904, wps=111.1, ups=0.12, wpb=904, bsz=80, num_updates=9550, lr=1.86286e-06, gnorm=1.108, clip=70, loss_scale=64, train_wall=81, gb_free=6.8, wall=127433
2022-05-21 08:48:50 - progress_bar.py[line:274] - INFO: epoch 002:   2494 / 7081 loss=-0.005, score=1.481, ntokens=893.1, nsentences=80, sample_size=893.1, wps=110.1, ups=0.12, wpb=893.1, bsz=80, num_updates=9560, lr=1.85925e-06, gnorm=1.463, clip=90, loss_scale=64, train_wall=81, gb_free=6.8, wall=127514
2022-05-21 08:50:06 - progress_bar.py[line:274] - INFO: epoch 002:   2504 / 7081 loss=-0.003, score=1.575, ntokens=885.6, nsentences=80, sample_size=885.6, wps=115.8, ups=0.13, wpb=885.6, bsz=80, num_updates=9570, lr=1.85564e-06, gnorm=1.665, clip=90, loss_scale=64, train_wall=76, gb_free=6.8, wall=127591
2022-05-21 08:51:23 - progress_bar.py[line:274] - INFO: epoch 002:   2514 / 7081 loss=-0.006, score=1.351, ntokens=902.9, nsentences=80, sample_size=902.9, wps=117.1, ups=0.13, wpb=902.9, bsz=80, num_updates=9580, lr=1.85204e-06, gnorm=1.981, clip=70, loss_scale=64, train_wall=77, gb_free=6.8, wall=127668
2022-05-21 08:52:44 - progress_bar.py[line:274] - INFO: epoch 002:   2524 / 7081 loss=-0.007, score=1.458, ntokens=889.1, nsentences=80, sample_size=889.1, wps=110.7, ups=0.12, wpb=889.1, bsz=80, num_updates=9590, lr=1.84843e-06, gnorm=1.451, clip=90, loss_scale=64, train_wall=80, gb_free=6.8, wall=127748
2022-05-21 08:54:05 - progress_bar.py[line:274] - INFO: epoch 002:   2534 / 7081 loss=-0.008, score=1.495, ntokens=886.4, nsentences=80, sample_size=886.4, wps=108.7, ups=0.12, wpb=886.4, bsz=80, num_updates=9600, lr=1.84483e-06, gnorm=1.663, clip=90, loss_scale=64, train_wall=81, gb_free=6.8, wall=127830
2022-05-21 08:55:27 - progress_bar.py[line:274] - INFO: epoch 002:   2544 / 7081 loss=-0.005, score=1.475, ntokens=894.2, nsentences=80, sample_size=894.2, wps=109.8, ups=0.12, wpb=894.2, bsz=80, num_updates=9610, lr=1.84122e-06, gnorm=2.065, clip=90, loss_scale=64, train_wall=81, gb_free=6.8, wall=127911
2022-05-21 08:56:48 - progress_bar.py[line:274] - INFO: epoch 002:   2554 / 7081 loss=-0.005, score=1.59, ntokens=891.6, nsentences=80, sample_size=891.6, wps=110, ups=0.12, wpb=891.6, bsz=80, num_updates=9620, lr=1.83762e-06, gnorm=1.858, clip=100, loss_scale=64, train_wall=81, gb_free=6.8, wall=127992
2022-05-21 08:58:09 - progress_bar.py[line:274] - INFO: epoch 002:   2564 / 7081 loss=-0.006, score=1.452, ntokens=889, nsentences=80, sample_size=889, wps=109.6, ups=0.12, wpb=889, bsz=80, num_updates=9630, lr=1.83401e-06, gnorm=1.408, clip=80, loss_scale=64, train_wall=81, gb_free=6.8, wall=128073
2022-05-21 08:59:30 - progress_bar.py[line:274] - INFO: epoch 002:   2574 / 7081 loss=-0.004, score=1.395, ntokens=898.6, nsentences=80, sample_size=898.6, wps=110.7, ups=0.12, wpb=898.6, bsz=80, num_updates=9640, lr=1.83041e-06, gnorm=1.486, clip=100, loss_scale=64, train_wall=81, gb_free=6.8, wall=128155
2022-05-21 09:00:51 - progress_bar.py[line:274] - INFO: epoch 002:   2584 / 7081 loss=-0.005, score=1.406, ntokens=892.8, nsentences=80, sample_size=892.8, wps=109.9, ups=0.12, wpb=892.8, bsz=80, num_updates=9650, lr=1.8268e-06, gnorm=1.351, clip=100, loss_scale=64, train_wall=81, gb_free=6.8, wall=128236
2022-05-21 09:02:13 - progress_bar.py[line:274] - INFO: epoch 002:   2594 / 7081 loss=-0.008, score=1.514, ntokens=898.6, nsentences=80, sample_size=898.6, wps=109.8, ups=0.12, wpb=898.6, bsz=80, num_updates=9660, lr=1.8232e-06, gnorm=1.791, clip=90, loss_scale=64, train_wall=82, gb_free=6.8, wall=128318
2022-05-21 09:03:34 - progress_bar.py[line:274] - INFO: epoch 002:   2604 / 7081 loss=-0.004, score=1.543, ntokens=890.9, nsentences=80, sample_size=890.9, wps=110.1, ups=0.12, wpb=890.9, bsz=80, num_updates=9670, lr=1.81959e-06, gnorm=1.561, clip=90, loss_scale=64, train_wall=81, gb_free=6.8, wall=128399
2022-05-21 09:04:55 - progress_bar.py[line:274] - INFO: epoch 002:   2614 / 7081 loss=-0.007, score=1.49, ntokens=886.5, nsentences=80, sample_size=886.5, wps=109.5, ups=0.12, wpb=886.5, bsz=80, num_updates=9680, lr=1.81598e-06, gnorm=1.853, clip=100, loss_scale=64, train_wall=81, gb_free=6.8, wall=128480
2022-05-21 09:06:16 - progress_bar.py[line:274] - INFO: epoch 002:   2624 / 7081 loss=-0.002, score=1.494, ntokens=876.8, nsentences=80, sample_size=876.8, wps=108.7, ups=0.12, wpb=876.8, bsz=80, num_updates=9690, lr=1.81238e-06, gnorm=1.991, clip=80, loss_scale=64, train_wall=81, gb_free=6.8, wall=128560
2022-05-21 09:07:37 - progress_bar.py[line:274] - INFO: epoch 002:   2634 / 7081 loss=-0.004, score=1.552, ntokens=889.1, nsentences=80, sample_size=889.1, wps=109.8, ups=0.12, wpb=889.1, bsz=80, num_updates=9700, lr=1.80877e-06, gnorm=1.893, clip=90, loss_scale=64, train_wall=81, gb_free=6.7, wall=128641
2022-05-21 09:08:58 - progress_bar.py[line:274] - INFO: epoch 002:   2644 / 7081 loss=-0.007, score=1.397, ntokens=900.4, nsentences=80, sample_size=900.4, wps=111, ups=0.12, wpb=900.4, bsz=80, num_updates=9710, lr=1.80517e-06, gnorm=1.679, clip=80, loss_scale=64, train_wall=81, gb_free=6.8, wall=128722
2022-05-21 09:10:19 - progress_bar.py[line:274] - INFO: epoch 002:   2654 / 7081 loss=-0.009, score=1.423, ntokens=890.5, nsentences=80, sample_size=890.5, wps=109.8, ups=0.12, wpb=890.5, bsz=80, num_updates=9720, lr=1.80156e-06, gnorm=1.339, clip=100, loss_scale=64, train_wall=81, gb_free=6.8, wall=128804
2022-05-21 09:11:40 - progress_bar.py[line:274] - INFO: epoch 002:   2664 / 7081 loss=-0.005, score=1.438, ntokens=892.3, nsentences=80, sample_size=892.3, wps=109.5, ups=0.12, wpb=892.3, bsz=80, num_updates=9730, lr=1.79796e-06, gnorm=0.953, clip=50, loss_scale=64, train_wall=81, gb_free=6.8, wall=128885
2022-05-21 09:13:01 - progress_bar.py[line:274] - INFO: epoch 002:   2674 / 7081 loss=-0.005, score=1.451, ntokens=885.4, nsentences=80, sample_size=885.4, wps=110, ups=0.12, wpb=885.4, bsz=80, num_updates=9740, lr=1.79435e-06, gnorm=1.666, clip=100, loss_scale=64, train_wall=80, gb_free=6.8, wall=128965
2022-05-21 09:14:22 - progress_bar.py[line:274] - INFO: epoch 002:   2684 / 7081 loss=-0.005, score=1.428, ntokens=891.9, nsentences=80, sample_size=891.9, wps=109.9, ups=0.12, wpb=891.9, bsz=80, num_updates=9750, lr=1.79075e-06, gnorm=1.157, clip=60, loss_scale=64, train_wall=81, gb_free=6.8, wall=129047
2022-05-21 09:15:40 - progress_bar.py[line:274] - INFO: epoch 002:   2694 / 7081 loss=-0.004, score=1.462, ntokens=895.2, nsentences=80, sample_size=895.2, wps=114.9, ups=0.13, wpb=895.2, bsz=80, num_updates=9760, lr=1.78714e-06, gnorm=1.228, clip=80, loss_scale=64, train_wall=78, gb_free=6.8, wall=129125
2022-05-21 09:16:57 - progress_bar.py[line:274] - INFO: epoch 002:   2704 / 7081 loss=-0.006, score=1.52, ntokens=886.4, nsentences=80, sample_size=886.4, wps=115.6, ups=0.13, wpb=886.4, bsz=80, num_updates=9770, lr=1.78353e-06, gnorm=1.669, clip=100, loss_scale=64, train_wall=77, gb_free=6.8, wall=129201
2022-05-21 09:18:16 - progress_bar.py[line:274] - INFO: epoch 002:   2714 / 7081 loss=-0.006, score=1.461, ntokens=905.4, nsentences=80, sample_size=905.4, wps=114.7, ups=0.13, wpb=905.4, bsz=80, num_updates=9780, lr=1.77993e-06, gnorm=1.439, clip=60, loss_scale=64, train_wall=79, gb_free=6.8, wall=129280
2022-05-21 09:19:36 - progress_bar.py[line:274] - INFO: epoch 002:   2724 / 7081 loss=-0.007, score=1.466, ntokens=889.1, nsentences=80, sample_size=889.1, wps=110.1, ups=0.12, wpb=889.1, bsz=80, num_updates=9790, lr=1.77632e-06, gnorm=1.628, clip=80, loss_scale=64, train_wall=81, gb_free=6.8, wall=129361
2022-05-21 09:20:57 - progress_bar.py[line:274] - INFO: epoch 002:   2734 / 7081 loss=-0.008, score=1.519, ntokens=883.3, nsentences=80, sample_size=883.3, wps=109.1, ups=0.12, wpb=883.3, bsz=80, num_updates=9800, lr=1.77272e-06, gnorm=1.751, clip=100, loss_scale=64, train_wall=81, gb_free=6.8, wall=129442
2022-05-21 09:22:19 - progress_bar.py[line:274] - INFO: epoch 002:   2744 / 7081 loss=-0.005, score=1.604, ntokens=890.7, nsentences=80, sample_size=890.7, wps=109.2, ups=0.12, wpb=890.7, bsz=80, num_updates=9810, lr=1.76911e-06, gnorm=2.173, clip=100, loss_scale=64, train_wall=81, gb_free=6.8, wall=129523
2022-05-21 09:23:40 - progress_bar.py[line:274] - INFO: epoch 002:   2754 / 7081 loss=-0.005, score=1.435, ntokens=894.8, nsentences=80, sample_size=894.8, wps=110.5, ups=0.12, wpb=894.8, bsz=80, num_updates=9820, lr=1.76551e-06, gnorm=2.391, clip=100, loss_scale=64, train_wall=81, gb_free=6.8, wall=129604
2022-05-21 09:25:02 - progress_bar.py[line:274] - INFO: epoch 002:   2764 / 7081 loss=-0.006, score=1.411, ntokens=897.5, nsentences=80, sample_size=897.5, wps=109.4, ups=0.12, wpb=897.5, bsz=80, num_updates=9830, lr=1.7619e-06, gnorm=1.75, clip=80, loss_scale=64, train_wall=82, gb_free=6.7, wall=129686
2022-05-21 09:26:23 - progress_bar.py[line:274] - INFO: epoch 002:   2774 / 7081 loss=-0.005, score=1.524, ntokens=883.8, nsentences=80, sample_size=883.8, wps=109.4, ups=0.12, wpb=883.8, bsz=80, num_updates=9840, lr=1.7583e-06, gnorm=1.888, clip=90, loss_scale=64, train_wall=81, gb_free=6.8, wall=129767
2022-05-21 09:27:44 - progress_bar.py[line:274] - INFO: epoch 002:   2784 / 7081 loss=-0.006, score=1.359, ntokens=900.8, nsentences=80, sample_size=900.8, wps=110.3, ups=0.12, wpb=900.8, bsz=80, num_updates=9850, lr=1.75469e-06, gnorm=1.509, clip=100, loss_scale=64, train_wall=82, gb_free=6.8, wall=129849
2022-05-21 09:29:06 - progress_bar.py[line:274] - INFO: epoch 002:   2794 / 7081 loss=-0.011, score=1.494, ntokens=887.9, nsentences=80, sample_size=887.9, wps=109.3, ups=0.12, wpb=887.9, bsz=80, num_updates=9860, lr=1.75109e-06, gnorm=2.239, clip=90, loss_scale=64, train_wall=81, gb_free=6.8, wall=129930
2022-05-21 09:30:27 - progress_bar.py[line:274] - INFO: epoch 002:   2804 / 7081 loss=-0.005, score=1.477, ntokens=884, nsentences=80, sample_size=884, wps=108.7, ups=0.12, wpb=884, bsz=80, num_updates=9870, lr=1.74748e-06, gnorm=1.641, clip=90, loss_scale=64, train_wall=81, gb_free=6.8, wall=130012
2022-05-21 09:31:48 - progress_bar.py[line:274] - INFO: epoch 002:   2814 / 7081 loss=-0.006, score=1.457, ntokens=892, nsentences=80, sample_size=892, wps=110.1, ups=0.12, wpb=892, bsz=80, num_updates=9880, lr=1.74387e-06, gnorm=1.316, clip=60, loss_scale=64, train_wall=81, gb_free=6.8, wall=130093
2022-05-21 09:33:08 - progress_bar.py[line:274] - INFO: epoch 002:   2824 / 7081 loss=-0.006, score=1.539, ntokens=885.5, nsentences=80, sample_size=885.5, wps=110.2, ups=0.12, wpb=885.5, bsz=80, num_updates=9890, lr=1.74027e-06, gnorm=1.481, clip=90, loss_scale=64, train_wall=80, gb_free=6.8, wall=130173
2022-05-21 09:34:29 - progress_bar.py[line:274] - INFO: epoch 002:   2834 / 7081 loss=-0.006, score=1.335, ntokens=889.9, nsentences=80, sample_size=889.9, wps=109.9, ups=0.12, wpb=889.9, bsz=80, num_updates=9900, lr=1.73666e-06, gnorm=1.811, clip=80, loss_scale=64, train_wall=81, gb_free=6.8, wall=130254
2022-05-21 09:35:50 - progress_bar.py[line:274] - INFO: epoch 002:   2844 / 7081 loss=-0.007, score=1.456, ntokens=885.7, nsentences=80, sample_size=885.7, wps=109.1, ups=0.12, wpb=885.7, bsz=80, num_updates=9910, lr=1.73306e-06, gnorm=2.198, clip=80, loss_scale=64, train_wall=81, gb_free=6.8, wall=130335
2022-05-21 09:37:11 - progress_bar.py[line:274] - INFO: epoch 002:   2854 / 7081 loss=-0.005, score=1.465, ntokens=883.2, nsentences=80, sample_size=883.2, wps=109.3, ups=0.12, wpb=883.2, bsz=80, num_updates=9920, lr=1.72945e-06, gnorm=2.029, clip=80, loss_scale=64, train_wall=81, gb_free=6.8, wall=130416
2022-05-21 09:38:33 - progress_bar.py[line:274] - INFO: epoch 002:   2864 / 7081 loss=-0.005, score=1.405, ntokens=896.1, nsentences=80, sample_size=896.1, wps=109.8, ups=0.12, wpb=896.1, bsz=80, num_updates=9930, lr=1.72585e-06, gnorm=1.46, clip=90, loss_scale=128, train_wall=82, gb_free=6.8, wall=130497
2022-05-21 09:39:55 - progress_bar.py[line:274] - INFO: epoch 002:   2874 / 7081 loss=-0.005, score=1.456, ntokens=901, nsentences=80, sample_size=901, wps=109.8, ups=0.12, wpb=901, bsz=80, num_updates=9940, lr=1.72224e-06, gnorm=1.628, clip=80, loss_scale=128, train_wall=82, gb_free=6.7, wall=130579
2022-05-21 09:41:14 - progress_bar.py[line:274] - INFO: epoch 002:   2884 / 7081 loss=-0.007, score=1.513, ntokens=884.4, nsentences=80, sample_size=884.4, wps=112.3, ups=0.13, wpb=884.4, bsz=80, num_updates=9950, lr=1.71864e-06, gnorm=1.84, clip=90, loss_scale=128, train_wall=79, gb_free=6.8, wall=130658
2022-05-21 09:42:30 - progress_bar.py[line:274] - INFO: epoch 002:   2894 / 7081 loss=-0.008, score=1.599, ntokens=886.9, nsentences=80, sample_size=886.9, wps=116.3, ups=0.13, wpb=886.9, bsz=80, num_updates=9960, lr=1.71503e-06, gnorm=1.864, clip=100, loss_scale=128, train_wall=76, gb_free=6.8, wall=130734
2022-05-21 09:43:47 - progress_bar.py[line:274] - INFO: epoch 002:   2904 / 7081 loss=-0.008, score=1.465, ntokens=889.8, nsentences=80, sample_size=889.8, wps=115.2, ups=0.13, wpb=889.8, bsz=80, num_updates=9970, lr=1.71142e-06, gnorm=1.667, clip=80, loss_scale=128, train_wall=77, gb_free=6.8, wall=130812
2022-05-21 09:45:08 - progress_bar.py[line:274] - INFO: epoch 002:   2914 / 7081 loss=-0.003, score=1.408, ntokens=891.9, nsentences=80, sample_size=891.9, wps=109.7, ups=0.12, wpb=891.9, bsz=80, num_updates=9980, lr=1.70782e-06, gnorm=1.573, clip=80, loss_scale=128, train_wall=81, gb_free=6.8, wall=130893
2022-05-21 09:46:30 - progress_bar.py[line:274] - INFO: epoch 002:   2924 / 7081 loss=-0.007, score=1.442, ntokens=902.9, nsentences=80, sample_size=902.9, wps=111, ups=0.12, wpb=902.9, bsz=80, num_updates=9990, lr=1.70421e-06, gnorm=1.433, clip=80, loss_scale=128, train_wall=81, gb_free=6.7, wall=130974
2022-05-21 09:47:51 - progress_bar.py[line:274] - INFO: epoch 002:   2934 / 7081 loss=-0.003, score=1.445, ntokens=897, nsentences=80, sample_size=897, wps=110.1, ups=0.12, wpb=897, bsz=80, num_updates=10000, lr=1.70061e-06, gnorm=1.457, clip=90, loss_scale=128, train_wall=81, gb_free=6.8, wall=131056
2022-05-21 09:47:51 - train.py[line:436] - INFO: begin validation on "valid" subset
slice_id 0 seek offset 0
slice_id 1 seek offset 2500
slice_id 0 seek offset 0
slice_id 1 seek offset 2500
2022-05-21 10:28:02 - progress_bar.py[line:282] - INFO: epoch 002 | valid on 'valid' subset | loss -0.005 | score 1.298 | ntokens 111.362 | nsentences 10 | sample_size 111.362 | cider 1.391 | wps 115.5 | wpb 111.4 | bsz 10 | num_updates 10000 | best_cider 1.394
2022-05-21 10:28:02 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 2 @ 10000 updates
2022-05-21 10:28:02 - trainer.py[line:431] - INFO: Saving checkpoint to /database/jhkim/stage2_checkpoints//5e-6_2/checkpoint_2_10000.pt
2022-05-21 10:28:10 - trainer.py[line:441] - INFO: Finished saving checkpoint to /database/jhkim/stage2_checkpoints//5e-6_2/checkpoint_2_10000.pt
2022-05-21 10:28:37 - checkpoint_utils.py[line:135] - INFO: Saved checkpoint /database/jhkim/stage2_checkpoints//5e-6_2/checkpoint_2_10000.pt (epoch 2 @ 10000 updates, score 1.391) (writing took 35.006062197033316 seconds)
2022-05-21 10:29:57 - progress_bar.py[line:274] - INFO: epoch 002:   2944 / 7081 loss=-0.006, score=1.452, ntokens=894.1, nsentences=80, sample_size=894.1, wps=3.5, ups=0, wpb=894.1, bsz=80, num_updates=10010, lr=1.697e-06, gnorm=1.31, clip=80, loss_scale=128, train_wall=80, gb_free=6.8, wall=133581
2022-05-21 10:31:18 - progress_bar.py[line:274] - INFO: epoch 002:   2954 / 7081 loss=-0.006, score=1.519, ntokens=893.5, nsentences=80, sample_size=893.5, wps=110.1, ups=0.12, wpb=893.5, bsz=80, num_updates=10020, lr=1.6934e-06, gnorm=1.48, clip=90, loss_scale=128, train_wall=81, gb_free=6.8, wall=133663
2022-05-21 10:32:39 - progress_bar.py[line:274] - INFO: epoch 002:   2964 / 7081 loss=-0.008, score=1.45, ntokens=881.3, nsentences=80, sample_size=881.3, wps=109.3, ups=0.12, wpb=881.3, bsz=80, num_updates=10030, lr=1.68979e-06, gnorm=1.549, clip=70, loss_scale=128, train_wall=81, gb_free=6.8, wall=133743
2022-05-21 10:33:55 - progress_bar.py[line:274] - INFO: epoch 002:   2974 / 7081 loss=-0.007, score=1.484, ntokens=896.6, nsentences=80, sample_size=896.6, wps=116.7, ups=0.13, wpb=896.6, bsz=80, num_updates=10040, lr=1.68619e-06, gnorm=1.556, clip=100, loss_scale=128, train_wall=77, gb_free=6.8, wall=133820
2022-05-21 10:35:13 - progress_bar.py[line:274] - INFO: epoch 002:   2984 / 7081 loss=-0.008, score=1.443, ntokens=901.1, nsentences=80, sample_size=901.1, wps=116.7, ups=0.13, wpb=901.1, bsz=80, num_updates=10050, lr=1.68258e-06, gnorm=1.72, clip=100, loss_scale=128, train_wall=77, gb_free=6.8, wall=133897
2022-05-21 10:36:33 - progress_bar.py[line:274] - INFO: epoch 002:   2994 / 7081 loss=-0.007, score=1.388, ntokens=898.7, nsentences=80, sample_size=898.7, wps=112.3, ups=0.12, wpb=898.7, bsz=80, num_updates=10060, lr=1.67898e-06, gnorm=1.639, clip=90, loss_scale=128, train_wall=80, gb_free=6.8, wall=133977
2022-05-21 10:37:55 - progress_bar.py[line:274] - INFO: epoch 002:   3004 / 7081 loss=-0.007, score=1.448, ntokens=899.7, nsentences=80, sample_size=899.7, wps=109.7, ups=0.12, wpb=899.7, bsz=80, num_updates=10070, lr=1.67537e-06, gnorm=2.139, clip=100, loss_scale=128, train_wall=82, gb_free=6.8, wall=134059
2022-05-21 10:39:16 - progress_bar.py[line:274] - INFO: epoch 002:   3014 / 7081 loss=-0.003, score=1.436, ntokens=893.3, nsentences=80, sample_size=893.3, wps=109.7, ups=0.12, wpb=893.3, bsz=80, num_updates=10080, lr=1.67176e-06, gnorm=1.422, clip=90, loss_scale=128, train_wall=81, gb_free=6.8, wall=134141
2022-05-21 10:40:37 - progress_bar.py[line:274] - INFO: epoch 002:   3024 / 7081 loss=-0.006, score=1.493, ntokens=881.3, nsentences=80, sample_size=881.3, wps=108.4, ups=0.12, wpb=881.3, bsz=80, num_updates=10090, lr=1.66816e-06, gnorm=1.338, clip=80, loss_scale=128, train_wall=81, gb_free=6.8, wall=134222
2022-05-21 10:41:59 - progress_bar.py[line:274] - INFO: epoch 002:   3034 / 7081 loss=-0.007, score=1.439, ntokens=880.7, nsentences=80, sample_size=880.7, wps=108.3, ups=0.12, wpb=880.7, bsz=80, num_updates=10100, lr=1.66455e-06, gnorm=1.621, clip=80, loss_scale=128, train_wall=81, gb_free=6.8, wall=134303
2022-05-21 10:43:20 - progress_bar.py[line:274] - INFO: epoch 002:   3044 / 7081 loss=-0.006, score=1.459, ntokens=889.8, nsentences=80, sample_size=889.8, wps=109.4, ups=0.12, wpb=889.8, bsz=80, num_updates=10110, lr=1.66095e-06, gnorm=1.392, clip=90, loss_scale=128, train_wall=81, gb_free=6.8, wall=134385
2022-05-21 10:44:41 - progress_bar.py[line:274] - INFO: epoch 002:   3054 / 7081 loss=-0.007, score=1.582, ntokens=882.5, nsentences=80, sample_size=882.5, wps=109.1, ups=0.12, wpb=882.5, bsz=80, num_updates=10120, lr=1.65734e-06, gnorm=1.809, clip=90, loss_scale=128, train_wall=81, gb_free=6.8, wall=134466
2022-05-21 10:46:02 - progress_bar.py[line:274] - INFO: epoch 002:   3064 / 7081 loss=-0.006, score=1.492, ntokens=890.2, nsentences=80, sample_size=890.2, wps=109.6, ups=0.12, wpb=890.2, bsz=80, num_updates=10130, lr=1.65374e-06, gnorm=1.482, clip=60, loss_scale=128, train_wall=81, gb_free=6.8, wall=134547
2022-05-21 10:47:23 - progress_bar.py[line:274] - INFO: epoch 002:   3074 / 7081 loss=-0.008, score=1.371, ntokens=886, nsentences=80, sample_size=886, wps=109.1, ups=0.12, wpb=886, bsz=80, num_updates=10140, lr=1.65013e-06, gnorm=1.657, clip=80, loss_scale=128, train_wall=81, gb_free=6.8, wall=134628
2022-05-21 10:48:44 - progress_bar.py[line:274] - INFO: epoch 002:   3084 / 7081 loss=-0.005, score=1.554, ntokens=894.2, nsentences=80, sample_size=894.2, wps=110.3, ups=0.12, wpb=894.2, bsz=80, num_updates=10150, lr=1.64653e-06, gnorm=1.433, clip=90, loss_scale=128, train_wall=81, gb_free=6.7, wall=134709
2022-05-21 10:50:05 - progress_bar.py[line:274] - INFO: epoch 002:   3094 / 7081 loss=-0.006, score=1.427, ntokens=875.4, nsentences=80, sample_size=875.4, wps=108.1, ups=0.12, wpb=875.4, bsz=80, num_updates=10160, lr=1.64292e-06, gnorm=1.609, clip=90, loss_scale=128, train_wall=81, gb_free=6.8, wall=134790
2022-05-21 10:51:26 - progress_bar.py[line:274] - INFO: epoch 002:   3104 / 7081 loss=-0.006, score=1.549, ntokens=883.9, nsentences=80, sample_size=883.9, wps=109.3, ups=0.12, wpb=883.9, bsz=80, num_updates=10170, lr=1.63931e-06, gnorm=1.567, clip=80, loss_scale=128, train_wall=81, gb_free=6.8, wall=134871
2022-05-21 10:52:47 - progress_bar.py[line:274] - INFO: epoch 002:   3114 / 7081 loss=-0.003, score=1.43, ntokens=883.7, nsentences=80, sample_size=883.7, wps=109, ups=0.12, wpb=883.7, bsz=80, num_updates=10180, lr=1.63571e-06, gnorm=1.453, clip=70, loss_scale=128, train_wall=81, gb_free=6.8, wall=134952
2022-05-21 10:54:08 - progress_bar.py[line:274] - INFO: epoch 002:   3124 / 7081 loss=-0.007, score=1.416, ntokens=879.6, nsentences=80, sample_size=879.6, wps=109.1, ups=0.12, wpb=879.6, bsz=80, num_updates=10190, lr=1.6321e-06, gnorm=1.424, clip=100, loss_scale=128, train_wall=81, gb_free=6.8, wall=135033
2022-05-21 10:55:29 - progress_bar.py[line:274] - INFO: epoch 002:   3134 / 7081 loss=-0.002, score=1.353, ntokens=903.1, nsentences=80, sample_size=903.1, wps=111.2, ups=0.12, wpb=903.1, bsz=80, num_updates=10200, lr=1.6285e-06, gnorm=1.568, clip=90, loss_scale=128, train_wall=81, gb_free=6.8, wall=135114
2022-05-21 10:56:50 - progress_bar.py[line:274] - INFO: epoch 002:   3144 / 7081 loss=-0.005, score=1.433, ntokens=890.2, nsentences=80, sample_size=890.2, wps=109.8, ups=0.12, wpb=890.2, bsz=80, num_updates=10210, lr=1.62489e-06, gnorm=2.041, clip=80, loss_scale=128, train_wall=81, gb_free=6.8, wall=135195
2022-05-21 10:58:12 - progress_bar.py[line:274] - INFO: epoch 002:   3154 / 7081 loss=-0.008, score=1.48, ntokens=879.3, nsentences=80, sample_size=879.3, wps=108.3, ups=0.12, wpb=879.3, bsz=80, num_updates=10220, lr=1.62129e-06, gnorm=1.413, clip=80, loss_scale=128, train_wall=81, gb_free=6.8, wall=135276
2022-05-21 10:59:30 - progress_bar.py[line:274] - INFO: epoch 002:   3164 / 7081 loss=-0.008, score=1.51, ntokens=889.3, nsentences=80, sample_size=889.3, wps=113.2, ups=0.13, wpb=889.3, bsz=80, num_updates=10230, lr=1.61768e-06, gnorm=1.454, clip=90, loss_scale=128, train_wall=78, gb_free=6.8, wall=135355
2022-05-21 11:00:46 - progress_bar.py[line:274] - INFO: epoch 002:   3174 / 7081 loss=-0.005, score=1.484, ntokens=870.9, nsentences=80, sample_size=870.9, wps=114.6, ups=0.13, wpb=870.9, bsz=80, num_updates=10240, lr=1.61408e-06, gnorm=1.598, clip=80, loss_scale=128, train_wall=76, gb_free=6.8, wall=135431
2022-05-21 11:02:04 - progress_bar.py[line:274] - INFO: epoch 002:   3184 / 7081 loss=-0.006, score=1.54, ntokens=890.2, nsentences=80, sample_size=890.2, wps=113.9, ups=0.13, wpb=890.2, bsz=80, num_updates=10250, lr=1.61047e-06, gnorm=1.598, clip=70, loss_scale=128, train_wall=78, gb_free=6.8, wall=135509
2022-05-21 11:03:24 - progress_bar.py[line:274] - INFO: epoch 002:   3194 / 7081 loss=-0.006, score=1.576, ntokens=869.8, nsentences=80, sample_size=869.8, wps=108.5, ups=0.12, wpb=869.8, bsz=80, num_updates=10260, lr=1.60687e-06, gnorm=1.529, clip=80, loss_scale=128, train_wall=80, gb_free=6.8, wall=135589
2022-05-21 11:04:45 - progress_bar.py[line:274] - INFO: epoch 002:   3204 / 7081 loss=-0.007, score=1.488, ntokens=886.1, nsentences=80, sample_size=886.1, wps=109.8, ups=0.12, wpb=886.1, bsz=80, num_updates=10270, lr=1.60326e-06, gnorm=1.498, clip=70, loss_scale=128, train_wall=81, gb_free=6.8, wall=135670
2022-05-21 11:06:06 - progress_bar.py[line:274] - INFO: epoch 002:   3214 / 7081 loss=-0.006, score=1.415, ntokens=886.1, nsentences=80, sample_size=886.1, wps=109.4, ups=0.12, wpb=886.1, bsz=80, num_updates=10280, lr=1.59965e-06, gnorm=1.499, clip=100, loss_scale=128, train_wall=81, gb_free=6.8, wall=135751
2022-05-21 11:07:27 - progress_bar.py[line:274] - INFO: epoch 002:   3224 / 7081 loss=-0.009, score=1.573, ntokens=883.4, nsentences=80, sample_size=883.4, wps=109, ups=0.12, wpb=883.4, bsz=80, num_updates=10290, lr=1.59605e-06, gnorm=1.548, clip=90, loss_scale=128, train_wall=81, gb_free=6.8, wall=135832
2022-05-21 11:08:48 - progress_bar.py[line:274] - INFO: epoch 002:   3234 / 7081 loss=-0.011, score=1.566, ntokens=884.2, nsentences=80, sample_size=884.2, wps=109.1, ups=0.12, wpb=884.2, bsz=80, num_updates=10300, lr=1.59244e-06, gnorm=1.442, clip=80, loss_scale=128, train_wall=81, gb_free=6.8, wall=135913
2022-05-21 11:10:09 - progress_bar.py[line:274] - INFO: epoch 002:   3244 / 7081 loss=-0.005, score=1.394, ntokens=878.4, nsentences=80, sample_size=878.4, wps=108.4, ups=0.12, wpb=878.4, bsz=80, num_updates=10310, lr=1.58884e-06, gnorm=1.562, clip=90, loss_scale=128, train_wall=81, gb_free=6.8, wall=135994
2022-05-21 11:11:31 - progress_bar.py[line:274] - INFO: epoch 002:   3254 / 7081 loss=-0.006, score=1.513, ntokens=899, nsentences=80, sample_size=899, wps=109.4, ups=0.12, wpb=899, bsz=80, num_updates=10320, lr=1.58523e-06, gnorm=1.594, clip=90, loss_scale=128, train_wall=82, gb_free=6.8, wall=136076
2022-05-21 11:12:52 - progress_bar.py[line:274] - INFO: epoch 002:   3264 / 7081 loss=-0.009, score=1.444, ntokens=877.5, nsentences=80, sample_size=877.5, wps=109.4, ups=0.12, wpb=877.5, bsz=80, num_updates=10330, lr=1.58163e-06, gnorm=1.877, clip=100, loss_scale=128, train_wall=80, gb_free=6.8, wall=136156
2022-05-21 11:14:13 - progress_bar.py[line:274] - INFO: epoch 002:   3274 / 7081 loss=-0.005, score=1.43, ntokens=887.3, nsentences=80, sample_size=887.3, wps=109.2, ups=0.12, wpb=887.3, bsz=80, num_updates=10340, lr=1.57802e-06, gnorm=1.481, clip=80, loss_scale=128, train_wall=81, gb_free=6.8, wall=136238
2022-05-21 11:15:33 - progress_bar.py[line:274] - INFO: epoch 002:   3284 / 7081 loss=-0.005, score=1.57, ntokens=875.2, nsentences=80, sample_size=875.2, wps=109.1, ups=0.12, wpb=875.2, bsz=80, num_updates=10350, lr=1.57442e-06, gnorm=1.788, clip=100, loss_scale=128, train_wall=80, gb_free=6.8, wall=136318
2022-05-21 11:16:54 - progress_bar.py[line:274] - INFO: epoch 002:   3294 / 7081 loss=-0.005, score=1.413, ntokens=875.1, nsentences=80, sample_size=875.1, wps=108.1, ups=0.12, wpb=875.1, bsz=80, num_updates=10360, lr=1.57081e-06, gnorm=2.339, clip=90, loss_scale=128, train_wall=81, gb_free=6.8, wall=136399
2022-05-21 11:18:15 - progress_bar.py[line:274] - INFO: epoch 002:   3304 / 7081 loss=-0.007, score=1.513, ntokens=884.3, nsentences=80, sample_size=884.3, wps=109, ups=0.12, wpb=884.3, bsz=80, num_updates=10370, lr=1.5672e-06, gnorm=1.621, clip=80, loss_scale=128, train_wall=81, gb_free=6.8, wall=136480
2022-05-21 11:19:36 - progress_bar.py[line:274] - INFO: epoch 002:   3314 / 7081 loss=-0.006, score=1.539, ntokens=890.1, nsentences=80, sample_size=890.1, wps=109.5, ups=0.12, wpb=890.1, bsz=80, num_updates=10380, lr=1.5636e-06, gnorm=1.356, clip=70, loss_scale=128, train_wall=81, gb_free=6.8, wall=136561
2022-05-21 11:20:58 - progress_bar.py[line:274] - INFO: epoch 002:   3324 / 7081 loss=-0.007, score=1.419, ntokens=889.7, nsentences=80, sample_size=889.7, wps=109.7, ups=0.12, wpb=889.7, bsz=80, num_updates=10390, lr=1.55999e-06, gnorm=2.059, clip=90, loss_scale=128, train_wall=81, gb_free=6.8, wall=136642
2022-05-21 11:22:18 - progress_bar.py[line:274] - INFO: epoch 002:   3334 / 7081 loss=-0.005, score=1.406, ntokens=883, nsentences=80, sample_size=883, wps=109.3, ups=0.12, wpb=883, bsz=80, num_updates=10400, lr=1.55639e-06, gnorm=1.987, clip=90, loss_scale=128, train_wall=81, gb_free=6.7, wall=136723
2022-05-21 11:23:39 - progress_bar.py[line:274] - INFO: epoch 002:   3344 / 7081 loss=-0.005, score=1.397, ntokens=893.5, nsentences=80, sample_size=893.5, wps=110.3, ups=0.12, wpb=893.5, bsz=80, num_updates=10410, lr=1.55278e-06, gnorm=1.53, clip=90, loss_scale=128, train_wall=81, gb_free=6.8, wall=136804
2022-05-21 11:25:00 - progress_bar.py[line:274] - INFO: epoch 002:   3354 / 7081 loss=-0.004, score=1.475, ntokens=900.1, nsentences=80, sample_size=900.1, wps=111.4, ups=0.12, wpb=900.1, bsz=80, num_updates=10420, lr=1.54918e-06, gnorm=1.31, clip=80, loss_scale=128, train_wall=81, gb_free=6.8, wall=136885
2022-05-21 11:26:16 - progress_bar.py[line:274] - INFO: epoch 002:   3364 / 7081 loss=-0.006, score=1.501, ntokens=879, nsentences=80, sample_size=879, wps=115.6, ups=0.13, wpb=879, bsz=80, num_updates=10430, lr=1.54557e-06, gnorm=1.726, clip=90, loss_scale=128, train_wall=76, gb_free=6.8, wall=136961
2022-05-21 11:27:33 - progress_bar.py[line:274] - INFO: epoch 002:   3374 / 7081 loss=-0.005, score=1.476, ntokens=892.2, nsentences=80, sample_size=892.2, wps=116.6, ups=0.13, wpb=892.2, bsz=80, num_updates=10440, lr=1.54197e-06, gnorm=1.669, clip=70, loss_scale=256, train_wall=76, gb_free=6.8, wall=137037
2022-05-21 11:28:53 - progress_bar.py[line:274] - INFO: epoch 002:   3384 / 7081 loss=-0.007, score=1.469, ntokens=884.9, nsentences=80, sample_size=884.9, wps=110.2, ups=0.12, wpb=884.9, bsz=80, num_updates=10450, lr=1.53836e-06, gnorm=1.313, clip=80, loss_scale=256, train_wall=80, gb_free=6.8, wall=137118
2022-05-21 11:29:01 - trainer.py[line:922] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 128.0
2022-05-21 11:30:22 - progress_bar.py[line:274] - INFO: epoch 002:   3395 / 7081 loss=-0.004, score=1.554, ntokens=886.3, nsentences=80, sample_size=886.3, wps=99.2, ups=0.11, wpb=886.3, bsz=80, num_updates=10460, lr=1.53476e-06, gnorm=1.304, clip=80, loss_scale=128, train_wall=89, gb_free=6.7, wall=137207
2022-05-21 11:31:43 - progress_bar.py[line:274] - INFO: epoch 002:   3405 / 7081 loss=-0.008, score=1.425, ntokens=878.3, nsentences=80, sample_size=878.3, wps=109.3, ups=0.12, wpb=878.3, bsz=80, num_updates=10470, lr=1.53115e-06, gnorm=1.411, clip=90, loss_scale=128, train_wall=80, gb_free=6.8, wall=137287
2022-05-21 11:33:04 - progress_bar.py[line:274] - INFO: epoch 002:   3415 / 7081 loss=-0.008, score=1.394, ntokens=886.9, nsentences=80, sample_size=886.9, wps=109.4, ups=0.12, wpb=886.9, bsz=80, num_updates=10480, lr=1.52754e-06, gnorm=1.347, clip=90, loss_scale=128, train_wall=81, gb_free=6.8, wall=137369
2022-05-21 11:34:25 - progress_bar.py[line:274] - INFO: epoch 002:   3425 / 7081 loss=-0.004, score=1.465, ntokens=891.5, nsentences=80, sample_size=891.5, wps=109.8, ups=0.12, wpb=891.5, bsz=80, num_updates=10490, lr=1.52394e-06, gnorm=1.562, clip=100, loss_scale=128, train_wall=81, gb_free=6.8, wall=137450
2022-05-21 11:35:46 - progress_bar.py[line:274] - INFO: epoch 002:   3435 / 7081 loss=-0.008, score=1.456, ntokens=899.8, nsentences=80, sample_size=899.8, wps=110.5, ups=0.12, wpb=899.8, bsz=80, num_updates=10500, lr=1.52033e-06, gnorm=2.272, clip=100, loss_scale=128, train_wall=81, gb_free=6.8, wall=137531
2022-05-21 11:35:46 - train.py[line:436] - INFO: begin validation on "valid" subset
slice_id 0 seek offset 0
slice_id 0 seek offset 0
slice_id 1 seek offset 2500
slice_id 1 seek offset 2500
2022-05-21 12:15:51 - progress_bar.py[line:282] - INFO: epoch 002 | valid on 'valid' subset | loss -0.005 | score 1.298 | ntokens 111.195 | nsentences 10 | sample_size 111.195 | cider 1.392 | wps 115.6 | wpb 111.2 | bsz 10 | num_updates 10500 | best_cider 1.394
2022-05-21 12:15:51 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 2 @ 10500 updates
2022-05-21 12:15:51 - trainer.py[line:431] - INFO: Saving checkpoint to /database/jhkim/stage2_checkpoints//5e-6_2/checkpoint_2_10500.pt
2022-05-21 12:16:00 - trainer.py[line:441] - INFO: Finished saving checkpoint to /database/jhkim/stage2_checkpoints//5e-6_2/checkpoint_2_10500.pt
2022-05-21 12:16:27 - checkpoint_utils.py[line:135] - INFO: Saved checkpoint /database/jhkim/stage2_checkpoints//5e-6_2/checkpoint_2_10500.pt (epoch 2 @ 10500 updates, score 1.392) (writing took 36.18557881191373 seconds)
2022-05-21 12:17:45 - progress_bar.py[line:274] - INFO: epoch 002:   3445 / 7081 loss=-0.008, score=1.469, ntokens=905.5, nsentences=80, sample_size=905.5, wps=3.6, ups=0, wpb=905.5, bsz=80, num_updates=10510, lr=1.51673e-06, gnorm=1.52, clip=80, loss_scale=128, train_wall=78, gb_free=6.8, wall=140050
2022-05-21 12:19:02 - progress_bar.py[line:274] - INFO: epoch 002:   3455 / 7081 loss=-0.005, score=1.435, ntokens=891, nsentences=80, sample_size=891, wps=116.5, ups=0.13, wpb=891, bsz=80, num_updates=10520, lr=1.51312e-06, gnorm=1.616, clip=80, loss_scale=128, train_wall=76, gb_free=6.7, wall=140126
2022-05-21 12:20:20 - progress_bar.py[line:274] - INFO: epoch 002:   3465 / 7081 loss=-0.006, score=1.459, ntokens=886.9, nsentences=80, sample_size=886.9, wps=112.9, ups=0.13, wpb=886.9, bsz=80, num_updates=10530, lr=1.50952e-06, gnorm=1.526, clip=90, loss_scale=128, train_wall=78, gb_free=6.8, wall=140205
2022-05-21 12:21:41 - progress_bar.py[line:274] - INFO: epoch 002:   3475 / 7081 loss=-0.007, score=1.543, ntokens=890.2, nsentences=80, sample_size=890.2, wps=110.2, ups=0.12, wpb=890.2, bsz=80, num_updates=10540, lr=1.50591e-06, gnorm=1.781, clip=90, loss_scale=128, train_wall=81, gb_free=6.8, wall=140286
2022-05-21 12:23:01 - progress_bar.py[line:274] - INFO: epoch 002:   3485 / 7081 loss=-0.008, score=1.474, ntokens=878.8, nsentences=80, sample_size=878.8, wps=109.4, ups=0.12, wpb=878.8, bsz=80, num_updates=10550, lr=1.50231e-06, gnorm=1.503, clip=80, loss_scale=128, train_wall=80, gb_free=6.8, wall=140366
2022-05-21 12:24:22 - progress_bar.py[line:274] - INFO: epoch 002:   3495 / 7081 loss=-0.008, score=1.551, ntokens=879.1, nsentences=80, sample_size=879.1, wps=108.7, ups=0.12, wpb=879.1, bsz=80, num_updates=10560, lr=1.4987e-06, gnorm=1.606, clip=100, loss_scale=128, train_wall=81, gb_free=6.8, wall=140447
2022-05-21 12:25:44 - progress_bar.py[line:274] - INFO: epoch 002:   3505 / 7081 loss=-0.005, score=1.466, ntokens=891.5, nsentences=80, sample_size=891.5, wps=109.6, ups=0.12, wpb=891.5, bsz=80, num_updates=10570, lr=1.4951e-06, gnorm=1.953, clip=80, loss_scale=128, train_wall=81, gb_free=6.8, wall=140528
2022-05-21 12:27:05 - progress_bar.py[line:274] - INFO: epoch 002:   3515 / 7081 loss=-0.007, score=1.443, ntokens=896.8, nsentences=80, sample_size=896.8, wps=110.2, ups=0.12, wpb=896.8, bsz=80, num_updates=10580, lr=1.49149e-06, gnorm=1.42, clip=90, loss_scale=128, train_wall=81, gb_free=6.8, wall=140610
2022-05-21 12:28:25 - progress_bar.py[line:274] - INFO: epoch 002:   3525 / 7081 loss=-0.005, score=1.497, ntokens=882.4, nsentences=80, sample_size=882.4, wps=109.5, ups=0.12, wpb=882.4, bsz=80, num_updates=10590, lr=1.48788e-06, gnorm=1.667, clip=90, loss_scale=128, train_wall=80, gb_free=6.8, wall=140690
2022-05-21 12:28:33 - trainer.py[line:922] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-05-21 12:29:54 - progress_bar.py[line:274] - INFO: epoch 002:   3536 / 7081 loss=-0.007, score=1.499, ntokens=886.7, nsentences=80, sample_size=886.7, wps=99.6, ups=0.11, wpb=886.7, bsz=80, num_updates=10600, lr=1.48428e-06, gnorm=1.737, clip=100, loss_scale=64, train_wall=89, gb_free=6.8, wall=140779
2022-05-21 12:31:15 - progress_bar.py[line:274] - INFO: epoch 002:   3546 / 7081 loss=-0.007, score=1.591, ntokens=879.7, nsentences=80, sample_size=879.7, wps=109.3, ups=0.12, wpb=879.7, bsz=80, num_updates=10610, lr=1.48067e-06, gnorm=1.505, clip=100, loss_scale=64, train_wall=80, gb_free=6.8, wall=140860
2022-05-21 12:32:36 - progress_bar.py[line:274] - INFO: epoch 002:   3556 / 7081 loss=-0.005, score=1.401, ntokens=884.8, nsentences=80, sample_size=884.8, wps=108.7, ups=0.12, wpb=884.8, bsz=80, num_updates=10620, lr=1.47707e-06, gnorm=1.4, clip=80, loss_scale=64, train_wall=81, gb_free=6.8, wall=140941
2022-05-21 12:33:58 - progress_bar.py[line:274] - INFO: epoch 002:   3566 / 7081 loss=-0.007, score=1.313, ntokens=890, nsentences=80, sample_size=890, wps=109.5, ups=0.12, wpb=890, bsz=80, num_updates=10630, lr=1.47346e-06, gnorm=2.282, clip=90, loss_scale=64, train_wall=81, gb_free=6.8, wall=141022
2022-05-21 12:35:18 - progress_bar.py[line:274] - INFO: epoch 002:   3576 / 7081 loss=-0.005, score=1.389, ntokens=891.7, nsentences=80, sample_size=891.7, wps=110.5, ups=0.12, wpb=891.7, bsz=80, num_updates=10640, lr=1.46986e-06, gnorm=1.837, clip=100, loss_scale=64, train_wall=81, gb_free=6.8, wall=141103
2022-05-21 12:36:39 - progress_bar.py[line:274] - INFO: epoch 002:   3586 / 7081 loss=-0.012, score=1.605, ntokens=881.6, nsentences=80, sample_size=881.6, wps=109, ups=0.12, wpb=881.6, bsz=80, num_updates=10650, lr=1.46625e-06, gnorm=1.641, clip=90, loss_scale=64, train_wall=81, gb_free=6.8, wall=141184
2022-05-21 12:38:00 - progress_bar.py[line:274] - INFO: epoch 002:   3596 / 7081 loss=-0.006, score=1.531, ntokens=883.3, nsentences=80, sample_size=883.3, wps=109, ups=0.12, wpb=883.3, bsz=80, num_updates=10660, lr=1.46265e-06, gnorm=1.701, clip=90, loss_scale=64, train_wall=81, gb_free=6.8, wall=141265
2022-05-21 12:39:22 - progress_bar.py[line:274] - INFO: epoch 002:   3606 / 7081 loss=-0.009, score=1.56, ntokens=899.1, nsentences=80, sample_size=899.1, wps=110.1, ups=0.12, wpb=899.1, bsz=80, num_updates=10670, lr=1.45904e-06, gnorm=2.262, clip=100, loss_scale=64, train_wall=82, gb_free=6.8, wall=141347
2022-05-21 12:40:43 - progress_bar.py[line:274] - INFO: epoch 002:   3616 / 7081 loss=-0.005, score=1.436, ntokens=881.6, nsentences=80, sample_size=881.6, wps=109.1, ups=0.12, wpb=881.6, bsz=80, num_updates=10680, lr=1.45543e-06, gnorm=1.853, clip=90, loss_scale=64, train_wall=81, gb_free=6.8, wall=141427
2022-05-21 12:42:04 - progress_bar.py[line:274] - INFO: epoch 002:   3626 / 7081 loss=-0.009, score=1.455, ntokens=881.1, nsentences=80, sample_size=881.1, wps=109, ups=0.12, wpb=881.1, bsz=80, num_updates=10690, lr=1.45183e-06, gnorm=1.849, clip=90, loss_scale=64, train_wall=81, gb_free=6.8, wall=141508
2022-05-21 12:43:23 - progress_bar.py[line:274] - INFO: epoch 002:   3636 / 7081 loss=-0.005, score=1.531, ntokens=889.8, nsentences=80, sample_size=889.8, wps=112.1, ups=0.13, wpb=889.8, bsz=80, num_updates=10700, lr=1.44822e-06, gnorm=1.791, clip=90, loss_scale=64, train_wall=79, gb_free=6.8, wall=141588
2022-05-21 12:44:39 - progress_bar.py[line:274] - INFO: epoch 002:   3646 / 7081 loss=-0.004, score=1.587, ntokens=881, nsentences=80, sample_size=881, wps=116.2, ups=0.13, wpb=881, bsz=80, num_updates=10710, lr=1.44462e-06, gnorm=1.856, clip=80, loss_scale=64, train_wall=76, gb_free=6.8, wall=141663
2022-05-21 12:45:56 - progress_bar.py[line:274] - INFO: epoch 002:   3656 / 7081 loss=-0.008, score=1.572, ntokens=880.3, nsentences=80, sample_size=880.3, wps=114.4, ups=0.13, wpb=880.3, bsz=80, num_updates=10720, lr=1.44101e-06, gnorm=1.51, clip=70, loss_scale=64, train_wall=77, gb_free=6.8, wall=141740
2022-05-21 12:47:17 - progress_bar.py[line:274] - INFO: epoch 002:   3666 / 7081 loss=-0.004, score=1.41, ntokens=892.5, nsentences=80, sample_size=892.5, wps=109.6, ups=0.12, wpb=892.5, bsz=80, num_updates=10730, lr=1.43741e-06, gnorm=1.373, clip=70, loss_scale=64, train_wall=81, gb_free=6.8, wall=141822
2022-05-21 12:48:38 - progress_bar.py[line:274] - INFO: epoch 002:   3676 / 7081 loss=-0.003, score=1.362, ntokens=885.7, nsentences=80, sample_size=885.7, wps=109.5, ups=0.12, wpb=885.7, bsz=80, num_updates=10740, lr=1.4338e-06, gnorm=1.618, clip=90, loss_scale=64, train_wall=81, gb_free=6.8, wall=141903
2022-05-21 12:49:59 - progress_bar.py[line:274] - INFO: epoch 002:   3686 / 7081 loss=-0.003, score=1.342, ntokens=898.8, nsentences=80, sample_size=898.8, wps=110.7, ups=0.12, wpb=898.8, bsz=80, num_updates=10750, lr=1.4302e-06, gnorm=1.626, clip=100, loss_scale=64, train_wall=81, gb_free=6.8, wall=141984
2022-05-21 12:51:20 - progress_bar.py[line:274] - INFO: epoch 002:   3696 / 7081 loss=-0.005, score=1.393, ntokens=879.9, nsentences=80, sample_size=879.9, wps=108.9, ups=0.12, wpb=879.9, bsz=80, num_updates=10760, lr=1.42659e-06, gnorm=1.384, clip=80, loss_scale=64, train_wall=81, gb_free=6.8, wall=142065
2022-05-21 12:52:40 - progress_bar.py[line:274] - INFO: epoch 002:   3706 / 7081 loss=-0.003, score=1.47, ntokens=892.1, nsentences=80, sample_size=892.1, wps=111.5, ups=0.12, wpb=892.1, bsz=80, num_updates=10770, lr=1.42299e-06, gnorm=1.615, clip=100, loss_scale=64, train_wall=80, gb_free=6.8, wall=142145
2022-05-21 12:54:01 - progress_bar.py[line:274] - INFO: epoch 002:   3716 / 7081 loss=-0.005, score=1.41, ntokens=880.7, nsentences=80, sample_size=880.7, wps=108.8, ups=0.12, wpb=880.7, bsz=80, num_updates=10780, lr=1.41938e-06, gnorm=1.957, clip=80, loss_scale=64, train_wall=81, gb_free=6.8, wall=142226
2022-05-21 12:55:22 - progress_bar.py[line:274] - INFO: epoch 002:   3726 / 7081 loss=-0.006, score=1.475, ntokens=890.7, nsentences=80, sample_size=890.7, wps=109.7, ups=0.12, wpb=890.7, bsz=80, num_updates=10790, lr=1.41577e-06, gnorm=1.665, clip=90, loss_scale=64, train_wall=81, gb_free=6.8, wall=142307
2022-05-21 12:56:43 - progress_bar.py[line:274] - INFO: epoch 002:   3736 / 7081 loss=-0.005, score=1.396, ntokens=887.3, nsentences=80, sample_size=887.3, wps=110.2, ups=0.12, wpb=887.3, bsz=80, num_updates=10800, lr=1.41217e-06, gnorm=1.651, clip=70, loss_scale=64, train_wall=80, gb_free=6.8, wall=142387
2022-05-21 12:58:03 - progress_bar.py[line:274] - INFO: epoch 002:   3746 / 7081 loss=-0.008, score=1.389, ntokens=885.6, nsentences=80, sample_size=885.6, wps=109.9, ups=0.12, wpb=885.6, bsz=80, num_updates=10810, lr=1.40856e-06, gnorm=1.486, clip=90, loss_scale=64, train_wall=81, gb_free=6.8, wall=142468
2022-05-21 12:59:25 - progress_bar.py[line:274] - INFO: epoch 002:   3756 / 7081 loss=-0.006, score=1.4, ntokens=888, nsentences=80, sample_size=888, wps=109, ups=0.12, wpb=888, bsz=80, num_updates=10820, lr=1.40496e-06, gnorm=1.394, clip=70, loss_scale=64, train_wall=81, gb_free=6.8, wall=142549
2022-05-21 13:00:46 - progress_bar.py[line:274] - INFO: epoch 002:   3766 / 7081 loss=-0.006, score=1.47, ntokens=893.6, nsentences=80, sample_size=893.6, wps=110, ups=0.12, wpb=893.6, bsz=80, num_updates=10830, lr=1.40135e-06, gnorm=1.914, clip=80, loss_scale=64, train_wall=81, gb_free=6.8, wall=142631
2022-05-21 13:02:07 - progress_bar.py[line:274] - INFO: epoch 002:   3776 / 7081 loss=-0.007, score=1.511, ntokens=903.1, nsentences=80, sample_size=903.1, wps=111.7, ups=0.12, wpb=903.1, bsz=80, num_updates=10840, lr=1.39775e-06, gnorm=1.34, clip=80, loss_scale=64, train_wall=81, gb_free=6.8, wall=142711
2022-05-21 13:03:27 - progress_bar.py[line:274] - INFO: epoch 002:   3786 / 7081 loss=-0.006, score=1.463, ntokens=880.5, nsentences=80, sample_size=880.5, wps=109.2, ups=0.12, wpb=880.5, bsz=80, num_updates=10850, lr=1.39414e-06, gnorm=1.697, clip=100, loss_scale=64, train_wall=81, gb_free=6.8, wall=142792
2022-05-21 13:04:48 - progress_bar.py[line:274] - INFO: epoch 002:   3796 / 7081 loss=-0.005, score=1.426, ntokens=877.5, nsentences=80, sample_size=877.5, wps=108.8, ups=0.12, wpb=877.5, bsz=80, num_updates=10860, lr=1.39054e-06, gnorm=1.416, clip=90, loss_scale=64, train_wall=81, gb_free=6.8, wall=142873
2022-05-21 13:06:10 - progress_bar.py[line:274] - INFO: epoch 002:   3806 / 7081 loss=-0.008, score=1.471, ntokens=897.3, nsentences=80, sample_size=897.3, wps=110, ups=0.12, wpb=897.3, bsz=80, num_updates=10870, lr=1.38693e-06, gnorm=1.602, clip=90, loss_scale=64, train_wall=82, gb_free=6.8, wall=142954
2022-05-21 13:07:31 - progress_bar.py[line:274] - INFO: epoch 002:   3816 / 7081 loss=-0.007, score=1.521, ntokens=885.6, nsentences=80, sample_size=885.6, wps=109, ups=0.12, wpb=885.6, bsz=80, num_updates=10880, lr=1.38332e-06, gnorm=1.972, clip=90, loss_scale=64, train_wall=81, gb_free=6.8, wall=143036
2022-05-21 13:08:52 - progress_bar.py[line:274] - INFO: epoch 002:   3826 / 7081 loss=-0.008, score=1.484, ntokens=884.4, nsentences=80, sample_size=884.4, wps=108.8, ups=0.12, wpb=884.4, bsz=80, num_updates=10890, lr=1.37972e-06, gnorm=1.847, clip=100, loss_scale=64, train_wall=81, gb_free=6.8, wall=143117
2022-05-21 13:10:10 - progress_bar.py[line:274] - INFO: epoch 002:   3836 / 7081 loss=-0.006, score=1.474, ntokens=892.2, nsentences=80, sample_size=892.2, wps=115.3, ups=0.13, wpb=892.2, bsz=80, num_updates=10900, lr=1.37611e-06, gnorm=1.339, clip=80, loss_scale=64, train_wall=77, gb_free=6.8, wall=143194
2022-05-21 13:11:26 - progress_bar.py[line:274] - INFO: epoch 002:   3846 / 7081 loss=-0.006, score=1.409, ntokens=878.3, nsentences=80, sample_size=878.3, wps=115.4, ups=0.13, wpb=878.3, bsz=80, num_updates=10910, lr=1.37251e-06, gnorm=1.853, clip=90, loss_scale=64, train_wall=76, gb_free=6.8, wall=143270
2022-05-21 13:12:44 - progress_bar.py[line:274] - INFO: epoch 002:   3856 / 7081 loss=-0.01, score=1.52, ntokens=876.8, nsentences=80, sample_size=876.8, wps=111.3, ups=0.13, wpb=876.8, bsz=80, num_updates=10920, lr=1.3689e-06, gnorm=1.518, clip=90, loss_scale=64, train_wall=79, gb_free=6.8, wall=143349
2022-05-21 13:14:05 - progress_bar.py[line:274] - INFO: epoch 002:   3866 / 7081 loss=-0.005, score=1.54, ntokens=879.5, nsentences=80, sample_size=879.5, wps=108.8, ups=0.12, wpb=879.5, bsz=80, num_updates=10930, lr=1.3653e-06, gnorm=1.634, clip=100, loss_scale=64, train_wall=81, gb_free=6.8, wall=143430
2022-05-21 13:15:26 - progress_bar.py[line:274] - INFO: epoch 002:   3876 / 7081 loss=-0.007, score=1.398, ntokens=888, nsentences=80, sample_size=888, wps=110, ups=0.12, wpb=888, bsz=80, num_updates=10940, lr=1.36169e-06, gnorm=3.831, clip=90, loss_scale=64, train_wall=81, gb_free=6.8, wall=143511
2022-05-21 13:16:48 - progress_bar.py[line:274] - INFO: epoch 002:   3886 / 7081 loss=-0.007, score=1.524, ntokens=898, nsentences=80, sample_size=898, wps=109.9, ups=0.12, wpb=898, bsz=80, num_updates=10950, lr=1.35809e-06, gnorm=1.903, clip=90, loss_scale=64, train_wall=82, gb_free=6.8, wall=143592
2022-05-21 13:18:09 - progress_bar.py[line:274] - INFO: epoch 002:   3896 / 7081 loss=-0.003, score=1.412, ntokens=894.1, nsentences=80, sample_size=894.1, wps=110.2, ups=0.12, wpb=894.1, bsz=80, num_updates=10960, lr=1.35448e-06, gnorm=1.803, clip=100, loss_scale=64, train_wall=81, gb_free=6.8, wall=143673
2022-05-21 13:19:30 - progress_bar.py[line:274] - INFO: epoch 002:   3906 / 7081 loss=-0.005, score=1.43, ntokens=885.4, nsentences=80, sample_size=885.4, wps=109, ups=0.12, wpb=885.4, bsz=80, num_updates=10970, lr=1.35088e-06, gnorm=1.399, clip=60, loss_scale=64, train_wall=81, gb_free=6.8, wall=143755
2022-05-21 13:20:52 - progress_bar.py[line:274] - INFO: epoch 002:   3916 / 7081 loss=-0.007, score=1.523, ntokens=890.4, nsentences=80, sample_size=890.4, wps=109.2, ups=0.12, wpb=890.4, bsz=80, num_updates=10980, lr=1.34727e-06, gnorm=1.385, clip=70, loss_scale=64, train_wall=81, gb_free=6.8, wall=143836
2022-05-21 13:22:13 - progress_bar.py[line:274] - INFO: epoch 002:   3926 / 7081 loss=-0.008, score=1.431, ntokens=884, nsentences=80, sample_size=884, wps=108.8, ups=0.12, wpb=884, bsz=80, num_updates=10990, lr=1.34366e-06, gnorm=2.157, clip=100, loss_scale=64, train_wall=81, gb_free=6.8, wall=143917
2022-05-21 13:23:34 - progress_bar.py[line:274] - INFO: epoch 002:   3936 / 7081 loss=-0.006, score=1.441, ntokens=889.6, nsentences=80, sample_size=889.6, wps=109.7, ups=0.12, wpb=889.6, bsz=80, num_updates=11000, lr=1.34006e-06, gnorm=2.208, clip=90, loss_scale=64, train_wall=81, gb_free=6.8, wall=143999
2022-05-21 13:23:34 - train.py[line:436] - INFO: begin validation on "valid" subset
slice_id 0 seek offset 0
slice_id 0 seek offset 0
slice_id 1 seek offset 2500
slice_id 1 seek offset 2500
2022-05-21 14:03:38 - progress_bar.py[line:282] - INFO: epoch 002 | valid on 'valid' subset | loss -0.005 | score 1.297 | ntokens 111.018 | nsentences 10 | sample_size 111.018 | cider 1.39 | wps 115.5 | wpb 111 | bsz 10 | num_updates 11000 | best_cider 1.394
2022-05-21 14:03:38 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 2 @ 11000 updates
2022-05-21 14:03:38 - trainer.py[line:431] - INFO: Saving checkpoint to /database/jhkim/stage2_checkpoints//5e-6_2/checkpoint_2_11000.pt
2022-05-21 14:03:46 - trainer.py[line:441] - INFO: Finished saving checkpoint to /database/jhkim/stage2_checkpoints//5e-6_2/checkpoint_2_11000.pt
2022-05-21 14:04:18 - checkpoint_utils.py[line:135] - INFO: Saved checkpoint /database/jhkim/stage2_checkpoints//5e-6_2/checkpoint_2_11000.pt (epoch 2 @ 11000 updates, score 1.39) (writing took 40.07438938412815 seconds)
2022-05-21 14:05:38 - progress_bar.py[line:274] - INFO: epoch 002:   3946 / 7081 loss=-0.005, score=1.513, ntokens=892, nsentences=80, sample_size=892, wps=3.5, ups=0, wpb=892, bsz=80, num_updates=11010, lr=1.33645e-06, gnorm=1.995, clip=70, loss_scale=64, train_wall=80, gb_free=6.8, wall=146523
2022-05-21 14:06:59 - progress_bar.py[line:274] - INFO: epoch 002:   3956 / 7081 loss=-0.005, score=1.505, ntokens=881.9, nsentences=80, sample_size=881.9, wps=108.6, ups=0.12, wpb=881.9, bsz=80, num_updates=11020, lr=1.33285e-06, gnorm=2.09, clip=80, loss_scale=64, train_wall=81, gb_free=6.8, wall=146604
2022-05-21 14:08:21 - progress_bar.py[line:274] - INFO: epoch 002:   3966 / 7081 loss=-0.007, score=1.404, ntokens=898.2, nsentences=80, sample_size=898.2, wps=109.8, ups=0.12, wpb=898.2, bsz=80, num_updates=11030, lr=1.32924e-06, gnorm=2.289, clip=100, loss_scale=64, train_wall=82, gb_free=6.8, wall=146686
2022-05-21 14:09:41 - progress_bar.py[line:274] - INFO: epoch 002:   3976 / 7081 loss=-0.004, score=1.547, ntokens=872.2, nsentences=80, sample_size=872.2, wps=108.8, ups=0.12, wpb=872.2, bsz=80, num_updates=11040, lr=1.32564e-06, gnorm=1.831, clip=80, loss_scale=64, train_wall=80, gb_free=6.8, wall=146766
2022-05-21 14:11:02 - progress_bar.py[line:274] - INFO: epoch 002:   3986 / 7081 loss=-0.007, score=1.515, ntokens=891.5, nsentences=80, sample_size=891.5, wps=110.4, ups=0.12, wpb=891.5, bsz=80, num_updates=11050, lr=1.32203e-06, gnorm=1.687, clip=80, loss_scale=64, train_wall=81, gb_free=6.8, wall=146847
2022-05-21 14:12:24 - progress_bar.py[line:274] - INFO: epoch 002:   3996 / 7081 loss=-0.004, score=1.494, ntokens=890.9, nsentences=80, sample_size=890.9, wps=109.3, ups=0.12, wpb=890.9, bsz=80, num_updates=11060, lr=1.31843e-06, gnorm=1.729, clip=90, loss_scale=64, train_wall=81, gb_free=6.8, wall=146928
2022-05-21 14:13:45 - progress_bar.py[line:274] - INFO: epoch 002:   4006 / 7081 loss=-0.005, score=1.472, ntokens=894.5, nsentences=80, sample_size=894.5, wps=110.4, ups=0.12, wpb=894.5, bsz=80, num_updates=11070, lr=1.31482e-06, gnorm=1.559, clip=90, loss_scale=64, train_wall=81, gb_free=6.8, wall=147009
2022-05-21 14:15:05 - progress_bar.py[line:274] - INFO: epoch 002:   4016 / 7081 loss=-0.006, score=1.459, ntokens=896.9, nsentences=80, sample_size=896.9, wps=111.2, ups=0.12, wpb=896.9, bsz=80, num_updates=11080, lr=1.31121e-06, gnorm=1.779, clip=80, loss_scale=64, train_wall=81, gb_free=6.8, wall=147090
2022-05-21 14:16:26 - progress_bar.py[line:274] - INFO: epoch 002:   4026 / 7081 loss=-0.005, score=1.375, ntokens=869.6, nsentences=80, sample_size=869.6, wps=108.1, ups=0.12, wpb=869.6, bsz=80, num_updates=11090, lr=1.30761e-06, gnorm=1.86, clip=70, loss_scale=64, train_wall=80, gb_free=6.8, wall=147170
2022-05-21 14:17:46 - progress_bar.py[line:274] - INFO: epoch 002:   4036 / 7081 loss=-0.006, score=1.397, ntokens=875.1, nsentences=80, sample_size=875.1, wps=108.6, ups=0.12, wpb=875.1, bsz=80, num_updates=11100, lr=1.304e-06, gnorm=1.643, clip=90, loss_scale=64, train_wall=81, gb_free=6.8, wall=147251
2022-05-21 14:19:07 - progress_bar.py[line:274] - INFO: epoch 002:   4046 / 7081 loss=-0.007, score=1.441, ntokens=877.8, nsentences=80, sample_size=877.8, wps=108.6, ups=0.12, wpb=877.8, bsz=80, num_updates=11110, lr=1.3004e-06, gnorm=2.121, clip=80, loss_scale=128, train_wall=81, gb_free=6.8, wall=147332
2022-05-21 14:20:28 - progress_bar.py[line:274] - INFO: epoch 002:   4056 / 7081 loss=-0.006, score=1.496, ntokens=892.4, nsentences=80, sample_size=892.4, wps=110.6, ups=0.12, wpb=892.4, bsz=80, num_updates=11120, lr=1.29679e-06, gnorm=1.977, clip=90, loss_scale=128, train_wall=81, gb_free=6.8, wall=147412
2022-05-21 14:21:49 - progress_bar.py[line:274] - INFO: epoch 002:   4066 / 7081 loss=-0.004, score=1.474, ntokens=887.1, nsentences=80, sample_size=887.1, wps=109.6, ups=0.12, wpb=887.1, bsz=80, num_updates=11130, lr=1.29319e-06, gnorm=1.474, clip=80, loss_scale=128, train_wall=81, gb_free=6.8, wall=147493
2022-05-21 14:23:10 - progress_bar.py[line:274] - INFO: epoch 002:   4076 / 7081 loss=-0.006, score=1.558, ntokens=891, nsentences=80, sample_size=891, wps=109.3, ups=0.12, wpb=891, bsz=80, num_updates=11140, lr=1.28958e-06, gnorm=1.769, clip=90, loss_scale=128, train_wall=81, gb_free=6.8, wall=147575
2022-05-21 14:24:31 - progress_bar.py[line:274] - INFO: epoch 002:   4086 / 7081 loss=-0.006, score=1.45, ntokens=878.4, nsentences=80, sample_size=878.4, wps=108.5, ups=0.12, wpb=878.4, bsz=80, num_updates=11150, lr=1.28598e-06, gnorm=1.974, clip=100, loss_scale=128, train_wall=81, gb_free=6.8, wall=147656
2022-05-21 14:25:52 - progress_bar.py[line:274] - INFO: epoch 002:   4096 / 7081 loss=-0.003, score=1.431, ntokens=877.9, nsentences=80, sample_size=877.9, wps=108.3, ups=0.12, wpb=877.9, bsz=80, num_updates=11160, lr=1.28237e-06, gnorm=1.373, clip=70, loss_scale=128, train_wall=81, gb_free=6.8, wall=147737
2022-05-21 14:27:14 - progress_bar.py[line:274] - INFO: epoch 002:   4106 / 7081 loss=-0.005, score=1.44, ntokens=879.5, nsentences=80, sample_size=879.5, wps=108, ups=0.12, wpb=879.5, bsz=80, num_updates=11170, lr=1.27877e-06, gnorm=1.662, clip=80, loss_scale=128, train_wall=81, gb_free=6.8, wall=147818
2022-05-21 14:28:31 - progress_bar.py[line:274] - INFO: epoch 002:   4116 / 7081 loss=-0.008, score=1.513, ntokens=877.4, nsentences=80, sample_size=877.4, wps=114.1, ups=0.13, wpb=877.4, bsz=80, num_updates=11180, lr=1.27516e-06, gnorm=2.548, clip=100, loss_scale=128, train_wall=77, gb_free=6.8, wall=147895
2022-05-21 14:29:47 - progress_bar.py[line:274] - INFO: epoch 002:   4126 / 7081 loss=-0.007, score=1.37, ntokens=880.5, nsentences=80, sample_size=880.5, wps=115.5, ups=0.13, wpb=880.5, bsz=80, num_updates=11190, lr=1.27155e-06, gnorm=1.53, clip=70, loss_scale=128, train_wall=76, gb_free=6.8, wall=147972
2022-05-21 14:31:06 - progress_bar.py[line:274] - INFO: epoch 002:   4136 / 7081 loss=-0.009, score=1.512, ntokens=882.5, nsentences=80, sample_size=882.5, wps=111.2, ups=0.13, wpb=882.5, bsz=80, num_updates=11200, lr=1.26795e-06, gnorm=1.919, clip=100, loss_scale=128, train_wall=79, gb_free=6.8, wall=148051
2022-05-21 14:32:27 - progress_bar.py[line:274] - INFO: epoch 002:   4146 / 7081 loss=-0.004, score=1.507, ntokens=874.1, nsentences=80, sample_size=874.1, wps=107.8, ups=0.12, wpb=874.1, bsz=80, num_updates=11210, lr=1.26434e-06, gnorm=1.631, clip=50, loss_scale=128, train_wall=81, gb_free=6.8, wall=148132
2022-05-21 14:33:48 - progress_bar.py[line:274] - INFO: epoch 002:   4156 / 7081 loss=-0.004, score=1.368, ntokens=896.1, nsentences=80, sample_size=896.1, wps=110.6, ups=0.12, wpb=896.1, bsz=80, num_updates=11220, lr=1.26074e-06, gnorm=1.278, clip=50, loss_scale=128, train_wall=81, gb_free=6.8, wall=148213
2022-05-21 14:35:09 - progress_bar.py[line:274] - INFO: epoch 002:   4166 / 7081 loss=-0.009, score=1.548, ntokens=880.3, nsentences=80, sample_size=880.3, wps=108.6, ups=0.12, wpb=880.3, bsz=80, num_updates=11230, lr=1.25713e-06, gnorm=1.763, clip=90, loss_scale=128, train_wall=81, gb_free=6.8, wall=148294
2022-05-21 14:36:31 - progress_bar.py[line:274] - INFO: epoch 002:   4176 / 7081 loss=-0.01, score=1.49, ntokens=902.1, nsentences=80, sample_size=902.1, wps=110.8, ups=0.12, wpb=902.1, bsz=80, num_updates=11240, lr=1.25353e-06, gnorm=1.603, clip=80, loss_scale=128, train_wall=81, gb_free=6.8, wall=148376
2022-05-21 14:37:52 - progress_bar.py[line:274] - INFO: epoch 002:   4186 / 7081 loss=-0.005, score=1.489, ntokens=884.1, nsentences=80, sample_size=884.1, wps=109.3, ups=0.12, wpb=884.1, bsz=80, num_updates=11250, lr=1.24992e-06, gnorm=1.41, clip=80, loss_scale=128, train_wall=81, gb_free=6.7, wall=148456
2022-05-21 14:39:13 - progress_bar.py[line:274] - INFO: epoch 002:   4196 / 7081 loss=-0.007, score=1.5, ntokens=893.3, nsentences=80, sample_size=893.3, wps=110.2, ups=0.12, wpb=893.3, bsz=80, num_updates=11260, lr=1.24632e-06, gnorm=1.811, clip=100, loss_scale=128, train_wall=81, gb_free=6.8, wall=148538
2022-05-21 14:40:34 - progress_bar.py[line:274] - INFO: epoch 002:   4206 / 7081 loss=-0.003, score=1.389, ntokens=890.6, nsentences=80, sample_size=890.6, wps=109.6, ups=0.12, wpb=890.6, bsz=80, num_updates=11270, lr=1.24271e-06, gnorm=1.739, clip=80, loss_scale=128, train_wall=81, gb_free=6.8, wall=148619
2022-05-21 14:41:55 - progress_bar.py[line:274] - INFO: epoch 002:   4216 / 7081 loss=-0.007, score=1.481, ntokens=882.6, nsentences=80, sample_size=882.6, wps=108.9, ups=0.12, wpb=882.6, bsz=80, num_updates=11280, lr=1.2391e-06, gnorm=1.52, clip=80, loss_scale=128, train_wall=81, gb_free=6.8, wall=148700
2022-05-21 14:43:16 - progress_bar.py[line:274] - INFO: epoch 002:   4226 / 7081 loss=-0.011, score=1.48, ntokens=897.6, nsentences=80, sample_size=897.6, wps=110.6, ups=0.12, wpb=897.6, bsz=80, num_updates=11290, lr=1.2355e-06, gnorm=1.519, clip=90, loss_scale=128, train_wall=81, gb_free=6.8, wall=148781
2022-05-21 14:44:37 - progress_bar.py[line:274] - INFO: epoch 002:   4236 / 7081 loss=-0.007, score=1.427, ntokens=882.9, nsentences=80, sample_size=882.9, wps=108.8, ups=0.12, wpb=882.9, bsz=80, num_updates=11300, lr=1.23189e-06, gnorm=1.946, clip=100, loss_scale=128, train_wall=81, gb_free=6.8, wall=148862
2022-05-21 14:45:58 - progress_bar.py[line:274] - INFO: epoch 002:   4246 / 7081 loss=-0.005, score=1.523, ntokens=890.5, nsentences=80, sample_size=890.5, wps=110.3, ups=0.12, wpb=890.5, bsz=80, num_updates=11310, lr=1.22829e-06, gnorm=1.626, clip=90, loss_scale=128, train_wall=81, gb_free=6.8, wall=148943
2022-05-21 14:47:19 - progress_bar.py[line:274] - INFO: epoch 002:   4256 / 7081 loss=-0.009, score=1.456, ntokens=883.7, nsentences=80, sample_size=883.7, wps=109.5, ups=0.12, wpb=883.7, bsz=80, num_updates=11320, lr=1.22468e-06, gnorm=1.697, clip=70, loss_scale=128, train_wall=81, gb_free=6.8, wall=149023
2022-05-21 14:48:40 - progress_bar.py[line:274] - INFO: epoch 002:   4266 / 7081 loss=-0.007, score=1.527, ntokens=887.3, nsentences=80, sample_size=887.3, wps=108.9, ups=0.12, wpb=887.3, bsz=80, num_updates=11330, lr=1.22108e-06, gnorm=1.934, clip=90, loss_scale=128, train_wall=81, gb_free=6.8, wall=149105
2022-05-21 14:50:02 - progress_bar.py[line:274] - INFO: epoch 002:   4276 / 7081 loss=-0.005, score=1.475, ntokens=898.5, nsentences=80, sample_size=898.5, wps=110.6, ups=0.12, wpb=898.5, bsz=80, num_updates=11340, lr=1.21747e-06, gnorm=1.555, clip=80, loss_scale=128, train_wall=81, gb_free=6.8, wall=149186
2022-05-21 14:51:23 - progress_bar.py[line:274] - INFO: epoch 002:   4286 / 7081 loss=-0.009, score=1.527, ntokens=892.8, nsentences=80, sample_size=892.8, wps=109.1, ups=0.12, wpb=892.8, bsz=80, num_updates=11350, lr=1.21387e-06, gnorm=2.312, clip=100, loss_scale=128, train_wall=82, gb_free=6.8, wall=149268
2022-05-21 14:52:44 - progress_bar.py[line:274] - INFO: epoch 002:   4296 / 7081 loss=-0.007, score=1.409, ntokens=887.5, nsentences=80, sample_size=887.5, wps=109.9, ups=0.12, wpb=887.5, bsz=80, num_updates=11360, lr=1.21026e-06, gnorm=1.307, clip=60, loss_scale=128, train_wall=81, gb_free=6.8, wall=149349
2022-05-21 14:53:33 - trainer.py[line:922] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-05-21 14:54:12 - progress_bar.py[line:274] - INFO: epoch 002:   4307 / 7081 loss=-0.007, score=1.524, ntokens=884.6, nsentences=80, sample_size=884.6, wps=100.7, ups=0.11, wpb=884.6, bsz=80, num_updates=11370, lr=1.20666e-06, gnorm=1.754, clip=100, loss_scale=64, train_wall=88, gb_free=6.8, wall=149437
2022-05-21 14:55:29 - progress_bar.py[line:274] - INFO: epoch 002:   4317 / 7081 loss=-0.005, score=1.358, ntokens=888.5, nsentences=80, sample_size=888.5, wps=115.6, ups=0.13, wpb=888.5, bsz=80, num_updates=11380, lr=1.20305e-06, gnorm=1.677, clip=70, loss_scale=64, train_wall=77, gb_free=6.8, wall=149514
2022-05-21 14:56:46 - progress_bar.py[line:274] - INFO: epoch 002:   4327 / 7081 loss=-0.006, score=1.434, ntokens=897.7, nsentences=80, sample_size=897.7, wps=115.8, ups=0.13, wpb=897.7, bsz=80, num_updates=11390, lr=1.19944e-06, gnorm=1.819, clip=80, loss_scale=64, train_wall=77, gb_free=6.8, wall=149591
2022-05-21 14:58:08 - progress_bar.py[line:274] - INFO: epoch 002:   4337 / 7081 loss=-0.006, score=1.513, ntokens=891.8, nsentences=80, sample_size=891.8, wps=109.2, ups=0.12, wpb=891.8, bsz=80, num_updates=11400, lr=1.19584e-06, gnorm=1.458, clip=80, loss_scale=64, train_wall=82, gb_free=6.8, wall=149673
2022-05-21 14:59:30 - progress_bar.py[line:274] - INFO: epoch 002:   4347 / 7081 loss=-0.004, score=1.514, ntokens=885.8, nsentences=80, sample_size=885.8, wps=108.7, ups=0.12, wpb=885.8, bsz=80, num_updates=11410, lr=1.19223e-06, gnorm=1.58, clip=70, loss_scale=64, train_wall=81, gb_free=6.8, wall=149754
2022-05-21 15:00:51 - progress_bar.py[line:274] - INFO: epoch 002:   4357 / 7081 loss=-0.007, score=1.407, ntokens=881.7, nsentences=80, sample_size=881.7, wps=108.7, ups=0.12, wpb=881.7, bsz=80, num_updates=11420, lr=1.18863e-06, gnorm=1.644, clip=70, loss_scale=64, train_wall=81, gb_free=6.8, wall=149835
2022-05-21 15:02:12 - progress_bar.py[line:274] - INFO: epoch 002:   4367 / 7081 loss=-0.008, score=1.517, ntokens=885.1, nsentences=80, sample_size=885.1, wps=109.3, ups=0.12, wpb=885.1, bsz=80, num_updates=11430, lr=1.18502e-06, gnorm=1.531, clip=80, loss_scale=64, train_wall=81, gb_free=6.8, wall=149916
2022-05-21 15:03:33 - progress_bar.py[line:274] - INFO: epoch 002:   4377 / 7081 loss=-0.007, score=1.417, ntokens=888.9, nsentences=80, sample_size=888.9, wps=109.7, ups=0.12, wpb=888.9, bsz=80, num_updates=11440, lr=1.18142e-06, gnorm=2.108, clip=80, loss_scale=64, train_wall=81, gb_free=6.8, wall=149997
2022-05-21 15:04:54 - progress_bar.py[line:274] - INFO: epoch 002:   4387 / 7081 loss=-0.008, score=1.485, ntokens=891.9, nsentences=80, sample_size=891.9, wps=110.4, ups=0.12, wpb=891.9, bsz=80, num_updates=11450, lr=1.17781e-06, gnorm=1.758, clip=80, loss_scale=64, train_wall=81, gb_free=6.7, wall=150078
2022-05-21 15:06:15 - progress_bar.py[line:274] - INFO: epoch 002:   4397 / 7081 loss=-0.006, score=1.395, ntokens=895, nsentences=80, sample_size=895, wps=110, ups=0.12, wpb=895, bsz=80, num_updates=11460, lr=1.17421e-06, gnorm=1.605, clip=80, loss_scale=64, train_wall=81, gb_free=6.8, wall=150160
2022-05-21 15:07:36 - progress_bar.py[line:274] - INFO: epoch 002:   4407 / 7081 loss=-0.003, score=1.446, ntokens=894.2, nsentences=80, sample_size=894.2, wps=110.6, ups=0.12, wpb=894.2, bsz=80, num_updates=11470, lr=1.1706e-06, gnorm=1.473, clip=50, loss_scale=64, train_wall=81, gb_free=6.8, wall=150240
2022-05-21 15:08:57 - progress_bar.py[line:274] - INFO: epoch 002:   4417 / 7081 loss=-0.006, score=1.522, ntokens=878.4, nsentences=80, sample_size=878.4, wps=108, ups=0.12, wpb=878.4, bsz=80, num_updates=11480, lr=1.16699e-06, gnorm=1.595, clip=100, loss_scale=64, train_wall=81, gb_free=6.8, wall=150322
2022-05-21 15:10:19 - progress_bar.py[line:274] - INFO: epoch 002:   4427 / 7081 loss=-0.007, score=1.415, ntokens=884, nsentences=80, sample_size=884, wps=108.1, ups=0.12, wpb=884, bsz=80, num_updates=11490, lr=1.16339e-06, gnorm=1.603, clip=70, loss_scale=64, train_wall=82, gb_free=6.8, wall=150404
2022-05-21 15:11:40 - progress_bar.py[line:274] - INFO: epoch 002:   4437 / 7081 loss=-0.005, score=1.354, ntokens=880.3, nsentences=80, sample_size=880.3, wps=108.8, ups=0.12, wpb=880.3, bsz=80, num_updates=11500, lr=1.15978e-06, gnorm=1.73, clip=80, loss_scale=64, train_wall=81, gb_free=6.8, wall=150484
2022-05-21 15:11:40 - train.py[line:436] - INFO: begin validation on "valid" subset
slice_id 0 seek offset 0
slice_id 1 seek offset 2500
slice_id 0 seek offset 0
slice_id 1 seek offset 2500
2022-05-21 15:51:31 - progress_bar.py[line:282] - INFO: epoch 002 | valid on 'valid' subset | loss -0.005 | score 1.297 | ntokens 110.956 | nsentences 10 | sample_size 110.956 | cider 1.39 | wps 116 | wpb 111 | bsz 10 | num_updates 11500 | best_cider 1.394
2022-05-21 15:51:31 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 2 @ 11500 updates
2022-05-21 15:51:31 - trainer.py[line:431] - INFO: Saving checkpoint to /database/jhkim/stage2_checkpoints//5e-6_2/checkpoint_2_11500.pt
2022-05-21 15:51:39 - trainer.py[line:441] - INFO: Finished saving checkpoint to /database/jhkim/stage2_checkpoints//5e-6_2/checkpoint_2_11500.pt
2022-05-21 15:52:12 - checkpoint_utils.py[line:135] - INFO: Saved checkpoint /database/jhkim/stage2_checkpoints//5e-6_2/checkpoint_2_11500.pt (epoch 2 @ 11500 updates, score 1.39) (writing took 40.9914041897282 seconds)
2022-05-21 15:53:33 - progress_bar.py[line:274] - INFO: epoch 002:   4447 / 7081 loss=-0.007, score=1.413, ntokens=892, nsentences=80, sample_size=892, wps=3.5, ups=0, wpb=892, bsz=80, num_updates=11510, lr=1.15618e-06, gnorm=1.725, clip=100, loss_scale=64, train_wall=80, gb_free=6.8, wall=152997
2022-05-21 15:54:53 - progress_bar.py[line:274] - INFO: epoch 002:   4457 / 7081 loss=-0.005, score=1.458, ntokens=881.4, nsentences=80, sample_size=881.4, wps=110.1, ups=0.12, wpb=881.4, bsz=80, num_updates=11520, lr=1.15257e-06, gnorm=1.831, clip=100, loss_scale=64, train_wall=80, gb_free=6.8, wall=153077
2022-05-21 15:56:14 - progress_bar.py[line:274] - INFO: epoch 002:   4467 / 7081 loss=-0.002, score=1.396, ntokens=898.8, nsentences=80, sample_size=898.8, wps=110.5, ups=0.12, wpb=898.8, bsz=80, num_updates=11530, lr=1.14897e-06, gnorm=1.549, clip=70, loss_scale=64, train_wall=81, gb_free=6.8, wall=153159
2022-05-21 15:57:35 - progress_bar.py[line:274] - INFO: epoch 002:   4477 / 7081 loss=-0.008, score=1.49, ntokens=883.5, nsentences=80, sample_size=883.5, wps=109.1, ups=0.12, wpb=883.5, bsz=80, num_updates=11540, lr=1.14536e-06, gnorm=1.72, clip=90, loss_scale=64, train_wall=81, gb_free=6.8, wall=153240
2022-05-21 15:58:57 - progress_bar.py[line:274] - INFO: epoch 002:   4487 / 7081 loss=-0.009, score=1.43, ntokens=892, nsentences=80, sample_size=892, wps=109.2, ups=0.12, wpb=892, bsz=80, num_updates=11550, lr=1.14176e-06, gnorm=2.333, clip=100, loss_scale=64, train_wall=82, gb_free=6.8, wall=153321
2022-05-21 16:00:18 - progress_bar.py[line:274] - INFO: epoch 002:   4497 / 7081 loss=-0.006, score=1.369, ntokens=889.9, nsentences=80, sample_size=889.9, wps=109, ups=0.12, wpb=889.9, bsz=80, num_updates=11560, lr=1.13815e-06, gnorm=1.361, clip=80, loss_scale=64, train_wall=82, gb_free=6.8, wall=153403
2022-05-21 16:01:39 - progress_bar.py[line:274] - INFO: epoch 002:   4507 / 7081 loss=-0.008, score=1.431, ntokens=882.6, nsentences=80, sample_size=882.6, wps=109.1, ups=0.12, wpb=882.6, bsz=80, num_updates=11570, lr=1.13455e-06, gnorm=1.587, clip=90, loss_scale=64, train_wall=81, gb_free=6.8, wall=153484
2022-05-21 16:03:00 - progress_bar.py[line:274] - INFO: epoch 002:   4517 / 7081 loss=-0.009, score=1.494, ntokens=893.5, nsentences=80, sample_size=893.5, wps=110.2, ups=0.12, wpb=893.5, bsz=80, num_updates=11580, lr=1.13094e-06, gnorm=1.251, clip=60, loss_scale=64, train_wall=81, gb_free=6.8, wall=153565
2022-05-21 16:04:21 - progress_bar.py[line:274] - INFO: epoch 002:   4527 / 7081 loss=-0.01, score=1.449, ntokens=878.5, nsentences=80, sample_size=878.5, wps=109.2, ups=0.12, wpb=878.5, bsz=80, num_updates=11590, lr=1.12733e-06, gnorm=1.616, clip=90, loss_scale=64, train_wall=80, gb_free=6.8, wall=153645
2022-05-21 16:05:41 - progress_bar.py[line:274] - INFO: epoch 002:   4537 / 7081 loss=-0.002, score=1.463, ntokens=882.7, nsentences=80, sample_size=882.7, wps=109.8, ups=0.12, wpb=882.7, bsz=80, num_updates=11600, lr=1.12373e-06, gnorm=1.816, clip=90, loss_scale=64, train_wall=80, gb_free=6.8, wall=153726
2022-05-21 16:07:02 - progress_bar.py[line:274] - INFO: epoch 002:   4547 / 7081 loss=-0.004, score=1.343, ntokens=875.8, nsentences=80, sample_size=875.8, wps=108.3, ups=0.12, wpb=875.8, bsz=80, num_updates=11610, lr=1.12012e-06, gnorm=1.525, clip=70, loss_scale=64, train_wall=81, gb_free=6.8, wall=153807
2022-05-21 16:08:23 - progress_bar.py[line:274] - INFO: epoch 002:   4557 / 7081 loss=-0.003, score=1.427, ntokens=894, nsentences=80, sample_size=894, wps=110.4, ups=0.12, wpb=894, bsz=80, num_updates=11620, lr=1.11652e-06, gnorm=1.361, clip=70, loss_scale=64, train_wall=81, gb_free=6.8, wall=153888
2022-05-21 16:09:43 - progress_bar.py[line:274] - INFO: epoch 002:   4567 / 7081 loss=-0.005, score=1.413, ntokens=891.6, nsentences=80, sample_size=891.6, wps=111.1, ups=0.12, wpb=891.6, bsz=80, num_updates=11630, lr=1.11291e-06, gnorm=1.415, clip=90, loss_scale=64, train_wall=80, gb_free=6.8, wall=153968
2022-05-21 16:11:04 - progress_bar.py[line:274] - INFO: epoch 002:   4577 / 7081 loss=-0.007, score=1.607, ntokens=876.9, nsentences=80, sample_size=876.9, wps=108.7, ups=0.12, wpb=876.9, bsz=80, num_updates=11640, lr=1.10931e-06, gnorm=1.386, clip=70, loss_scale=64, train_wall=81, gb_free=6.8, wall=154049
2022-05-21 16:12:23 - progress_bar.py[line:274] - INFO: epoch 002:   4587 / 7081 loss=-0.008, score=1.512, ntokens=891.9, nsentences=80, sample_size=891.9, wps=112.5, ups=0.13, wpb=891.9, bsz=80, num_updates=11650, lr=1.1057e-06, gnorm=1.211, clip=80, loss_scale=64, train_wall=79, gb_free=6.8, wall=154128
2022-05-21 16:13:40 - progress_bar.py[line:274] - INFO: epoch 002:   4597 / 7081 loss=-0.004, score=1.326, ntokens=890.8, nsentences=80, sample_size=890.8, wps=116, ups=0.13, wpb=890.8, bsz=80, num_updates=11660, lr=1.1021e-06, gnorm=1.439, clip=100, loss_scale=64, train_wall=77, gb_free=6.8, wall=154205
2022-05-21 16:14:58 - progress_bar.py[line:274] - INFO: epoch 002:   4607 / 7081 loss=-0.004, score=1.433, ntokens=897.1, nsentences=80, sample_size=897.1, wps=114.4, ups=0.13, wpb=897.1, bsz=80, num_updates=11670, lr=1.09849e-06, gnorm=2.025, clip=70, loss_scale=64, train_wall=78, gb_free=6.8, wall=154283
2022-05-21 16:16:20 - progress_bar.py[line:274] - INFO: epoch 002:   4617 / 7081 loss=-0.009, score=1.385, ntokens=888.2, nsentences=80, sample_size=888.2, wps=109.3, ups=0.12, wpb=888.2, bsz=80, num_updates=11680, lr=1.09488e-06, gnorm=1.875, clip=70, loss_scale=64, train_wall=81, gb_free=6.8, wall=154364
2022-05-21 16:17:42 - progress_bar.py[line:274] - INFO: epoch 002:   4627 / 7081 loss=-0.007, score=1.523, ntokens=887.1, nsentences=80, sample_size=887.1, wps=108.1, ups=0.12, wpb=887.1, bsz=80, num_updates=11690, lr=1.09128e-06, gnorm=1.475, clip=90, loss_scale=64, train_wall=82, gb_free=6.8, wall=154446
2022-05-21 16:19:03 - progress_bar.py[line:274] - INFO: epoch 002:   4637 / 7081 loss=-0.008, score=1.433, ntokens=895.5, nsentences=80, sample_size=895.5, wps=109.8, ups=0.12, wpb=895.5, bsz=80, num_updates=11700, lr=1.08767e-06, gnorm=1.557, clip=90, loss_scale=64, train_wall=81, gb_free=6.8, wall=154528
2022-05-21 16:20:24 - progress_bar.py[line:274] - INFO: epoch 002:   4647 / 7081 loss=-0.003, score=1.349, ntokens=888.4, nsentences=80, sample_size=888.4, wps=109.6, ups=0.12, wpb=888.4, bsz=80, num_updates=11710, lr=1.08407e-06, gnorm=1.903, clip=90, loss_scale=64, train_wall=81, gb_free=6.8, wall=154609
2022-05-21 16:21:45 - progress_bar.py[line:274] - INFO: epoch 002:   4657 / 7081 loss=-0.008, score=1.537, ntokens=884.3, nsentences=80, sample_size=884.3, wps=109.5, ups=0.12, wpb=884.3, bsz=80, num_updates=11720, lr=1.08046e-06, gnorm=1.843, clip=80, loss_scale=64, train_wall=81, gb_free=6.8, wall=154690
2022-05-21 16:23:06 - progress_bar.py[line:274] - INFO: epoch 002:   4667 / 7081 loss=-0.005, score=1.504, ntokens=889.4, nsentences=80, sample_size=889.4, wps=110.6, ups=0.12, wpb=889.4, bsz=80, num_updates=11730, lr=1.07686e-06, gnorm=1.841, clip=90, loss_scale=64, train_wall=80, gb_free=6.8, wall=154770
2022-05-21 16:24:27 - progress_bar.py[line:274] - INFO: epoch 002:   4677 / 7081 loss=-0.007, score=1.474, ntokens=877.7, nsentences=80, sample_size=877.7, wps=107.9, ups=0.12, wpb=877.7, bsz=80, num_updates=11740, lr=1.07325e-06, gnorm=1.377, clip=70, loss_scale=64, train_wall=81, gb_free=6.8, wall=154852
2022-05-21 16:25:48 - progress_bar.py[line:274] - INFO: epoch 002:   4687 / 7081 loss=-0.007, score=1.39, ntokens=894.1, nsentences=80, sample_size=894.1, wps=109.8, ups=0.12, wpb=894.1, bsz=80, num_updates=11750, lr=1.06965e-06, gnorm=1.707, clip=90, loss_scale=64, train_wall=81, gb_free=6.8, wall=154933
2022-05-21 16:27:09 - progress_bar.py[line:274] - INFO: epoch 002:   4697 / 7081 loss=-0.007, score=1.438, ntokens=872.7, nsentences=80, sample_size=872.7, wps=108.7, ups=0.12, wpb=872.7, bsz=80, num_updates=11760, lr=1.06604e-06, gnorm=1.614, clip=90, loss_scale=64, train_wall=80, gb_free=6.8, wall=155013
2022-05-21 16:28:30 - progress_bar.py[line:274] - INFO: epoch 002:   4707 / 7081 loss=-0.008, score=1.615, ntokens=902.9, nsentences=80, sample_size=902.9, wps=110.6, ups=0.12, wpb=902.9, bsz=80, num_updates=11770, lr=1.06244e-06, gnorm=1.322, clip=80, loss_scale=64, train_wall=82, gb_free=6.8, wall=155095
2022-05-21 16:29:51 - progress_bar.py[line:274] - INFO: epoch 002:   4717 / 7081 loss=-0.006, score=1.502, ntokens=882.9, nsentences=80, sample_size=882.9, wps=108.9, ups=0.12, wpb=882.9, bsz=80, num_updates=11780, lr=1.05883e-06, gnorm=1.586, clip=90, loss_scale=64, train_wall=81, gb_free=6.8, wall=155176
2022-05-21 16:31:13 - progress_bar.py[line:274] - INFO: epoch 002:   4727 / 7081 loss=-0.007, score=1.433, ntokens=891.9, nsentences=80, sample_size=891.9, wps=109.3, ups=0.12, wpb=891.9, bsz=80, num_updates=11790, lr=1.05522e-06, gnorm=1.911, clip=90, loss_scale=64, train_wall=82, gb_free=6.8, wall=155258
2022-05-21 16:32:34 - progress_bar.py[line:274] - INFO: epoch 002:   4737 / 7081 loss=-0.006, score=1.487, ntokens=881.3, nsentences=80, sample_size=881.3, wps=108.1, ups=0.12, wpb=881.3, bsz=80, num_updates=11800, lr=1.05162e-06, gnorm=1.519, clip=80, loss_scale=64, train_wall=81, gb_free=6.7, wall=155339
2022-05-21 16:33:56 - progress_bar.py[line:274] - INFO: epoch 002:   4747 / 7081 loss=-0.005, score=1.426, ntokens=890.3, nsentences=80, sample_size=890.3, wps=109.5, ups=0.12, wpb=890.3, bsz=80, num_updates=11810, lr=1.04801e-06, gnorm=1.461, clip=90, loss_scale=64, train_wall=81, gb_free=6.8, wall=155420
2022-05-21 16:35:17 - progress_bar.py[line:274] - INFO: epoch 002:   4757 / 7081 loss=-0.005, score=1.464, ntokens=884.8, nsentences=80, sample_size=884.8, wps=109.5, ups=0.12, wpb=884.8, bsz=80, num_updates=11820, lr=1.04441e-06, gnorm=1.213, clip=60, loss_scale=64, train_wall=81, gb_free=6.8, wall=155501
2022-05-21 16:36:38 - progress_bar.py[line:274] - INFO: epoch 002:   4767 / 7081 loss=-0.005, score=1.465, ntokens=875, nsentences=80, sample_size=875, wps=108, ups=0.12, wpb=875, bsz=80, num_updates=11830, lr=1.0408e-06, gnorm=1.62, clip=70, loss_scale=64, train_wall=81, gb_free=6.8, wall=155582
2022-05-21 16:37:58 - progress_bar.py[line:274] - INFO: epoch 002:   4777 / 7081 loss=-0.008, score=1.515, ntokens=886, nsentences=80, sample_size=886, wps=109.7, ups=0.12, wpb=886, bsz=80, num_updates=11840, lr=1.0372e-06, gnorm=1.564, clip=100, loss_scale=64, train_wall=81, gb_free=6.8, wall=155663
2022-05-21 16:39:15 - progress_bar.py[line:274] - INFO: epoch 002:   4787 / 7081 loss=-0.008, score=1.427, ntokens=871.9, nsentences=80, sample_size=871.9, wps=113.6, ups=0.13, wpb=871.9, bsz=80, num_updates=11850, lr=1.03359e-06, gnorm=1.81, clip=80, loss_scale=64, train_wall=77, gb_free=6.8, wall=155740
2022-05-21 16:40:31 - progress_bar.py[line:274] - INFO: epoch 002:   4797 / 7081 loss=-0.003, score=1.512, ntokens=878.7, nsentences=80, sample_size=878.7, wps=115.3, ups=0.13, wpb=878.7, bsz=80, num_updates=11860, lr=1.02999e-06, gnorm=2.503, clip=100, loss_scale=64, train_wall=76, gb_free=6.8, wall=155816
2022-05-21 16:41:51 - progress_bar.py[line:274] - INFO: epoch 002:   4807 / 7081 loss=-0.006, score=1.41, ntokens=879.9, nsentences=80, sample_size=879.9, wps=109.9, ups=0.12, wpb=879.9, bsz=80, num_updates=11870, lr=1.02638e-06, gnorm=1.5, clip=80, loss_scale=64, train_wall=80, gb_free=6.8, wall=155896
2022-05-21 16:43:12 - progress_bar.py[line:274] - INFO: epoch 002:   4817 / 7081 loss=-0.006, score=1.435, ntokens=878.1, nsentences=80, sample_size=878.1, wps=108.4, ups=0.12, wpb=878.1, bsz=80, num_updates=11880, lr=1.02277e-06, gnorm=1.506, clip=80, loss_scale=128, train_wall=81, gb_free=6.8, wall=155977
2022-05-21 16:44:33 - progress_bar.py[line:274] - INFO: epoch 002:   4827 / 7081 loss=-0.004, score=1.475, ntokens=889.7, nsentences=80, sample_size=889.7, wps=110.1, ups=0.12, wpb=889.7, bsz=80, num_updates=11890, lr=1.01917e-06, gnorm=1.242, clip=70, loss_scale=128, train_wall=81, gb_free=6.8, wall=156058
2022-05-21 16:45:54 - progress_bar.py[line:274] - INFO: epoch 002:   4837 / 7081 loss=-0.005, score=1.488, ntokens=883.2, nsentences=80, sample_size=883.2, wps=108.9, ups=0.12, wpb=883.2, bsz=80, num_updates=11900, lr=1.01556e-06, gnorm=1.247, clip=70, loss_scale=128, train_wall=81, gb_free=6.8, wall=156139
2022-05-21 16:47:15 - progress_bar.py[line:274] - INFO: epoch 002:   4847 / 7081 loss=-0.007, score=1.594, ntokens=886.5, nsentences=80, sample_size=886.5, wps=109.5, ups=0.12, wpb=886.5, bsz=80, num_updates=11910, lr=1.01196e-06, gnorm=1.701, clip=90, loss_scale=128, train_wall=81, gb_free=6.8, wall=156220
2022-05-21 16:48:36 - progress_bar.py[line:274] - INFO: epoch 002:   4857 / 7081 loss=-0.007, score=1.567, ntokens=891.2, nsentences=80, sample_size=891.2, wps=110, ups=0.12, wpb=891.2, bsz=80, num_updates=11920, lr=1.00835e-06, gnorm=1.842, clip=90, loss_scale=128, train_wall=81, gb_free=6.8, wall=156301
2022-05-21 16:49:57 - progress_bar.py[line:274] - INFO: epoch 002:   4867 / 7081 loss=-0.003, score=1.477, ntokens=890.3, nsentences=80, sample_size=890.3, wps=109.6, ups=0.12, wpb=890.3, bsz=80, num_updates=11930, lr=1.00475e-06, gnorm=1.714, clip=100, loss_scale=128, train_wall=81, gb_free=6.8, wall=156382
2022-05-21 16:51:18 - progress_bar.py[line:274] - INFO: epoch 002:   4877 / 7081 loss=-0.008, score=1.542, ntokens=890.6, nsentences=80, sample_size=890.6, wps=110, ups=0.12, wpb=890.6, bsz=80, num_updates=11940, lr=1.00114e-06, gnorm=1.571, clip=100, loss_scale=128, train_wall=81, gb_free=6.8, wall=156463
2022-05-21 16:52:40 - progress_bar.py[line:274] - INFO: epoch 002:   4887 / 7081 loss=-0.008, score=1.523, ntokens=890.2, nsentences=80, sample_size=890.2, wps=109.6, ups=0.12, wpb=890.2, bsz=80, num_updates=11950, lr=9.97536e-07, gnorm=1.863, clip=90, loss_scale=128, train_wall=81, gb_free=6.8, wall=156544
2022-05-21 16:54:01 - progress_bar.py[line:274] - INFO: epoch 002:   4897 / 7081 loss=-0.005, score=1.444, ntokens=893.3, nsentences=80, sample_size=893.3, wps=109.5, ups=0.12, wpb=893.3, bsz=80, num_updates=11960, lr=9.93931e-07, gnorm=1.597, clip=70, loss_scale=128, train_wall=81, gb_free=6.8, wall=156626
2022-05-21 16:55:22 - progress_bar.py[line:274] - INFO: epoch 002:   4907 / 7081 loss=-0.006, score=1.511, ntokens=878.6, nsentences=80, sample_size=878.6, wps=108, ups=0.12, wpb=878.6, bsz=80, num_updates=11970, lr=9.90325e-07, gnorm=1.443, clip=90, loss_scale=128, train_wall=81, gb_free=6.8, wall=156707
2022-05-21 16:56:43 - progress_bar.py[line:274] - INFO: epoch 002:   4917 / 7081 loss=-0.008, score=1.479, ntokens=894, nsentences=80, sample_size=894, wps=110.6, ups=0.12, wpb=894, bsz=80, num_updates=11980, lr=9.8672e-07, gnorm=1.729, clip=90, loss_scale=128, train_wall=81, gb_free=6.8, wall=156788
2022-05-21 16:58:05 - progress_bar.py[line:274] - INFO: epoch 002:   4927 / 7081 loss=-0.004, score=1.532, ntokens=898.8, nsentences=80, sample_size=898.8, wps=110.1, ups=0.12, wpb=898.8, bsz=80, num_updates=11990, lr=9.83114e-07, gnorm=1.416, clip=70, loss_scale=128, train_wall=82, gb_free=6.8, wall=156870
2022-05-21 16:59:26 - progress_bar.py[line:274] - INFO: epoch 002:   4937 / 7081 loss=-0.009, score=1.549, ntokens=880.2, nsentences=80, sample_size=880.2, wps=109.1, ups=0.12, wpb=880.2, bsz=80, num_updates=12000, lr=9.79509e-07, gnorm=1.472, clip=80, loss_scale=128, train_wall=81, gb_free=6.8, wall=156950
2022-05-21 16:59:26 - train.py[line:436] - INFO: begin validation on "valid" subset
slice_id 0 seek offset 0
slice_id 0 seek offset 0
slice_id 1 seek offset 2500
slice_id 1 seek offset 2500
2022-05-21 17:39:23 - progress_bar.py[line:282] - INFO: epoch 002 | valid on 'valid' subset | loss -0.005 | score 1.298 | ntokens 110.934 | nsentences 10 | sample_size 110.934 | cider 1.391 | wps 115.7 | wpb 110.9 | bsz 10 | num_updates 12000 | best_cider 1.394
2022-05-21 17:39:23 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 2 @ 12000 updates
2022-05-21 17:39:23 - trainer.py[line:431] - INFO: Saving checkpoint to /database/jhkim/stage2_checkpoints//5e-6_2/checkpoint_2_12000.pt
2022-05-21 17:39:32 - trainer.py[line:441] - INFO: Finished saving checkpoint to /database/jhkim/stage2_checkpoints//5e-6_2/checkpoint_2_12000.pt
2022-05-21 17:40:01 - checkpoint_utils.py[line:135] - INFO: Saved checkpoint /database/jhkim/stage2_checkpoints//5e-6_2/checkpoint_2_12000.pt (epoch 2 @ 12000 updates, score 1.391) (writing took 37.34805349400267 seconds)
2022-05-21 17:41:20 - progress_bar.py[line:274] - INFO: epoch 002:   4947 / 7081 loss=-0.005, score=1.459, ntokens=891.9, nsentences=80, sample_size=891.9, wps=3.5, ups=0, wpb=891.9, bsz=80, num_updates=12010, lr=9.75903e-07, gnorm=2.054, clip=80, loss_scale=128, train_wall=80, gb_free=6.8, wall=159465
2022-05-21 17:42:41 - progress_bar.py[line:274] - INFO: epoch 002:   4957 / 7081 loss=-0.009, score=1.489, ntokens=890.9, nsentences=80, sample_size=890.9, wps=110, ups=0.12, wpb=890.9, bsz=80, num_updates=12020, lr=9.72298e-07, gnorm=1.533, clip=90, loss_scale=128, train_wall=81, gb_free=6.8, wall=159546
2022-05-21 17:44:03 - progress_bar.py[line:274] - INFO: epoch 002:   4967 / 7081 loss=-0.006, score=1.454, ntokens=908.2, nsentences=80, sample_size=908.2, wps=111.2, ups=0.12, wpb=908.2, bsz=80, num_updates=12030, lr=9.68692e-07, gnorm=1.757, clip=80, loss_scale=128, train_wall=82, gb_free=6.8, wall=159628
2022-05-21 17:45:24 - progress_bar.py[line:274] - INFO: epoch 002:   4977 / 7081 loss=-0.005, score=1.474, ntokens=884.3, nsentences=80, sample_size=884.3, wps=109, ups=0.12, wpb=884.3, bsz=80, num_updates=12040, lr=9.65087e-07, gnorm=1.558, clip=90, loss_scale=128, train_wall=81, gb_free=6.8, wall=159709
2022-05-21 17:46:46 - progress_bar.py[line:274] - INFO: epoch 002:   4987 / 7081 loss=-0.006, score=1.473, ntokens=893.6, nsentences=80, sample_size=893.6, wps=109.5, ups=0.12, wpb=893.6, bsz=80, num_updates=12050, lr=9.61481e-07, gnorm=2.223, clip=90, loss_scale=128, train_wall=81, gb_free=6.8, wall=159790
2022-05-21 17:48:07 - progress_bar.py[line:274] - INFO: epoch 002:   4997 / 7081 loss=-0.008, score=1.504, ntokens=875.9, nsentences=80, sample_size=875.9, wps=108.2, ups=0.12, wpb=875.9, bsz=80, num_updates=12060, lr=9.57876e-07, gnorm=1.753, clip=80, loss_scale=128, train_wall=81, gb_free=6.8, wall=159871
2022-05-21 17:49:28 - progress_bar.py[line:274] - INFO: epoch 002:   5007 / 7081 loss=-0.005, score=1.424, ntokens=891.5, nsentences=80, sample_size=891.5, wps=110, ups=0.12, wpb=891.5, bsz=80, num_updates=12070, lr=9.5427e-07, gnorm=1.344, clip=80, loss_scale=128, train_wall=81, gb_free=6.8, wall=159952
2022-05-21 17:50:49 - progress_bar.py[line:274] - INFO: epoch 002:   5017 / 7081 loss=-0.006, score=1.312, ntokens=885.3, nsentences=80, sample_size=885.3, wps=108.7, ups=0.12, wpb=885.3, bsz=80, num_updates=12080, lr=9.50665e-07, gnorm=1.516, clip=80, loss_scale=128, train_wall=81, gb_free=6.8, wall=160034
2022-05-21 17:52:11 - progress_bar.py[line:274] - INFO: epoch 002:   5027 / 7081 loss=-0.008, score=1.52, ntokens=886.6, nsentences=80, sample_size=886.6, wps=108.7, ups=0.12, wpb=886.6, bsz=80, num_updates=12090, lr=9.47059e-07, gnorm=1.506, clip=100, loss_scale=128, train_wall=82, gb_free=6.8, wall=160115
2022-05-21 17:53:32 - progress_bar.py[line:274] - INFO: epoch 002:   5037 / 7081 loss=-0.003, score=1.536, ntokens=886.5, nsentences=80, sample_size=886.5, wps=109, ups=0.12, wpb=886.5, bsz=80, num_updates=12100, lr=9.43454e-07, gnorm=1.452, clip=80, loss_scale=128, train_wall=81, gb_free=6.8, wall=160197
2022-05-21 17:54:53 - progress_bar.py[line:274] - INFO: epoch 002:   5047 / 7081 loss=-0.003, score=1.425, ntokens=881.2, nsentences=80, sample_size=881.2, wps=108.7, ups=0.12, wpb=881.2, bsz=80, num_updates=12110, lr=9.39848e-07, gnorm=1.865, clip=90, loss_scale=128, train_wall=81, gb_free=6.8, wall=160278
2022-05-21 17:55:58 - trainer.py[line:922] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-05-21 17:56:22 - progress_bar.py[line:274] - INFO: epoch 002:   5058 / 7081 loss=-0.01, score=1.524, ntokens=899.4, nsentences=80, sample_size=899.4, wps=101.9, ups=0.11, wpb=899.4, bsz=80, num_updates=12120, lr=9.36243e-07, gnorm=1.642, clip=90, loss_scale=64, train_wall=88, gb_free=6.8, wall=160366
2022-05-21 17:57:37 - progress_bar.py[line:274] - INFO: epoch 002:   5068 / 7081 loss=-0.007, score=1.475, ntokens=874.5, nsentences=80, sample_size=874.5, wps=115.2, ups=0.13, wpb=874.5, bsz=80, num_updates=12130, lr=9.32637e-07, gnorm=1.596, clip=100, loss_scale=64, train_wall=76, gb_free=6.8, wall=160442
2022-05-21 17:58:54 - progress_bar.py[line:274] - INFO: epoch 002:   5078 / 7081 loss=-0.008, score=1.553, ntokens=881.9, nsentences=80, sample_size=881.9, wps=115.1, ups=0.13, wpb=881.9, bsz=80, num_updates=12140, lr=9.29032e-07, gnorm=1.714, clip=70, loss_scale=64, train_wall=77, gb_free=6.8, wall=160519
2022-05-21 18:00:15 - progress_bar.py[line:274] - INFO: epoch 002:   5088 / 7081 loss=-0.003, score=1.328, ntokens=896.9, nsentences=80, sample_size=896.9, wps=110.4, ups=0.12, wpb=896.9, bsz=80, num_updates=12150, lr=9.25426e-07, gnorm=1.595, clip=60, loss_scale=64, train_wall=81, gb_free=6.8, wall=160600
2022-05-21 18:01:36 - progress_bar.py[line:274] - INFO: epoch 002:   5098 / 7081 loss=-0.003, score=1.358, ntokens=878.9, nsentences=80, sample_size=878.9, wps=109.2, ups=0.12, wpb=878.9, bsz=80, num_updates=12160, lr=9.21821e-07, gnorm=1.636, clip=100, loss_scale=64, train_wall=80, gb_free=6.8, wall=160681
2022-05-21 18:02:57 - progress_bar.py[line:274] - INFO: epoch 002:   5108 / 7081 loss=-0.007, score=1.451, ntokens=884.2, nsentences=80, sample_size=884.2, wps=108.7, ups=0.12, wpb=884.2, bsz=80, num_updates=12170, lr=9.18215e-07, gnorm=1.594, clip=100, loss_scale=64, train_wall=81, gb_free=6.8, wall=160762
2022-05-21 18:04:18 - progress_bar.py[line:274] - INFO: epoch 002:   5118 / 7081 loss=-0.005, score=1.43, ntokens=889.7, nsentences=80, sample_size=889.7, wps=109.9, ups=0.12, wpb=889.7, bsz=80, num_updates=12180, lr=9.1461e-07, gnorm=2.136, clip=90, loss_scale=64, train_wall=81, gb_free=6.8, wall=160843
2022-05-21 18:05:40 - progress_bar.py[line:274] - INFO: epoch 002:   5128 / 7081 loss=-0.007, score=1.574, ntokens=899.4, nsentences=80, sample_size=899.4, wps=110.4, ups=0.12, wpb=899.4, bsz=80, num_updates=12190, lr=9.11004e-07, gnorm=1.491, clip=100, loss_scale=64, train_wall=81, gb_free=6.8, wall=160924
2022-05-21 18:07:01 - progress_bar.py[line:274] - INFO: epoch 002:   5138 / 7081 loss=-0.004, score=1.485, ntokens=882.7, nsentences=80, sample_size=882.7, wps=109, ups=0.12, wpb=882.7, bsz=80, num_updates=12200, lr=9.07399e-07, gnorm=1.494, clip=80, loss_scale=64, train_wall=81, gb_free=6.8, wall=161005
2022-05-21 18:08:22 - progress_bar.py[line:274] - INFO: epoch 002:   5148 / 7081 loss=-0.007, score=1.463, ntokens=887.4, nsentences=80, sample_size=887.4, wps=109, ups=0.12, wpb=887.4, bsz=80, num_updates=12210, lr=9.03793e-07, gnorm=1.686, clip=90, loss_scale=64, train_wall=81, gb_free=6.8, wall=161087
2022-05-21 18:09:43 - progress_bar.py[line:274] - INFO: epoch 002:   5158 / 7081 loss=-0.006, score=1.359, ntokens=884.7, nsentences=80, sample_size=884.7, wps=109.4, ups=0.12, wpb=884.7, bsz=80, num_updates=12220, lr=9.00188e-07, gnorm=1.388, clip=80, loss_scale=64, train_wall=81, gb_free=6.8, wall=161168
2022-05-21 18:11:03 - progress_bar.py[line:274] - INFO: epoch 002:   5168 / 7081 loss=-0.008, score=1.513, ntokens=868.8, nsentences=80, sample_size=868.8, wps=107.8, ups=0.12, wpb=868.8, bsz=80, num_updates=12230, lr=8.96582e-07, gnorm=1.699, clip=90, loss_scale=64, train_wall=81, gb_free=6.8, wall=161248
2022-05-21 18:12:25 - progress_bar.py[line:274] - INFO: epoch 002:   5178 / 7081 loss=-0.004, score=1.444, ntokens=887.1, nsentences=80, sample_size=887.1, wps=108.9, ups=0.12, wpb=887.1, bsz=80, num_updates=12240, lr=8.92977e-07, gnorm=1.892, clip=80, loss_scale=64, train_wall=81, gb_free=6.8, wall=161330
2022-05-21 18:13:46 - progress_bar.py[line:274] - INFO: epoch 002:   5188 / 7081 loss=-0.007, score=1.529, ntokens=868.6, nsentences=80, sample_size=868.6, wps=107.7, ups=0.12, wpb=868.6, bsz=80, num_updates=12250, lr=8.89371e-07, gnorm=1.541, clip=80, loss_scale=64, train_wall=81, gb_free=6.8, wall=161410
2022-05-21 18:15:07 - progress_bar.py[line:274] - INFO: epoch 002:   5198 / 7081 loss=-0.008, score=1.601, ntokens=876.6, nsentences=80, sample_size=876.6, wps=107.9, ups=0.12, wpb=876.6, bsz=80, num_updates=12260, lr=8.85766e-07, gnorm=1.425, clip=70, loss_scale=64, train_wall=81, gb_free=6.8, wall=161492
2022-05-21 18:16:28 - progress_bar.py[line:274] - INFO: epoch 002:   5208 / 7081 loss=-0.007, score=1.44, ntokens=891.6, nsentences=80, sample_size=891.6, wps=109.3, ups=0.12, wpb=891.6, bsz=80, num_updates=12270, lr=8.8216e-07, gnorm=1.645, clip=70, loss_scale=64, train_wall=81, gb_free=6.8, wall=161573
2022-05-21 18:17:49 - progress_bar.py[line:274] - INFO: epoch 002:   5218 / 7081 loss=-0.009, score=1.472, ntokens=878.9, nsentences=80, sample_size=878.9, wps=109, ups=0.12, wpb=878.9, bsz=80, num_updates=12280, lr=8.78555e-07, gnorm=1.504, clip=100, loss_scale=64, train_wall=81, gb_free=6.8, wall=161654
2022-05-21 18:19:11 - progress_bar.py[line:274] - INFO: epoch 002:   5228 / 7081 loss=-0.002, score=1.449, ntokens=888.5, nsentences=80, sample_size=888.5, wps=109.1, ups=0.12, wpb=888.5, bsz=80, num_updates=12290, lr=8.74949e-07, gnorm=1.897, clip=100, loss_scale=64, train_wall=81, gb_free=6.8, wall=161735
2022-05-21 18:20:31 - progress_bar.py[line:274] - INFO: epoch 002:   5238 / 7081 loss=-0.006, score=1.515, ntokens=877, nsentences=80, sample_size=877, wps=108.3, ups=0.12, wpb=877, bsz=80, num_updates=12300, lr=8.71344e-07, gnorm=1.77, clip=100, loss_scale=64, train_wall=81, gb_free=6.8, wall=161816
2022-05-21 18:21:52 - progress_bar.py[line:274] - INFO: epoch 002:   5248 / 7081 loss=-0.007, score=1.432, ntokens=878.9, nsentences=80, sample_size=878.9, wps=109, ups=0.12, wpb=878.9, bsz=80, num_updates=12310, lr=8.67738e-07, gnorm=2.14, clip=100, loss_scale=64, train_wall=81, gb_free=6.8, wall=161897
2022-05-21 18:23:09 - progress_bar.py[line:274] - INFO: epoch 002:   5258 / 7081 loss=-0.007, score=1.411, ntokens=888, nsentences=80, sample_size=888, wps=116, ups=0.13, wpb=888, bsz=80, num_updates=12320, lr=8.64133e-07, gnorm=1.411, clip=80, loss_scale=64, train_wall=76, gb_free=6.8, wall=161973
2022-05-21 18:24:25 - progress_bar.py[line:274] - INFO: epoch 002:   5268 / 7081 loss=-0.005, score=1.537, ntokens=882.2, nsentences=80, sample_size=882.2, wps=115.8, ups=0.13, wpb=882.2, bsz=80, num_updates=12330, lr=8.60527e-07, gnorm=1.594, clip=80, loss_scale=64, train_wall=76, gb_free=6.8, wall=162049
2022-05-21 18:25:44 - progress_bar.py[line:274] - INFO: epoch 002:   5278 / 7081 loss=-0.005, score=1.522, ntokens=890.6, nsentences=80, sample_size=890.6, wps=112.2, ups=0.13, wpb=890.6, bsz=80, num_updates=12340, lr=8.56922e-07, gnorm=1.886, clip=100, loss_scale=64, train_wall=79, gb_free=6.8, wall=162129
2022-05-21 18:27:05 - progress_bar.py[line:274] - INFO: epoch 002:   5288 / 7081 loss=-0.006, score=1.443, ntokens=873.3, nsentences=80, sample_size=873.3, wps=108.2, ups=0.12, wpb=873.3, bsz=80, num_updates=12350, lr=8.53316e-07, gnorm=1.989, clip=90, loss_scale=64, train_wall=81, gb_free=6.8, wall=162210
2022-05-21 18:28:26 - progress_bar.py[line:274] - INFO: epoch 002:   5298 / 7081 loss=-0.002, score=1.419, ntokens=887.4, nsentences=80, sample_size=887.4, wps=109.8, ups=0.12, wpb=887.4, bsz=80, num_updates=12360, lr=8.49711e-07, gnorm=1.482, clip=70, loss_scale=64, train_wall=81, gb_free=6.8, wall=162290
2022-05-21 18:29:47 - progress_bar.py[line:274] - INFO: epoch 002:   5308 / 7081 loss=-0.004, score=1.517, ntokens=902.9, nsentences=80, sample_size=902.9, wps=111.3, ups=0.12, wpb=902.9, bsz=80, num_updates=12370, lr=8.46105e-07, gnorm=1.605, clip=90, loss_scale=64, train_wall=81, gb_free=6.8, wall=162372
2022-05-21 18:31:07 - progress_bar.py[line:274] - INFO: epoch 002:   5318 / 7081 loss=-0.004, score=1.385, ntokens=885.8, nsentences=80, sample_size=885.8, wps=109.9, ups=0.12, wpb=885.8, bsz=80, num_updates=12380, lr=8.425e-07, gnorm=1.862, clip=90, loss_scale=64, train_wall=81, gb_free=6.7, wall=162452
2022-05-21 18:32:28 - progress_bar.py[line:274] - INFO: epoch 002:   5328 / 7081 loss=-0.006, score=1.502, ntokens=880.2, nsentences=80, sample_size=880.2, wps=109.7, ups=0.12, wpb=880.2, bsz=80, num_updates=12390, lr=8.38894e-07, gnorm=2.37, clip=90, loss_scale=64, train_wall=80, gb_free=6.8, wall=162532
2022-05-21 18:33:49 - progress_bar.py[line:274] - INFO: epoch 002:   5338 / 7081 loss=-0.001, score=1.423, ntokens=892.3, nsentences=80, sample_size=892.3, wps=109.5, ups=0.12, wpb=892.3, bsz=80, num_updates=12400, lr=8.35289e-07, gnorm=1.48, clip=90, loss_scale=64, train_wall=81, gb_free=6.8, wall=162614
2022-05-21 18:35:10 - progress_bar.py[line:274] - INFO: epoch 002:   5348 / 7081 loss=-0.007, score=1.45, ntokens=873.4, nsentences=80, sample_size=873.4, wps=107.6, ups=0.12, wpb=873.4, bsz=80, num_updates=12410, lr=8.31683e-07, gnorm=1.672, clip=100, loss_scale=64, train_wall=81, gb_free=6.8, wall=162695
2022-05-21 18:36:32 - progress_bar.py[line:274] - INFO: epoch 002:   5358 / 7081 loss=-0.006, score=1.424, ntokens=884.2, nsentences=80, sample_size=884.2, wps=108.8, ups=0.12, wpb=884.2, bsz=80, num_updates=12420, lr=8.28078e-07, gnorm=1.955, clip=90, loss_scale=64, train_wall=81, gb_free=6.8, wall=162776
2022-05-21 18:37:53 - progress_bar.py[line:274] - INFO: epoch 002:   5368 / 7081 loss=-0.002, score=1.451, ntokens=888.3, nsentences=80, sample_size=888.3, wps=108.9, ups=0.12, wpb=888.3, bsz=80, num_updates=12430, lr=8.24472e-07, gnorm=1.537, clip=80, loss_scale=64, train_wall=81, gb_free=6.8, wall=162858
2022-05-21 18:39:14 - progress_bar.py[line:274] - INFO: epoch 002:   5378 / 7081 loss=-0.007, score=1.498, ntokens=884.5, nsentences=80, sample_size=884.5, wps=109.2, ups=0.12, wpb=884.5, bsz=80, num_updates=12440, lr=8.20867e-07, gnorm=1.376, clip=70, loss_scale=64, train_wall=81, gb_free=6.8, wall=162939
2022-05-21 18:40:35 - progress_bar.py[line:274] - INFO: epoch 002:   5388 / 7081 loss=-0.006, score=1.482, ntokens=897.6, nsentences=80, sample_size=897.6, wps=110.3, ups=0.12, wpb=897.6, bsz=80, num_updates=12450, lr=8.17261e-07, gnorm=1.652, clip=90, loss_scale=64, train_wall=81, gb_free=6.7, wall=163020
2022-05-21 18:41:55 - progress_bar.py[line:274] - INFO: epoch 002:   5398 / 7081 loss=-0.004, score=1.569, ntokens=875.6, nsentences=80, sample_size=875.6, wps=109.5, ups=0.13, wpb=875.6, bsz=80, num_updates=12460, lr=8.13656e-07, gnorm=1.68, clip=90, loss_scale=64, train_wall=80, gb_free=6.7, wall=163100
2022-05-21 18:43:16 - progress_bar.py[line:274] - INFO: epoch 002:   5408 / 7081 loss=-0.005, score=1.487, ntokens=879.7, nsentences=80, sample_size=879.7, wps=108.8, ups=0.12, wpb=879.7, bsz=80, num_updates=12470, lr=8.1005e-07, gnorm=1.863, clip=90, loss_scale=64, train_wall=81, gb_free=6.8, wall=163181
2022-05-21 18:44:38 - progress_bar.py[line:274] - INFO: epoch 002:   5418 / 7081 loss=-0.007, score=1.542, ntokens=887.4, nsentences=80, sample_size=887.4, wps=108.9, ups=0.12, wpb=887.4, bsz=80, num_updates=12480, lr=8.06445e-07, gnorm=2.528, clip=90, loss_scale=64, train_wall=81, gb_free=6.8, wall=163262
2022-05-21 18:45:59 - progress_bar.py[line:274] - INFO: epoch 002:   5428 / 7081 loss=-0.006, score=1.484, ntokens=895.3, nsentences=80, sample_size=895.3, wps=109.6, ups=0.12, wpb=895.3, bsz=80, num_updates=12490, lr=8.02839e-07, gnorm=1.692, clip=80, loss_scale=64, train_wall=82, gb_free=6.8, wall=163344
2022-05-21 18:47:21 - progress_bar.py[line:274] - INFO: epoch 002:   5438 / 7081 loss=-0.004, score=1.454, ntokens=875.7, nsentences=80, sample_size=875.7, wps=108, ups=0.12, wpb=875.7, bsz=80, num_updates=12500, lr=7.99234e-07, gnorm=1.977, clip=90, loss_scale=64, train_wall=81, gb_free=6.8, wall=163425
2022-05-21 18:47:21 - train.py[line:436] - INFO: begin validation on "valid" subset
slice_id 0 seek offset 0
slice_id 1 seek offset 2500
slice_id 0 seek offset 0
slice_id 1 seek offset 2500
2022-05-21 19:27:11 - progress_bar.py[line:282] - INFO: epoch 002 | valid on 'valid' subset | loss -0.005 | score 1.298 | ntokens 110.933 | nsentences 10 | sample_size 110.933 | cider 1.389 | wps 116 | wpb 110.9 | bsz 10 | num_updates 12500 | best_cider 1.394
2022-05-21 19:27:11 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 2 @ 12500 updates
2022-05-21 19:27:11 - trainer.py[line:431] - INFO: Saving checkpoint to /database/jhkim/stage2_checkpoints//5e-6_2/checkpoint_2_12500.pt
2022-05-21 19:27:19 - trainer.py[line:441] - INFO: Finished saving checkpoint to /database/jhkim/stage2_checkpoints//5e-6_2/checkpoint_2_12500.pt
2022-05-21 19:28:10 - checkpoint_utils.py[line:135] - INFO: Saved checkpoint /database/jhkim/stage2_checkpoints//5e-6_2/checkpoint_2_12500.pt (epoch 2 @ 12500 updates, score 1.389) (writing took 59.224007453769445 seconds)
2022-05-21 19:29:30 - progress_bar.py[line:274] - INFO: epoch 002:   5448 / 7081 loss=-0.005, score=1.586, ntokens=901, nsentences=80, sample_size=901, wps=3.6, ups=0, wpb=901, bsz=80, num_updates=12510, lr=7.95628e-07, gnorm=1.939, clip=100, loss_scale=64, train_wall=80, gb_free=6.8, wall=165955
2022-05-21 19:30:52 - progress_bar.py[line:274] - INFO: epoch 002:   5458 / 7081 loss=-0.005, score=1.456, ntokens=881.3, nsentences=80, sample_size=881.3, wps=108.6, ups=0.12, wpb=881.3, bsz=80, num_updates=12520, lr=7.92023e-07, gnorm=1.483, clip=80, loss_scale=64, train_wall=81, gb_free=6.8, wall=166036
2022-05-21 19:32:12 - progress_bar.py[line:274] - INFO: epoch 002:   5468 / 7081 loss=-0.008, score=1.466, ntokens=881.8, nsentences=80, sample_size=881.8, wps=109.3, ups=0.12, wpb=881.8, bsz=80, num_updates=12530, lr=7.88417e-07, gnorm=1.498, clip=90, loss_scale=64, train_wall=81, gb_free=6.7, wall=166117
2022-05-21 19:33:33 - progress_bar.py[line:274] - INFO: epoch 002:   5478 / 7081 loss=-0.004, score=1.438, ntokens=893.7, nsentences=80, sample_size=893.7, wps=110.3, ups=0.12, wpb=893.7, bsz=80, num_updates=12540, lr=7.84812e-07, gnorm=1.277, clip=90, loss_scale=64, train_wall=81, gb_free=6.8, wall=166198
2022-05-21 19:34:54 - progress_bar.py[line:274] - INFO: epoch 002:   5488 / 7081 loss=-0.005, score=1.422, ntokens=875.7, nsentences=80, sample_size=875.7, wps=108.4, ups=0.12, wpb=875.7, bsz=80, num_updates=12550, lr=7.81206e-07, gnorm=1.882, clip=90, loss_scale=64, train_wall=81, gb_free=6.8, wall=166279
2022-05-21 19:36:16 - progress_bar.py[line:274] - INFO: epoch 002:   5498 / 7081 loss=-0.004, score=1.441, ntokens=903.7, nsentences=80, sample_size=903.7, wps=110.9, ups=0.12, wpb=903.7, bsz=80, num_updates=12560, lr=7.77601e-07, gnorm=1.404, clip=80, loss_scale=64, train_wall=81, gb_free=6.8, wall=166360
2022-05-21 19:37:37 - progress_bar.py[line:274] - INFO: epoch 002:   5508 / 7081 loss=-0.007, score=1.453, ntokens=889.9, nsentences=80, sample_size=889.9, wps=109.3, ups=0.12, wpb=889.9, bsz=80, num_updates=12570, lr=7.73995e-07, gnorm=1.821, clip=90, loss_scale=64, train_wall=81, gb_free=6.8, wall=166442
2022-05-21 19:38:58 - progress_bar.py[line:274] - INFO: epoch 002:   5518 / 7081 loss=-0.006, score=1.526, ntokens=898.2, nsentences=80, sample_size=898.2, wps=110.7, ups=0.12, wpb=898.2, bsz=80, num_updates=12580, lr=7.7039e-07, gnorm=2.341, clip=90, loss_scale=64, train_wall=81, gb_free=6.8, wall=166523
2022-05-21 19:40:19 - progress_bar.py[line:274] - INFO: epoch 002:   5528 / 7081 loss=-0.006, score=1.419, ntokens=882.4, nsentences=80, sample_size=882.4, wps=109.5, ups=0.12, wpb=882.4, bsz=80, num_updates=12590, lr=7.66784e-07, gnorm=1.441, clip=80, loss_scale=64, train_wall=80, gb_free=6.8, wall=166603
2022-05-21 19:41:35 - progress_bar.py[line:274] - INFO: epoch 002:   5538 / 7081 loss=-0.009, score=1.553, ntokens=886.7, nsentences=80, sample_size=886.7, wps=116, ups=0.13, wpb=886.7, bsz=80, num_updates=12600, lr=7.63179e-07, gnorm=1.501, clip=100, loss_scale=64, train_wall=76, gb_free=6.8, wall=166680
2022-05-21 19:42:52 - progress_bar.py[line:274] - INFO: epoch 002:   5548 / 7081 loss=-0.003, score=1.427, ntokens=890.9, nsentences=80, sample_size=890.9, wps=116.7, ups=0.13, wpb=890.9, bsz=80, num_updates=12610, lr=7.59573e-07, gnorm=1.787, clip=100, loss_scale=64, train_wall=76, gb_free=6.8, wall=166756
2022-05-21 19:44:12 - progress_bar.py[line:274] - INFO: epoch 002:   5558 / 7081 loss=-0.007, score=1.45, ntokens=885.5, nsentences=80, sample_size=885.5, wps=109.4, ups=0.12, wpb=885.5, bsz=80, num_updates=12620, lr=7.55968e-07, gnorm=1.775, clip=100, loss_scale=64, train_wall=81, gb_free=6.8, wall=166837
2022-05-21 19:45:34 - progress_bar.py[line:274] - INFO: epoch 002:   5568 / 7081 loss=-0.007, score=1.409, ntokens=901.2, nsentences=80, sample_size=901.2, wps=110.5, ups=0.12, wpb=901.2, bsz=80, num_updates=12630, lr=7.52362e-07, gnorm=1.764, clip=80, loss_scale=128, train_wall=81, gb_free=6.8, wall=166919
2022-05-21 19:46:55 - progress_bar.py[line:274] - INFO: epoch 002:   5578 / 7081 loss=-0.005, score=1.512, ntokens=885.4, nsentences=80, sample_size=885.4, wps=109.3, ups=0.12, wpb=885.4, bsz=80, num_updates=12640, lr=7.48757e-07, gnorm=1.247, clip=70, loss_scale=128, train_wall=81, gb_free=6.8, wall=167000
2022-05-21 19:48:16 - progress_bar.py[line:274] - INFO: epoch 002:   5588 / 7081 loss=-0.005, score=1.511, ntokens=891.7, nsentences=80, sample_size=891.7, wps=109.4, ups=0.12, wpb=891.7, bsz=80, num_updates=12650, lr=7.45151e-07, gnorm=1.621, clip=100, loss_scale=128, train_wall=81, gb_free=6.8, wall=167081
2022-05-21 19:49:38 - progress_bar.py[line:274] - INFO: epoch 002:   5598 / 7081 loss=-0.012, score=1.446, ntokens=892, nsentences=80, sample_size=892, wps=109.8, ups=0.12, wpb=892, bsz=80, num_updates=12660, lr=7.41546e-07, gnorm=2.405, clip=90, loss_scale=128, train_wall=81, gb_free=6.8, wall=167162
2022-05-21 19:50:26 - trainer.py[line:922] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-05-21 19:51:06 - progress_bar.py[line:274] - INFO: epoch 002:   5609 / 7081 loss=-0.009, score=1.433, ntokens=875.6, nsentences=80, sample_size=875.6, wps=98.7, ups=0.11, wpb=875.6, bsz=80, num_updates=12670, lr=7.3794e-07, gnorm=2.355, clip=100, loss_scale=64, train_wall=89, gb_free=6.8, wall=167251
2022-05-21 19:52:28 - progress_bar.py[line:274] - INFO: epoch 002:   5619 / 7081 loss=-0.004, score=1.495, ntokens=888.2, nsentences=80, sample_size=888.2, wps=108.5, ups=0.12, wpb=888.2, bsz=80, num_updates=12680, lr=7.34335e-07, gnorm=1.137, clip=80, loss_scale=64, train_wall=82, gb_free=6.8, wall=167333
2022-05-21 19:53:50 - progress_bar.py[line:274] - INFO: epoch 002:   5629 / 7081 loss=-0.006, score=1.503, ntokens=886.8, nsentences=80, sample_size=886.8, wps=109.1, ups=0.12, wpb=886.8, bsz=80, num_updates=12690, lr=7.30729e-07, gnorm=1.477, clip=100, loss_scale=64, train_wall=81, gb_free=6.8, wall=167414
2022-05-21 19:55:10 - progress_bar.py[line:274] - INFO: epoch 002:   5639 / 7081 loss=-0.007, score=1.471, ntokens=883.4, nsentences=80, sample_size=883.4, wps=109.7, ups=0.12, wpb=883.4, bsz=80, num_updates=12700, lr=7.27124e-07, gnorm=1.822, clip=100, loss_scale=64, train_wall=80, gb_free=6.8, wall=167495
2022-05-21 19:56:31 - progress_bar.py[line:274] - INFO: epoch 002:   5649 / 7081 loss=-0.006, score=1.416, ntokens=880.3, nsentences=80, sample_size=880.3, wps=109, ups=0.12, wpb=880.3, bsz=80, num_updates=12710, lr=7.23518e-07, gnorm=2.045, clip=90, loss_scale=64, train_wall=81, gb_free=6.7, wall=167575
2022-05-21 19:57:53 - progress_bar.py[line:274] - INFO: epoch 002:   5659 / 7081 loss=-0.006, score=1.544, ntokens=893.8, nsentences=80, sample_size=893.8, wps=108.8, ups=0.12, wpb=893.8, bsz=80, num_updates=12720, lr=7.19913e-07, gnorm=1.524, clip=80, loss_scale=64, train_wall=82, gb_free=6.8, wall=167658
2022-05-21 19:59:15 - progress_bar.py[line:274] - INFO: epoch 002:   5669 / 7081 loss=-0.007, score=1.413, ntokens=887, nsentences=80, sample_size=887, wps=108.3, ups=0.12, wpb=887, bsz=80, num_updates=12730, lr=7.16307e-07, gnorm=1.803, clip=100, loss_scale=64, train_wall=82, gb_free=6.8, wall=167740
2022-05-21 20:00:36 - progress_bar.py[line:274] - INFO: epoch 002:   5679 / 7081 loss=-0.008, score=1.523, ntokens=891.8, nsentences=80, sample_size=891.8, wps=109.9, ups=0.12, wpb=891.8, bsz=80, num_updates=12740, lr=7.12702e-07, gnorm=1.644, clip=100, loss_scale=64, train_wall=81, gb_free=6.8, wall=167821
2022-05-21 20:01:57 - progress_bar.py[line:274] - INFO: epoch 002:   5689 / 7081 loss=-0.007, score=1.471, ntokens=883.3, nsentences=80, sample_size=883.3, wps=109.3, ups=0.12, wpb=883.3, bsz=80, num_updates=12750, lr=7.09096e-07, gnorm=1.227, clip=70, loss_scale=64, train_wall=81, gb_free=6.8, wall=167902
2022-05-21 20:03:18 - progress_bar.py[line:274] - INFO: epoch 002:   5699 / 7081 loss=-0.004, score=1.401, ntokens=897.3, nsentences=80, sample_size=897.3, wps=110.3, ups=0.12, wpb=897.3, bsz=80, num_updates=12760, lr=7.05491e-07, gnorm=1.551, clip=80, loss_scale=64, train_wall=81, gb_free=6.8, wall=167983
2022-05-21 20:04:39 - progress_bar.py[line:274] - INFO: epoch 002:   5709 / 7081 loss=-0.006, score=1.474, ntokens=897.3, nsentences=80, sample_size=897.3, wps=110.8, ups=0.12, wpb=897.3, bsz=80, num_updates=12770, lr=7.01885e-07, gnorm=1.412, clip=70, loss_scale=64, train_wall=81, gb_free=6.8, wall=168064
2022-05-21 20:06:00 - progress_bar.py[line:274] - INFO: epoch 002:   5719 / 7081 loss=-0.009, score=1.426, ntokens=881.2, nsentences=80, sample_size=881.2, wps=108.9, ups=0.12, wpb=881.2, bsz=80, num_updates=12780, lr=6.9828e-07, gnorm=1.496, clip=70, loss_scale=64, train_wall=81, gb_free=6.8, wall=168145
2022-05-21 20:07:17 - progress_bar.py[line:274] - INFO: epoch 002:   5729 / 7081 loss=-0.006, score=1.393, ntokens=871.1, nsentences=80, sample_size=871.1, wps=113.3, ups=0.13, wpb=871.1, bsz=80, num_updates=12790, lr=6.94674e-07, gnorm=1.799, clip=100, loss_scale=64, train_wall=77, gb_free=6.8, wall=168222
2022-05-21 20:08:34 - progress_bar.py[line:274] - INFO: epoch 002:   5739 / 7081 loss=-0.005, score=1.411, ntokens=898.9, nsentences=80, sample_size=898.9, wps=116.4, ups=0.13, wpb=898.9, bsz=80, num_updates=12800, lr=6.91069e-07, gnorm=1.337, clip=80, loss_scale=64, train_wall=77, gb_free=6.8, wall=168299
2022-05-21 20:09:53 - progress_bar.py[line:274] - INFO: epoch 002:   5749 / 7081 loss=-0.008, score=1.396, ntokens=895.7, nsentences=80, sample_size=895.7, wps=113.1, ups=0.13, wpb=895.7, bsz=80, num_updates=12810, lr=6.87463e-07, gnorm=1.948, clip=90, loss_scale=64, train_wall=79, gb_free=6.8, wall=168378
2022-05-21 20:11:15 - progress_bar.py[line:274] - INFO: epoch 002:   5759 / 7081 loss=-0.004, score=1.337, ntokens=886.2, nsentences=80, sample_size=886.2, wps=108.5, ups=0.12, wpb=886.2, bsz=80, num_updates=12820, lr=6.83858e-07, gnorm=1.383, clip=60, loss_scale=64, train_wall=82, gb_free=6.8, wall=168460
2022-05-21 20:12:36 - progress_bar.py[line:274] - INFO: epoch 002:   5769 / 7081 loss=-0.006, score=1.498, ntokens=883.8, nsentences=80, sample_size=883.8, wps=108.7, ups=0.12, wpb=883.8, bsz=80, num_updates=12830, lr=6.80252e-07, gnorm=1.82, clip=100, loss_scale=64, train_wall=81, gb_free=6.8, wall=168541
2022-05-21 20:13:58 - progress_bar.py[line:274] - INFO: epoch 002:   5779 / 7081 loss=-0.005, score=1.461, ntokens=889.1, nsentences=80, sample_size=889.1, wps=108.6, ups=0.12, wpb=889.1, bsz=80, num_updates=12840, lr=6.76647e-07, gnorm=1.987, clip=90, loss_scale=64, train_wall=82, gb_free=6.8, wall=168623
2022-05-21 20:15:19 - progress_bar.py[line:274] - INFO: epoch 002:   5789 / 7081 loss=-0.006, score=1.441, ntokens=882.7, nsentences=80, sample_size=882.7, wps=109.1, ups=0.12, wpb=882.7, bsz=80, num_updates=12850, lr=6.73041e-07, gnorm=1.258, clip=80, loss_scale=64, train_wall=81, gb_free=6.8, wall=168704
2022-05-21 20:16:40 - progress_bar.py[line:274] - INFO: epoch 002:   5799 / 7081 loss=-0.008, score=1.461, ntokens=896.8, nsentences=80, sample_size=896.8, wps=110.4, ups=0.12, wpb=896.8, bsz=80, num_updates=12860, lr=6.69436e-07, gnorm=1.777, clip=100, loss_scale=64, train_wall=81, gb_free=6.8, wall=168785
2022-05-21 20:18:02 - progress_bar.py[line:274] - INFO: epoch 002:   5809 / 7081 loss=-0.009, score=1.493, ntokens=889.4, nsentences=80, sample_size=889.4, wps=109.5, ups=0.12, wpb=889.4, bsz=80, num_updates=12870, lr=6.6583e-07, gnorm=1.693, clip=100, loss_scale=64, train_wall=81, gb_free=6.8, wall=168866
2022-05-21 20:19:22 - progress_bar.py[line:274] - INFO: epoch 002:   5819 / 7081 loss=-0.009, score=1.501, ntokens=881.1, nsentences=80, sample_size=881.1, wps=109, ups=0.12, wpb=881.1, bsz=80, num_updates=12880, lr=6.62225e-07, gnorm=1.532, clip=100, loss_scale=64, train_wall=81, gb_free=6.8, wall=168947
2022-05-21 20:20:44 - progress_bar.py[line:274] - INFO: epoch 002:   5829 / 7081 loss=-0.005, score=1.337, ntokens=880.9, nsentences=80, sample_size=880.9, wps=107.6, ups=0.12, wpb=880.9, bsz=80, num_updates=12890, lr=6.58619e-07, gnorm=1.341, clip=70, loss_scale=64, train_wall=82, gb_free=6.8, wall=169029
2022-05-21 20:22:05 - progress_bar.py[line:274] - INFO: epoch 002:   5839 / 7081 loss=-0.008, score=1.522, ntokens=898.1, nsentences=80, sample_size=898.1, wps=110.8, ups=0.12, wpb=898.1, bsz=80, num_updates=12900, lr=6.55014e-07, gnorm=2.081, clip=100, loss_scale=64, train_wall=81, gb_free=6.8, wall=169110
2022-05-21 20:23:26 - progress_bar.py[line:274] - INFO: epoch 002:   5849 / 7081 loss=-0.007, score=1.39, ntokens=891.9, nsentences=80, sample_size=891.9, wps=110.3, ups=0.12, wpb=891.9, bsz=80, num_updates=12910, lr=6.51408e-07, gnorm=1.599, clip=100, loss_scale=64, train_wall=81, gb_free=6.8, wall=169191
2022-05-21 20:24:47 - progress_bar.py[line:274] - INFO: epoch 002:   5859 / 7081 loss=-0.004, score=1.477, ntokens=878.8, nsentences=80, sample_size=878.8, wps=109.2, ups=0.12, wpb=878.8, bsz=80, num_updates=12920, lr=6.47803e-07, gnorm=1.984, clip=80, loss_scale=64, train_wall=80, gb_free=6.8, wall=169271
2022-05-21 20:26:08 - progress_bar.py[line:274] - INFO: epoch 002:   5869 / 7081 loss=-0.005, score=1.492, ntokens=883.8, nsentences=80, sample_size=883.8, wps=109.2, ups=0.12, wpb=883.8, bsz=80, num_updates=12930, lr=6.44197e-07, gnorm=1.582, clip=90, loss_scale=64, train_wall=81, gb_free=6.8, wall=169352
2022-05-21 20:27:29 - progress_bar.py[line:274] - INFO: epoch 002:   5879 / 7081 loss=-0.003, score=1.467, ntokens=887.1, nsentences=80, sample_size=887.1, wps=109, ups=0.12, wpb=887.1, bsz=80, num_updates=12940, lr=6.40592e-07, gnorm=1.801, clip=100, loss_scale=64, train_wall=81, gb_free=6.8, wall=169434
2022-05-21 20:28:50 - progress_bar.py[line:274] - INFO: epoch 002:   5889 / 7081 loss=-0.002, score=1.451, ntokens=900, nsentences=80, sample_size=900, wps=111.2, ups=0.12, wpb=900, bsz=80, num_updates=12950, lr=6.36986e-07, gnorm=1.516, clip=70, loss_scale=64, train_wall=81, gb_free=6.8, wall=169515
2022-05-21 20:30:11 - progress_bar.py[line:274] - INFO: epoch 002:   5899 / 7081 loss=-0.006, score=1.447, ntokens=882.4, nsentences=80, sample_size=882.4, wps=108.7, ups=0.12, wpb=882.4, bsz=80, num_updates=12960, lr=6.33381e-07, gnorm=2.675, clip=90, loss_scale=64, train_wall=81, gb_free=6.8, wall=169596
2022-05-21 20:31:32 - progress_bar.py[line:274] - INFO: epoch 002:   5909 / 7081 loss=-0.007, score=1.429, ntokens=876, nsentences=80, sample_size=876, wps=108.1, ups=0.12, wpb=876, bsz=80, num_updates=12970, lr=6.29775e-07, gnorm=2.462, clip=100, loss_scale=64, train_wall=81, gb_free=6.8, wall=169677
2022-05-21 20:32:52 - progress_bar.py[line:274] - INFO: epoch 002:   5919 / 7081 loss=-0.007, score=1.497, ntokens=892.3, nsentences=80, sample_size=892.3, wps=111.3, ups=0.12, wpb=892.3, bsz=80, num_updates=12980, lr=6.2617e-07, gnorm=1.795, clip=100, loss_scale=64, train_wall=80, gb_free=6.8, wall=169757
2022-05-21 20:34:09 - progress_bar.py[line:274] - INFO: epoch 002:   5929 / 7081 loss=-0.004, score=1.469, ntokens=883.9, nsentences=80, sample_size=883.9, wps=115.9, ups=0.13, wpb=883.9, bsz=80, num_updates=12990, lr=6.22564e-07, gnorm=1.932, clip=90, loss_scale=64, train_wall=76, gb_free=6.8, wall=169833
slice_id 1 seek offset 2500
2022-05-21 20:35:25 - progress_bar.py[line:274] - INFO: epoch 002:   5939 / 7081 loss=-0.006, score=1.557, ntokens=891.5, nsentences=80, sample_size=891.5, wps=116.7, ups=0.13, wpb=891.5, bsz=80, num_updates=13000, lr=6.18959e-07, gnorm=1.95, clip=90, loss_scale=64, train_wall=76, gb_free=6.8, wall=169910
2022-05-21 20:35:25 - train.py[line:436] - INFO: begin validation on "valid" subset
slice_id 0 seek offset 0
slice_id 1 seek offset 2500
slice_id 0 seek offset 0
2022-05-21 21:15:28 - progress_bar.py[line:282] - INFO: epoch 002 | valid on 'valid' subset | loss -0.005 | score 1.298 | ntokens 110.933 | nsentences 10 | sample_size 110.933 | cider 1.389 | wps 115.4 | wpb 110.9 | bsz 10 | num_updates 13000 | best_cider 1.394
2022-05-21 21:15:28 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 2 @ 13000 updates
2022-05-21 21:15:28 - trainer.py[line:431] - INFO: Saving checkpoint to /database/jhkim/stage2_checkpoints//5e-6_2/checkpoint_2_13000.pt
2022-05-21 21:15:36 - trainer.py[line:441] - INFO: Finished saving checkpoint to /database/jhkim/stage2_checkpoints//5e-6_2/checkpoint_2_13000.pt
2022-05-21 21:16:08 - checkpoint_utils.py[line:135] - INFO: Saved checkpoint /database/jhkim/stage2_checkpoints//5e-6_2/checkpoint_2_13000.pt (epoch 2 @ 13000 updates, score 1.389) (writing took 40.385427525267005 seconds)
2022-05-21 21:17:28 - progress_bar.py[line:274] - INFO: epoch 002:   5949 / 7081 loss=-0.006, score=1.473, ntokens=901.3, nsentences=80, sample_size=901.3, wps=3.6, ups=0, wpb=901.3, bsz=80, num_updates=13010, lr=6.15353e-07, gnorm=1.65, clip=90, loss_scale=64, train_wall=80, gb_free=6.8, wall=172433
2022-05-21 21:18:49 - progress_bar.py[line:274] - INFO: epoch 002:   5959 / 7081 loss=-0.006, score=1.495, ntokens=882.9, nsentences=80, sample_size=882.9, wps=109.7, ups=0.12, wpb=882.9, bsz=80, num_updates=13020, lr=6.11748e-07, gnorm=1.419, clip=80, loss_scale=64, train_wall=80, gb_free=6.8, wall=172514
2022-05-21 21:20:10 - progress_bar.py[line:274] - INFO: epoch 002:   5969 / 7081 loss=-0.007, score=1.409, ntokens=883.7, nsentences=80, sample_size=883.7, wps=109.2, ups=0.12, wpb=883.7, bsz=80, num_updates=13030, lr=6.08142e-07, gnorm=1.45, clip=90, loss_scale=64, train_wall=81, gb_free=6.8, wall=172594
2022-05-21 21:21:32 - progress_bar.py[line:274] - INFO: epoch 002:   5979 / 7081 loss=-0.006, score=1.36, ntokens=901.3, nsentences=80, sample_size=901.3, wps=110.1, ups=0.12, wpb=901.3, bsz=80, num_updates=13040, lr=6.04537e-07, gnorm=1.287, clip=70, loss_scale=64, train_wall=82, gb_free=6.8, wall=172676
2022-05-21 21:22:52 - progress_bar.py[line:274] - INFO: epoch 002:   5989 / 7081 loss=-0.005, score=1.396, ntokens=888.1, nsentences=80, sample_size=888.1, wps=110.1, ups=0.12, wpb=888.1, bsz=80, num_updates=13050, lr=6.00931e-07, gnorm=1.755, clip=100, loss_scale=64, train_wall=81, gb_free=6.8, wall=172757
2022-05-21 21:24:13 - progress_bar.py[line:274] - INFO: epoch 002:   5999 / 7081 loss=-0.007, score=1.33, ntokens=891.9, nsentences=80, sample_size=891.9, wps=110.1, ups=0.12, wpb=891.9, bsz=80, num_updates=13060, lr=5.97326e-07, gnorm=1.714, clip=80, loss_scale=64, train_wall=81, gb_free=6.8, wall=172838
2022-05-21 21:25:32 - progress_bar.py[line:274] - INFO: epoch 002:   6009 / 7081 loss=-0.005, score=1.415, ntokens=895.9, nsentences=80, sample_size=895.9, wps=114.3, ups=0.13, wpb=895.9, bsz=80, num_updates=13070, lr=5.9372e-07, gnorm=1.701, clip=100, loss_scale=64, train_wall=78, gb_free=6.8, wall=172916
2022-05-21 21:26:48 - progress_bar.py[line:274] - INFO: epoch 002:   6019 / 7081 loss=-0.006, score=1.385, ntokens=887.9, nsentences=80, sample_size=887.9, wps=116.4, ups=0.13, wpb=887.9, bsz=80, num_updates=13080, lr=5.90115e-07, gnorm=2.255, clip=90, loss_scale=64, train_wall=76, gb_free=6.8, wall=172993
2022-05-21 21:28:06 - progress_bar.py[line:274] - INFO: epoch 002:   6029 / 7081 loss=-0.004, score=1.461, ntokens=871.8, nsentences=80, sample_size=871.8, wps=111.8, ups=0.13, wpb=871.8, bsz=80, num_updates=13090, lr=5.86509e-07, gnorm=1.839, clip=90, loss_scale=64, train_wall=78, gb_free=6.8, wall=173071
2022-05-21 21:29:27 - progress_bar.py[line:274] - INFO: epoch 002:   6039 / 7081 loss=-0.004, score=1.391, ntokens=890.5, nsentences=80, sample_size=890.5, wps=109.6, ups=0.12, wpb=890.5, bsz=80, num_updates=13100, lr=5.82904e-07, gnorm=1.475, clip=70, loss_scale=64, train_wall=81, gb_free=6.8, wall=173152
2022-05-21 21:30:48 - progress_bar.py[line:274] - INFO: epoch 002:   6049 / 7081 loss=-0.007, score=1.539, ntokens=886.2, nsentences=80, sample_size=886.2, wps=109.8, ups=0.12, wpb=886.2, bsz=80, num_updates=13110, lr=5.79298e-07, gnorm=1.488, clip=80, loss_scale=64, train_wall=81, gb_free=6.8, wall=173233
2022-05-21 21:32:09 - progress_bar.py[line:274] - INFO: epoch 002:   6059 / 7081 loss=-0.009, score=1.524, ntokens=885.9, nsentences=80, sample_size=885.9, wps=109.8, ups=0.12, wpb=885.9, bsz=80, num_updates=13120, lr=5.75693e-07, gnorm=1.528, clip=100, loss_scale=64, train_wall=81, gb_free=6.8, wall=173313
2022-05-21 21:33:30 - progress_bar.py[line:274] - INFO: epoch 002:   6069 / 7081 loss=-0.006, score=1.5, ntokens=886.2, nsentences=80, sample_size=886.2, wps=109.4, ups=0.12, wpb=886.2, bsz=80, num_updates=13130, lr=5.72087e-07, gnorm=1.662, clip=100, loss_scale=64, train_wall=81, gb_free=6.8, wall=173394
2022-05-21 21:34:51 - progress_bar.py[line:274] - INFO: epoch 002:   6079 / 7081 loss=-0.008, score=1.444, ntokens=895.1, nsentences=80, sample_size=895.1, wps=110.3, ups=0.12, wpb=895.1, bsz=80, num_updates=13140, lr=5.68482e-07, gnorm=1.533, clip=90, loss_scale=64, train_wall=81, gb_free=6.8, wall=173475
2022-05-21 21:36:12 - progress_bar.py[line:274] - INFO: epoch 002:   6089 / 7081 loss=-0.007, score=1.41, ntokens=888.4, nsentences=80, sample_size=888.4, wps=109.7, ups=0.12, wpb=888.4, bsz=80, num_updates=13150, lr=5.64876e-07, gnorm=1.631, clip=60, loss_scale=64, train_wall=81, gb_free=6.8, wall=173556
2022-05-21 21:37:32 - progress_bar.py[line:274] - INFO: epoch 002:   6099 / 7081 loss=-0.006, score=1.408, ntokens=877.4, nsentences=80, sample_size=877.4, wps=109.2, ups=0.12, wpb=877.4, bsz=80, num_updates=13160, lr=5.61271e-07, gnorm=2.201, clip=90, loss_scale=64, train_wall=80, gb_free=6.8, wall=173637
2022-05-21 21:38:54 - progress_bar.py[line:274] - INFO: epoch 002:   6109 / 7081 loss=-0.007, score=1.454, ntokens=902.1, nsentences=80, sample_size=902.1, wps=110.3, ups=0.12, wpb=902.1, bsz=80, num_updates=13170, lr=5.57665e-07, gnorm=1.232, clip=60, loss_scale=64, train_wall=82, gb_free=6.8, wall=173719
2022-05-21 21:40:15 - progress_bar.py[line:274] - INFO: epoch 002:   6119 / 7081 loss=-0.004, score=1.509, ntokens=884.6, nsentences=80, sample_size=884.6, wps=108.7, ups=0.12, wpb=884.6, bsz=80, num_updates=13180, lr=5.5406e-07, gnorm=2.096, clip=100, loss_scale=128, train_wall=81, gb_free=6.8, wall=173800
2022-05-21 21:41:37 - progress_bar.py[line:274] - INFO: epoch 002:   6129 / 7081 loss=-0.009, score=1.491, ntokens=899.3, nsentences=80, sample_size=899.3, wps=110.6, ups=0.12, wpb=899.3, bsz=80, num_updates=13190, lr=5.50454e-07, gnorm=1.501, clip=80, loss_scale=128, train_wall=81, gb_free=6.8, wall=173881
2022-05-21 21:42:58 - progress_bar.py[line:274] - INFO: epoch 002:   6139 / 7081 loss=-0.004, score=1.421, ntokens=885.6, nsentences=80, sample_size=885.6, wps=109.2, ups=0.12, wpb=885.6, bsz=80, num_updates=13200, lr=5.46849e-07, gnorm=1.372, clip=90, loss_scale=128, train_wall=81, gb_free=6.7, wall=173962
2022-05-21 21:44:19 - progress_bar.py[line:274] - INFO: epoch 002:   6149 / 7081 loss=-0.008, score=1.415, ntokens=883.7, nsentences=80, sample_size=883.7, wps=109.2, ups=0.12, wpb=883.7, bsz=80, num_updates=13210, lr=5.43243e-07, gnorm=1.545, clip=90, loss_scale=128, train_wall=81, gb_free=6.8, wall=174043
2022-05-21 21:45:40 - progress_bar.py[line:274] - INFO: epoch 002:   6159 / 7081 loss=-0, score=1.42, ntokens=890.5, nsentences=80, sample_size=890.5, wps=109.6, ups=0.12, wpb=890.5, bsz=80, num_updates=13220, lr=5.39638e-07, gnorm=1.324, clip=80, loss_scale=128, train_wall=81, gb_free=6.8, wall=174125
2022-05-21 21:47:00 - progress_bar.py[line:274] - INFO: epoch 002:   6169 / 7081 loss=-0.007, score=1.485, ntokens=885.5, nsentences=80, sample_size=885.5, wps=110.3, ups=0.12, wpb=885.5, bsz=80, num_updates=13230, lr=5.36032e-07, gnorm=2.039, clip=100, loss_scale=128, train_wall=80, gb_free=6.8, wall=174205
2022-05-21 21:47:08 - trainer.py[line:922] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
2022-05-21 21:48:29 - progress_bar.py[line:274] - INFO: epoch 002:   6180 / 7081 loss=-0.007, score=1.406, ntokens=879.9, nsentences=80, sample_size=879.9, wps=99.1, ups=0.11, wpb=879.9, bsz=80, num_updates=13240, lr=5.32427e-07, gnorm=1.451, clip=70, loss_scale=64, train_wall=89, gb_free=6.8, wall=174294
2022-05-21 21:49:50 - progress_bar.py[line:274] - INFO: epoch 002:   6190 / 7081 loss=-0.005, score=1.4, ntokens=891.3, nsentences=80, sample_size=891.3, wps=109.9, ups=0.12, wpb=891.3, bsz=80, num_updates=13250, lr=5.28821e-07, gnorm=2.217, clip=90, loss_scale=64, train_wall=81, gb_free=6.8, wall=174375
2022-05-21 21:51:11 - progress_bar.py[line:274] - INFO: epoch 002:   6200 / 7081 loss=-0.006, score=1.367, ntokens=887.7, nsentences=80, sample_size=887.7, wps=110.3, ups=0.12, wpb=887.7, bsz=80, num_updates=13260, lr=5.25216e-07, gnorm=1.511, clip=70, loss_scale=64, train_wall=80, gb_free=6.8, wall=174455
2022-05-21 21:52:27 - progress_bar.py[line:274] - INFO: epoch 002:   6210 / 7081 loss=-0.009, score=1.525, ntokens=895.9, nsentences=80, sample_size=895.9, wps=116.9, ups=0.13, wpb=895.9, bsz=80, num_updates=13270, lr=5.2161e-07, gnorm=1.281, clip=80, loss_scale=64, train_wall=77, gb_free=6.8, wall=174532
2022-05-21 21:53:43 - progress_bar.py[line:274] - INFO: epoch 002:   6220 / 7081 loss=-0.007, score=1.462, ntokens=885.4, nsentences=80, sample_size=885.4, wps=116.6, ups=0.13, wpb=885.4, bsz=80, num_updates=13280, lr=5.18005e-07, gnorm=1.581, clip=80, loss_scale=64, train_wall=76, gb_free=6.8, wall=174608
2022-05-21 21:55:03 - progress_bar.py[line:274] - INFO: epoch 002:   6230 / 7081 loss=-0.005, score=1.314, ntokens=889, nsentences=80, sample_size=889, wps=110.8, ups=0.12, wpb=889, bsz=80, num_updates=13290, lr=5.14399e-07, gnorm=1.261, clip=60, loss_scale=64, train_wall=80, gb_free=6.8, wall=174688
2022-05-21 21:56:25 - progress_bar.py[line:274] - INFO: epoch 002:   6240 / 7081 loss=-0.008, score=1.549, ntokens=881.5, nsentences=80, sample_size=881.5, wps=108.6, ups=0.12, wpb=881.5, bsz=80, num_updates=13300, lr=5.10794e-07, gnorm=1.898, clip=100, loss_scale=64, train_wall=81, gb_free=6.8, wall=174769
2022-05-21 21:57:46 - progress_bar.py[line:274] - INFO: epoch 002:   6250 / 7081 loss=-0.005, score=1.495, ntokens=890.5, nsentences=80, sample_size=890.5, wps=110, ups=0.12, wpb=890.5, bsz=80, num_updates=13310, lr=5.07188e-07, gnorm=1.718, clip=80, loss_scale=64, train_wall=81, gb_free=6.8, wall=174850
2022-05-21 21:59:07 - progress_bar.py[line:274] - INFO: epoch 002:   6260 / 7081 loss=-0.007, score=1.501, ntokens=884.1, nsentences=80, sample_size=884.1, wps=109.2, ups=0.12, wpb=884.1, bsz=80, num_updates=13320, lr=5.03583e-07, gnorm=1.772, clip=100, loss_scale=64, train_wall=81, gb_free=6.8, wall=174931
2022-05-21 22:00:28 - progress_bar.py[line:274] - INFO: epoch 002:   6270 / 7081 loss=-0.005, score=1.411, ntokens=888.7, nsentences=80, sample_size=888.7, wps=109.5, ups=0.12, wpb=888.7, bsz=80, num_updates=13330, lr=4.99977e-07, gnorm=1.293, clip=70, loss_scale=64, train_wall=81, gb_free=6.8, wall=175012
2022-05-21 22:01:48 - progress_bar.py[line:274] - INFO: epoch 002:   6280 / 7081 loss=-0.004, score=1.562, ntokens=869.9, nsentences=80, sample_size=869.9, wps=108.2, ups=0.12, wpb=869.9, bsz=80, num_updates=13340, lr=4.96372e-07, gnorm=1.735, clip=100, loss_scale=64, train_wall=80, gb_free=6.8, wall=175093
2022-05-21 22:03:09 - progress_bar.py[line:274] - INFO: epoch 002:   6290 / 7081 loss=-0.006, score=1.484, ntokens=872.2, nsentences=80, sample_size=872.2, wps=108.1, ups=0.12, wpb=872.2, bsz=80, num_updates=13350, lr=4.92766e-07, gnorm=1.672, clip=70, loss_scale=64, train_wall=81, gb_free=6.8, wall=175173
2022-05-21 22:04:30 - progress_bar.py[line:274] - INFO: epoch 002:   6300 / 7081 loss=-0.006, score=1.428, ntokens=888.5, nsentences=80, sample_size=888.5, wps=109.7, ups=0.12, wpb=888.5, bsz=80, num_updates=13360, lr=4.89161e-07, gnorm=1.944, clip=90, loss_scale=64, train_wall=81, gb_free=6.8, wall=175254
2022-05-21 22:05:51 - progress_bar.py[line:274] - INFO: epoch 002:   6310 / 7081 loss=-0.005, score=1.354, ntokens=894.5, nsentences=80, sample_size=894.5, wps=109.7, ups=0.12, wpb=894.5, bsz=80, num_updates=13370, lr=4.85555e-07, gnorm=1.381, clip=70, loss_scale=64, train_wall=81, gb_free=6.8, wall=175336
2022-05-21 22:07:11 - progress_bar.py[line:274] - INFO: epoch 002:   6320 / 7081 loss=-0.005, score=1.489, ntokens=879, nsentences=80, sample_size=879, wps=109.7, ups=0.12, wpb=879, bsz=80, num_updates=13380, lr=4.8195e-07, gnorm=1.953, clip=80, loss_scale=64, train_wall=80, gb_free=6.8, wall=175416
2022-05-21 22:08:33 - progress_bar.py[line:274] - INFO: epoch 002:   6330 / 7081 loss=-0.004, score=1.478, ntokens=884.1, nsentences=80, sample_size=884.1, wps=108.8, ups=0.12, wpb=884.1, bsz=80, num_updates=13390, lr=4.78344e-07, gnorm=2.051, clip=80, loss_scale=64, train_wall=81, gb_free=6.8, wall=175497
2022-05-21 22:09:53 - progress_bar.py[line:274] - INFO: epoch 002:   6340 / 7081 loss=-0.005, score=1.573, ntokens=880.9, nsentences=80, sample_size=880.9, wps=109.1, ups=0.12, wpb=880.9, bsz=80, num_updates=13400, lr=4.74739e-07, gnorm=1.478, clip=100, loss_scale=64, train_wall=81, gb_free=6.8, wall=175578
2022-05-21 22:11:14 - progress_bar.py[line:274] - INFO: epoch 002:   6350 / 7081 loss=-0.006, score=1.518, ntokens=888, nsentences=80, sample_size=888, wps=110.3, ups=0.12, wpb=888, bsz=80, num_updates=13410, lr=4.71133e-07, gnorm=1.798, clip=80, loss_scale=64, train_wall=80, gb_free=6.8, wall=175659
2022-05-21 22:12:35 - progress_bar.py[line:274] - INFO: epoch 002:   6360 / 7081 loss=-0.008, score=1.359, ntokens=887.4, nsentences=80, sample_size=887.4, wps=109.6, ups=0.12, wpb=887.4, bsz=80, num_updates=13420, lr=4.67528e-07, gnorm=1.526, clip=90, loss_scale=64, train_wall=81, gb_free=6.8, wall=175740
2022-05-21 22:13:55 - progress_bar.py[line:274] - INFO: epoch 002:   6370 / 7081 loss=-0.009, score=1.425, ntokens=878.1, nsentences=80, sample_size=878.1, wps=109.2, ups=0.12, wpb=878.1, bsz=80, num_updates=13430, lr=4.63922e-07, gnorm=1.609, clip=100, loss_scale=64, train_wall=80, gb_free=6.8, wall=175820
2022-05-21 22:15:16 - progress_bar.py[line:274] - INFO: epoch 002:   6380 / 7081 loss=-0.008, score=1.508, ntokens=879.4, nsentences=80, sample_size=879.4, wps=109.2, ups=0.12, wpb=879.4, bsz=80, num_updates=13440, lr=4.60317e-07, gnorm=1.483, clip=100, loss_scale=64, train_wall=80, gb_free=6.8, wall=175901
2022-05-21 22:16:37 - progress_bar.py[line:274] - INFO: epoch 002:   6390 / 7081 loss=-0.008, score=1.493, ntokens=893, nsentences=80, sample_size=893, wps=110.2, ups=0.12, wpb=893, bsz=80, num_updates=13450, lr=4.56711e-07, gnorm=1.391, clip=80, loss_scale=64, train_wall=81, gb_free=6.8, wall=175982
2022-05-21 22:17:55 - progress_bar.py[line:274] - INFO: epoch 002:   6400 / 7081 loss=-0.006, score=1.339, ntokens=877.9, nsentences=80, sample_size=877.9, wps=112.2, ups=0.13, wpb=877.9, bsz=80, num_updates=13460, lr=4.53106e-07, gnorm=2.015, clip=100, loss_scale=64, train_wall=78, gb_free=6.8, wall=176060
2022-05-21 22:19:12 - progress_bar.py[line:274] - INFO: epoch 002:   6410 / 7081 loss=-0.004, score=1.397, ntokens=880, nsentences=80, sample_size=880, wps=114.8, ups=0.13, wpb=880, bsz=80, num_updates=13470, lr=4.495e-07, gnorm=1.298, clip=80, loss_scale=64, train_wall=77, gb_free=6.8, wall=176136
2022-05-21 22:20:30 - progress_bar.py[line:274] - INFO: epoch 002:   6420 / 7081 loss=-0.006, score=1.478, ntokens=879.6, nsentences=80, sample_size=879.6, wps=112.6, ups=0.13, wpb=879.6, bsz=80, num_updates=13480, lr=4.45895e-07, gnorm=2.137, clip=90, loss_scale=64, train_wall=78, gb_free=6.8, wall=176215
2022-05-21 22:21:50 - progress_bar.py[line:274] - INFO: epoch 002:   6430 / 7081 loss=-0.007, score=1.463, ntokens=888, nsentences=80, sample_size=888, wps=110.6, ups=0.12, wpb=888, bsz=80, num_updates=13490, lr=4.42289e-07, gnorm=1.806, clip=70, loss_scale=64, train_wall=80, gb_free=6.8, wall=176295
slice_id 1 seek offset 2500
2022-05-21 22:23:11 - progress_bar.py[line:274] - INFO: epoch 002:   6440 / 7081 loss=-0.003, score=1.418, ntokens=882.8, nsentences=80, sample_size=882.8, wps=109.1, ups=0.12, wpb=882.8, bsz=80, num_updates=13500, lr=4.38684e-07, gnorm=1.507, clip=70, loss_scale=64, train_wall=81, gb_free=6.7, wall=176376
2022-05-21 22:23:11 - train.py[line:436] - INFO: begin validation on "valid" subset
slice_id 0 seek offset 0
slice_id 0 seek offset 0
slice_id 1 seek offset 2500
2022-05-21 23:03:15 - progress_bar.py[line:282] - INFO: epoch 002 | valid on 'valid' subset | loss -0.005 | score 1.299 | ntokens 110.949 | nsentences 10 | sample_size 110.949 | cider 1.39 | wps 115.4 | wpb 110.9 | bsz 10 | num_updates 13500 | best_cider 1.394
2022-05-21 23:03:15 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 2 @ 13500 updates
2022-05-21 23:03:15 - trainer.py[line:431] - INFO: Saving checkpoint to /database/jhkim/stage2_checkpoints//5e-6_2/checkpoint_2_13500.pt
2022-05-21 23:03:23 - trainer.py[line:441] - INFO: Finished saving checkpoint to /database/jhkim/stage2_checkpoints//5e-6_2/checkpoint_2_13500.pt
2022-05-21 23:03:50 - checkpoint_utils.py[line:135] - INFO: Saved checkpoint /database/jhkim/stage2_checkpoints//5e-6_2/checkpoint_2_13500.pt (epoch 2 @ 13500 updates, score 1.39) (writing took 35.61499398900196 seconds)
2022-05-21 23:05:09 - progress_bar.py[line:274] - INFO: epoch 002:   6450 / 7081 loss=-0.007, score=1.43, ntokens=873.2, nsentences=80, sample_size=873.2, wps=3.5, ups=0, wpb=873.2, bsz=80, num_updates=13510, lr=4.35078e-07, gnorm=1.614, clip=90, loss_scale=64, train_wall=79, gb_free=6.8, wall=178894
2022-05-21 23:06:30 - progress_bar.py[line:274] - INFO: epoch 002:   6460 / 7081 loss=-0.008, score=1.496, ntokens=891.2, nsentences=80, sample_size=891.2, wps=109.9, ups=0.12, wpb=891.2, bsz=80, num_updates=13520, lr=4.31473e-07, gnorm=1.422, clip=90, loss_scale=64, train_wall=81, gb_free=6.8, wall=178975
2022-05-21 23:07:51 - progress_bar.py[line:274] - INFO: epoch 002:   6470 / 7081 loss=-0.007, score=1.435, ntokens=886.3, nsentences=80, sample_size=886.3, wps=109.4, ups=0.12, wpb=886.3, bsz=80, num_updates=13530, lr=4.27867e-07, gnorm=1.681, clip=90, loss_scale=64, train_wall=81, gb_free=6.8, wall=179056
2022-05-21 23:09:13 - progress_bar.py[line:274] - INFO: epoch 002:   6480 / 7081 loss=-0.007, score=1.491, ntokens=887.6, nsentences=80, sample_size=887.6, wps=108.7, ups=0.12, wpb=887.6, bsz=80, num_updates=13540, lr=4.24262e-07, gnorm=1.256, clip=60, loss_scale=64, train_wall=82, gb_free=6.8, wall=179138
2022-05-21 23:10:30 - progress_bar.py[line:274] - INFO: epoch 002:   6490 / 7081 loss=-0.009, score=1.588, ntokens=892.6, nsentences=80, sample_size=892.6, wps=116.2, ups=0.13, wpb=892.6, bsz=80, num_updates=13550, lr=4.20657e-07, gnorm=1.849, clip=90, loss_scale=64, train_wall=77, gb_free=6.8, wall=179215
2022-05-21 23:11:47 - progress_bar.py[line:274] - INFO: epoch 002:   6500 / 7081 loss=-0.009, score=1.479, ntokens=908, nsentences=80, sample_size=908, wps=118, ups=0.13, wpb=908, bsz=80, num_updates=13560, lr=4.17051e-07, gnorm=1.527, clip=90, loss_scale=64, train_wall=77, gb_free=6.8, wall=179291
2022-05-21 23:13:07 - progress_bar.py[line:274] - INFO: epoch 002:   6510 / 7081 loss=-0.01, score=1.543, ntokens=879, nsentences=80, sample_size=879, wps=109.7, ups=0.12, wpb=879, bsz=80, num_updates=13570, lr=4.13446e-07, gnorm=1.441, clip=80, loss_scale=64, train_wall=80, gb_free=6.8, wall=179372
2022-05-21 23:14:28 - progress_bar.py[line:274] - INFO: epoch 002:   6520 / 7081 loss=-0.005, score=1.478, ntokens=881.1, nsentences=80, sample_size=881.1, wps=109, ups=0.12, wpb=881.1, bsz=80, num_updates=13580, lr=4.0984e-07, gnorm=1.501, clip=80, loss_scale=64, train_wall=81, gb_free=6.8, wall=179452
2022-05-21 23:15:48 - progress_bar.py[line:274] - INFO: epoch 002:   6530 / 7081 loss=-0.003, score=1.618, ntokens=876.9, nsentences=80, sample_size=876.9, wps=108.9, ups=0.12, wpb=876.9, bsz=80, num_updates=13590, lr=4.06235e-07, gnorm=1.437, clip=80, loss_scale=64, train_wall=80, gb_free=6.8, wall=179533
2022-05-21 23:17:09 - progress_bar.py[line:274] - INFO: epoch 002:   6540 / 7081 loss=-0.005, score=1.418, ntokens=878.7, nsentences=80, sample_size=878.7, wps=108.8, ups=0.12, wpb=878.7, bsz=80, num_updates=13600, lr=4.02629e-07, gnorm=1.369, clip=90, loss_scale=64, train_wall=81, gb_free=6.8, wall=179614
2022-05-21 23:18:31 - progress_bar.py[line:274] - INFO: epoch 002:   6550 / 7081 loss=-0.005, score=1.353, ntokens=897.9, nsentences=80, sample_size=897.9, wps=109.8, ups=0.12, wpb=897.9, bsz=80, num_updates=13610, lr=3.99024e-07, gnorm=1.622, clip=80, loss_scale=64, train_wall=82, gb_free=6.8, wall=179696
2022-05-21 23:19:52 - progress_bar.py[line:274] - INFO: epoch 002:   6560 / 7081 loss=-0.004, score=1.515, ntokens=880.8, nsentences=80, sample_size=880.8, wps=108.7, ups=0.12, wpb=880.8, bsz=80, num_updates=13620, lr=3.95418e-07, gnorm=1.598, clip=100, loss_scale=64, train_wall=81, gb_free=6.8, wall=179777
2022-05-21 23:21:13 - progress_bar.py[line:274] - INFO: epoch 002:   6570 / 7081 loss=-0.004, score=1.431, ntokens=901.1, nsentences=80, sample_size=901.1, wps=110.5, ups=0.12, wpb=901.1, bsz=80, num_updates=13630, lr=3.91813e-07, gnorm=1.327, clip=80, loss_scale=64, train_wall=81, gb_free=6.8, wall=179858
2022-05-21 23:22:34 - progress_bar.py[line:274] - INFO: epoch 002:   6580 / 7081 loss=-0.006, score=1.489, ntokens=872.7, nsentences=80, sample_size=872.7, wps=108.1, ups=0.12, wpb=872.7, bsz=80, num_updates=13640, lr=3.88207e-07, gnorm=1.697, clip=80, loss_scale=64, train_wall=81, gb_free=6.8, wall=179939
2022-05-21 23:23:55 - progress_bar.py[line:274] - INFO: epoch 002:   6590 / 7081 loss=-0.006, score=1.527, ntokens=889.3, nsentences=80, sample_size=889.3, wps=110.6, ups=0.12, wpb=889.3, bsz=80, num_updates=13650, lr=3.84602e-07, gnorm=1.325, clip=80, loss_scale=64, train_wall=80, gb_free=6.8, wall=180019
2022-05-21 23:25:15 - progress_bar.py[line:274] - INFO: epoch 002:   6600 / 7081 loss=-0.009, score=1.452, ntokens=883.5, nsentences=80, sample_size=883.5, wps=109.4, ups=0.12, wpb=883.5, bsz=80, num_updates=13660, lr=3.80996e-07, gnorm=1.861, clip=90, loss_scale=64, train_wall=81, gb_free=6.8, wall=180100
2022-05-21 23:26:36 - progress_bar.py[line:274] - INFO: epoch 002:   6610 / 7081 loss=-0.008, score=1.438, ntokens=881.2, nsentences=80, sample_size=881.2, wps=108.7, ups=0.12, wpb=881.2, bsz=80, num_updates=13670, lr=3.77391e-07, gnorm=1.846, clip=90, loss_scale=64, train_wall=81, gb_free=6.8, wall=180181
2022-05-21 23:27:58 - progress_bar.py[line:274] - INFO: epoch 002:   6620 / 7081 loss=-0.004, score=1.488, ntokens=887.9, nsentences=80, sample_size=887.9, wps=109.3, ups=0.12, wpb=887.9, bsz=80, num_updates=13680, lr=3.73785e-07, gnorm=1.392, clip=90, loss_scale=64, train_wall=81, gb_free=6.8, wall=180262
2022-05-21 23:29:18 - progress_bar.py[line:274] - INFO: epoch 002:   6630 / 7081 loss=-0.004, score=1.536, ntokens=892.9, nsentences=80, sample_size=892.9, wps=110.5, ups=0.12, wpb=892.9, bsz=80, num_updates=13690, lr=3.7018e-07, gnorm=1.673, clip=90, loss_scale=64, train_wall=81, gb_free=6.8, wall=180343
2022-05-21 23:30:39 - progress_bar.py[line:274] - INFO: epoch 002:   6640 / 7081 loss=-0.006, score=1.41, ntokens=881.9, nsentences=80, sample_size=881.9, wps=109.2, ups=0.12, wpb=881.9, bsz=80, num_updates=13700, lr=3.66574e-07, gnorm=1.639, clip=80, loss_scale=64, train_wall=81, gb_free=6.8, wall=180424
2022-05-21 23:32:00 - progress_bar.py[line:274] - INFO: epoch 002:   6650 / 7081 loss=-0.006, score=1.499, ntokens=887.7, nsentences=80, sample_size=887.7, wps=109.4, ups=0.12, wpb=887.7, bsz=80, num_updates=13710, lr=3.62969e-07, gnorm=2.287, clip=90, loss_scale=64, train_wall=81, gb_free=6.8, wall=180505
2022-05-21 23:33:22 - progress_bar.py[line:274] - INFO: epoch 002:   6660 / 7081 loss=-0.009, score=1.481, ntokens=890.1, nsentences=80, sample_size=890.1, wps=109.6, ups=0.12, wpb=890.1, bsz=80, num_updates=13720, lr=3.59363e-07, gnorm=1.887, clip=100, loss_scale=64, train_wall=81, gb_free=6.8, wall=180586
2022-05-21 23:34:42 - progress_bar.py[line:274] - INFO: epoch 002:   6670 / 7081 loss=-0.01, score=1.525, ntokens=887, nsentences=80, sample_size=887, wps=109.7, ups=0.12, wpb=887, bsz=80, num_updates=13730, lr=3.55758e-07, gnorm=1.375, clip=90, loss_scale=64, train_wall=81, gb_free=6.8, wall=180667
2022-05-21 23:34:51 - trainer.py[line:922] - INFO: NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
2022-05-21 23:36:09 - progress_bar.py[line:274] - INFO: epoch 002:   6681 / 7081 loss=-0.005, score=1.47, ntokens=886.5, nsentences=80, sample_size=886.5, wps=102, ups=0.12, wpb=886.5, bsz=80, num_updates=13740, lr=3.52152e-07, gnorm=1.418, clip=80, loss_scale=32, train_wall=87, gb_free=6.8, wall=180754
2022-05-21 23:37:26 - progress_bar.py[line:274] - INFO: epoch 002:   6691 / 7081 loss=-0.005, score=1.386, ntokens=893.5, nsentences=80, sample_size=893.5, wps=116.7, ups=0.13, wpb=893.5, bsz=80, num_updates=13750, lr=3.48547e-07, gnorm=1.502, clip=90, loss_scale=32, train_wall=77, gb_free=6.8, wall=180831
2022-05-21 23:38:44 - progress_bar.py[line:274] - INFO: epoch 002:   6701 / 7081 loss=-0.008, score=1.403, ntokens=886.6, nsentences=80, sample_size=886.6, wps=114, ups=0.13, wpb=886.6, bsz=80, num_updates=13760, lr=3.44941e-07, gnorm=1.488, clip=90, loss_scale=32, train_wall=78, gb_free=6.8, wall=180908
2022-05-21 23:40:05 - progress_bar.py[line:274] - INFO: epoch 002:   6711 / 7081 loss=-0.003, score=1.362, ntokens=884.8, nsentences=80, sample_size=884.8, wps=108.8, ups=0.12, wpb=884.8, bsz=80, num_updates=13770, lr=3.41336e-07, gnorm=1.518, clip=80, loss_scale=32, train_wall=81, gb_free=6.8, wall=180990
2022-05-21 23:41:26 - progress_bar.py[line:274] - INFO: epoch 002:   6721 / 7081 loss=-0.008, score=1.507, ntokens=880.1, nsentences=80, sample_size=880.1, wps=109, ups=0.12, wpb=880.1, bsz=80, num_updates=13780, lr=3.3773e-07, gnorm=1.682, clip=90, loss_scale=32, train_wall=81, gb_free=6.8, wall=181070
2022-05-21 23:42:46 - progress_bar.py[line:274] - INFO: epoch 002:   6731 / 7081 loss=-0.005, score=1.463, ntokens=881.2, nsentences=80, sample_size=881.2, wps=109.4, ups=0.12, wpb=881.2, bsz=80, num_updates=13790, lr=3.34125e-07, gnorm=1.665, clip=90, loss_scale=32, train_wall=80, gb_free=6.8, wall=181151
2022-05-21 23:44:07 - progress_bar.py[line:274] - INFO: epoch 002:   6741 / 7081 loss=-0.005, score=1.511, ntokens=890.5, nsentences=80, sample_size=890.5, wps=110, ups=0.12, wpb=890.5, bsz=80, num_updates=13800, lr=3.30519e-07, gnorm=1.782, clip=100, loss_scale=32, train_wall=81, gb_free=6.8, wall=181232
2022-05-21 23:45:29 - progress_bar.py[line:274] - INFO: epoch 002:   6751 / 7081 loss=-0.002, score=1.467, ntokens=885.6, nsentences=80, sample_size=885.6, wps=108.5, ups=0.12, wpb=885.6, bsz=80, num_updates=13810, lr=3.26914e-07, gnorm=1.495, clip=80, loss_scale=32, train_wall=82, gb_free=6.8, wall=181314
2022-05-21 23:46:50 - progress_bar.py[line:274] - INFO: epoch 002:   6761 / 7081 loss=-0.006, score=1.567, ntokens=893, nsentences=80, sample_size=893, wps=110.3, ups=0.12, wpb=893, bsz=80, num_updates=13820, lr=3.23308e-07, gnorm=1.94, clip=100, loss_scale=32, train_wall=81, gb_free=6.8, wall=181395
2022-05-21 23:48:11 - progress_bar.py[line:274] - INFO: epoch 002:   6771 / 7081 loss=-0.004, score=1.455, ntokens=878.4, nsentences=80, sample_size=878.4, wps=108.8, ups=0.12, wpb=878.4, bsz=80, num_updates=13830, lr=3.19703e-07, gnorm=1.458, clip=70, loss_scale=32, train_wall=81, gb_free=6.8, wall=181475
2022-05-21 23:49:32 - progress_bar.py[line:274] - INFO: epoch 002:   6781 / 7081 loss=-0.006, score=1.465, ntokens=888.9, nsentences=80, sample_size=888.9, wps=109.6, ups=0.12, wpb=888.9, bsz=80, num_updates=13840, lr=3.16097e-07, gnorm=1.707, clip=80, loss_scale=32, train_wall=81, gb_free=6.8, wall=181556
2022-05-21 23:50:53 - progress_bar.py[line:274] - INFO: epoch 002:   6791 / 7081 loss=-0.007, score=1.43, ntokens=884.7, nsentences=80, sample_size=884.7, wps=109.4, ups=0.12, wpb=884.7, bsz=80, num_updates=13850, lr=3.12492e-07, gnorm=1.825, clip=100, loss_scale=32, train_wall=81, gb_free=6.8, wall=181637
2022-05-21 23:52:14 - progress_bar.py[line:274] - INFO: epoch 002:   6801 / 7081 loss=-0.007, score=1.44, ntokens=878.1, nsentences=80, sample_size=878.1, wps=107.9, ups=0.12, wpb=878.1, bsz=80, num_updates=13860, lr=3.08886e-07, gnorm=1.758, clip=100, loss_scale=32, train_wall=81, gb_free=6.8, wall=181719
2022-05-21 23:53:35 - progress_bar.py[line:274] - INFO: epoch 002:   6811 / 7081 loss=-0.005, score=1.453, ntokens=891, nsentences=80, sample_size=891, wps=110.2, ups=0.12, wpb=891, bsz=80, num_updates=13870, lr=3.05281e-07, gnorm=1.189, clip=60, loss_scale=32, train_wall=81, gb_free=6.8, wall=181800
2022-05-21 23:54:56 - progress_bar.py[line:274] - INFO: epoch 002:   6821 / 7081 loss=-0.005, score=1.497, ntokens=878.2, nsentences=80, sample_size=878.2, wps=108.4, ups=0.12, wpb=878.2, bsz=80, num_updates=13880, lr=3.01675e-07, gnorm=1.698, clip=80, loss_scale=32, train_wall=81, gb_free=6.8, wall=181881
2022-05-21 23:56:17 - progress_bar.py[line:274] - INFO: epoch 002:   6831 / 7081 loss=-0.004, score=1.362, ntokens=873.2, nsentences=80, sample_size=873.2, wps=107.3, ups=0.12, wpb=873.2, bsz=80, num_updates=13890, lr=2.9807e-07, gnorm=1.403, clip=90, loss_scale=32, train_wall=81, gb_free=6.8, wall=181962
2022-05-21 23:57:38 - progress_bar.py[line:274] - INFO: epoch 002:   6841 / 7081 loss=-0.007, score=1.395, ntokens=880.3, nsentences=80, sample_size=880.3, wps=109.2, ups=0.12, wpb=880.3, bsz=80, num_updates=13900, lr=2.94464e-07, gnorm=1.566, clip=80, loss_scale=32, train_wall=81, gb_free=6.8, wall=182043
2022-05-21 23:58:59 - progress_bar.py[line:274] - INFO: epoch 002:   6851 / 7081 loss=-0.007, score=1.469, ntokens=899.8, nsentences=80, sample_size=899.8, wps=110.3, ups=0.12, wpb=899.8, bsz=80, num_updates=13910, lr=2.90859e-07, gnorm=1.291, clip=70, loss_scale=32, train_wall=81, gb_free=6.8, wall=182124
2022-05-22 00:00:20 - progress_bar.py[line:274] - INFO: epoch 002:   6861 / 7081 loss=-0.005, score=1.536, ntokens=870.7, nsentences=80, sample_size=870.7, wps=108.4, ups=0.12, wpb=870.7, bsz=80, num_updates=13920, lr=2.87253e-07, gnorm=1.721, clip=80, loss_scale=32, train_wall=80, gb_free=6.7, wall=182204
2022-05-22 00:01:40 - progress_bar.py[line:274] - INFO: epoch 002:   6871 / 7081 loss=-0.007, score=1.546, ntokens=887.9, nsentences=80, sample_size=887.9, wps=110.1, ups=0.12, wpb=887.9, bsz=80, num_updates=13930, lr=2.83648e-07, gnorm=2.425, clip=100, loss_scale=32, train_wall=81, gb_free=6.8, wall=182285
2022-05-22 00:02:58 - progress_bar.py[line:274] - INFO: epoch 002:   6881 / 7081 loss=-0.009, score=1.508, ntokens=900.1, nsentences=80, sample_size=900.1, wps=116.5, ups=0.13, wpb=900.1, bsz=80, num_updates=13940, lr=2.80042e-07, gnorm=1.503, clip=80, loss_scale=32, train_wall=77, gb_free=6.8, wall=182362
2022-05-22 00:04:14 - progress_bar.py[line:274] - INFO: epoch 002:   6891 / 7081 loss=-0.007, score=1.44, ntokens=894.7, nsentences=80, sample_size=894.7, wps=116.8, ups=0.13, wpb=894.7, bsz=80, num_updates=13950, lr=2.76437e-07, gnorm=1.56, clip=90, loss_scale=32, train_wall=77, gb_free=6.8, wall=182439
2022-05-22 00:05:35 - progress_bar.py[line:274] - INFO: epoch 002:   6901 / 7081 loss=-0.005, score=1.4, ntokens=888.5, nsentences=80, sample_size=888.5, wps=110, ups=0.12, wpb=888.5, bsz=80, num_updates=13960, lr=2.72831e-07, gnorm=1.904, clip=80, loss_scale=32, train_wall=81, gb_free=6.8, wall=182520
2022-05-22 00:06:56 - progress_bar.py[line:274] - INFO: epoch 002:   6911 / 7081 loss=-0.008, score=1.553, ntokens=889.8, nsentences=80, sample_size=889.8, wps=109.8, ups=0.12, wpb=889.8, bsz=80, num_updates=13970, lr=2.69226e-07, gnorm=1.703, clip=90, loss_scale=32, train_wall=81, gb_free=6.8, wall=182601
2022-05-22 00:08:17 - progress_bar.py[line:274] - INFO: epoch 002:   6921 / 7081 loss=-0.007, score=1.479, ntokens=894.3, nsentences=80, sample_size=894.3, wps=110.1, ups=0.12, wpb=894.3, bsz=80, num_updates=13980, lr=2.6562e-07, gnorm=1.523, clip=90, loss_scale=32, train_wall=81, gb_free=6.8, wall=182682
2022-05-22 00:09:39 - progress_bar.py[line:274] - INFO: epoch 002:   6931 / 7081 loss=-0.01, score=1.466, ntokens=895.2, nsentences=80, sample_size=895.2, wps=109.4, ups=0.12, wpb=895.2, bsz=80, num_updates=13990, lr=2.62015e-07, gnorm=1.918, clip=90, loss_scale=32, train_wall=82, gb_free=6.8, wall=182764
2022-05-22 00:11:00 - progress_bar.py[line:274] - INFO: epoch 002:   6941 / 7081 loss=-0.005, score=1.402, ntokens=878.9, nsentences=80, sample_size=878.9, wps=108.6, ups=0.12, wpb=878.9, bsz=80, num_updates=14000, lr=2.58409e-07, gnorm=1.527, clip=100, loss_scale=32, train_wall=81, gb_free=6.7, wall=182845
2022-05-22 00:11:00 - train.py[line:436] - INFO: begin validation on "valid" subset
slice_id 0 seek offset 0
slice_id 0 seek offset 0
slice_id 1 seek offset 2500
slice_id 1 seek offset 2500
2022-05-22 00:51:08 - progress_bar.py[line:282] - INFO: epoch 002 | valid on 'valid' subset | loss -0.005 | score 1.298 | ntokens 110.937 | nsentences 10 | sample_size 110.937 | cider 1.39 | wps 115.2 | wpb 110.9 | bsz 10 | num_updates 14000 | best_cider 1.394
2022-05-22 00:51:08 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 2 @ 14000 updates
2022-05-22 00:51:08 - trainer.py[line:431] - INFO: Saving checkpoint to /database/jhkim/stage2_checkpoints//5e-6_2/checkpoint_2_14000.pt
2022-05-22 00:51:16 - trainer.py[line:441] - INFO: Finished saving checkpoint to /database/jhkim/stage2_checkpoints//5e-6_2/checkpoint_2_14000.pt
2022-05-22 00:51:48 - checkpoint_utils.py[line:135] - INFO: Saved checkpoint /database/jhkim/stage2_checkpoints//5e-6_2/checkpoint_2_14000.pt (epoch 2 @ 14000 updates, score 1.39) (writing took 40.36146581498906 seconds)
2022-05-22 00:53:08 - progress_bar.py[line:274] - INFO: epoch 002:   6951 / 7081 loss=-0.006, score=1.494, ntokens=880.9, nsentences=80, sample_size=880.9, wps=3.5, ups=0, wpb=880.9, bsz=80, num_updates=14010, lr=2.54804e-07, gnorm=2.293, clip=80, loss_scale=32, train_wall=79, gb_free=6.8, wall=185372
2022-05-22 00:54:25 - progress_bar.py[line:274] - INFO: epoch 002:   6961 / 7081 loss=-0.005, score=1.413, ntokens=870.6, nsentences=80, sample_size=870.6, wps=112.9, ups=0.13, wpb=870.6, bsz=80, num_updates=14020, lr=2.51198e-07, gnorm=1.826, clip=100, loss_scale=32, train_wall=77, gb_free=6.8, wall=185450
2022-05-22 00:55:41 - progress_bar.py[line:274] - INFO: epoch 002:   6971 / 7081 loss=-0.003, score=1.504, ntokens=878.2, nsentences=80, sample_size=878.2, wps=115.2, ups=0.13, wpb=878.2, bsz=80, num_updates=14030, lr=2.47593e-07, gnorm=1.905, clip=90, loss_scale=32, train_wall=76, gb_free=6.8, wall=185526
2022-05-22 00:56:59 - progress_bar.py[line:274] - INFO: epoch 002:   6981 / 7081 loss=-0.009, score=1.42, ntokens=885.1, nsentences=80, sample_size=885.1, wps=113.5, ups=0.13, wpb=885.1, bsz=80, num_updates=14040, lr=2.43987e-07, gnorm=1.588, clip=90, loss_scale=32, train_wall=78, gb_free=6.8, wall=185604
2022-05-22 00:58:21 - progress_bar.py[line:274] - INFO: epoch 002:   6991 / 7081 loss=-0.009, score=1.469, ntokens=887.7, nsentences=80, sample_size=887.7, wps=108.8, ups=0.12, wpb=887.7, bsz=80, num_updates=14050, lr=2.40382e-07, gnorm=1.721, clip=100, loss_scale=32, train_wall=81, gb_free=6.8, wall=185685
2022-05-22 00:59:42 - progress_bar.py[line:274] - INFO: epoch 002:   7001 / 7081 loss=-0.008, score=1.494, ntokens=886.7, nsentences=80, sample_size=886.7, wps=109.3, ups=0.12, wpb=886.7, bsz=80, num_updates=14060, lr=2.36776e-07, gnorm=1.82, clip=90, loss_scale=32, train_wall=81, gb_free=6.8, wall=185766
2022-05-22 01:01:03 - progress_bar.py[line:274] - INFO: epoch 002:   7011 / 7081 loss=-0.004, score=1.384, ntokens=896.1, nsentences=80, sample_size=896.1, wps=110.7, ups=0.12, wpb=896.1, bsz=80, num_updates=14070, lr=2.33171e-07, gnorm=1.675, clip=100, loss_scale=32, train_wall=81, gb_free=6.8, wall=185847
2022-05-22 01:02:24 - progress_bar.py[line:274] - INFO: epoch 002:   7021 / 7081 loss=-0.007, score=1.517, ntokens=891.5, nsentences=80, sample_size=891.5, wps=109.7, ups=0.12, wpb=891.5, bsz=80, num_updates=14080, lr=2.29565e-07, gnorm=1.427, clip=60, loss_scale=32, train_wall=81, gb_free=6.8, wall=185929
2022-05-22 01:03:44 - progress_bar.py[line:274] - INFO: epoch 002:   7031 / 7081 loss=-0.007, score=1.441, ntokens=887.5, nsentences=80, sample_size=887.5, wps=110.4, ups=0.12, wpb=887.5, bsz=80, num_updates=14090, lr=2.2596e-07, gnorm=1.636, clip=80, loss_scale=32, train_wall=80, gb_free=6.8, wall=186009
2022-05-22 01:05:05 - progress_bar.py[line:274] - INFO: epoch 002:   7041 / 7081 loss=-0.006, score=1.36, ntokens=887.8, nsentences=80, sample_size=887.8, wps=110.4, ups=0.12, wpb=887.8, bsz=80, num_updates=14100, lr=2.22354e-07, gnorm=1.514, clip=90, loss_scale=32, train_wall=80, gb_free=6.8, wall=186089
2022-05-22 01:06:26 - progress_bar.py[line:274] - INFO: epoch 002:   7051 / 7081 loss=-0.007, score=1.461, ntokens=891.7, nsentences=80, sample_size=891.7, wps=109.8, ups=0.12, wpb=891.7, bsz=80, num_updates=14110, lr=2.18749e-07, gnorm=1.629, clip=80, loss_scale=32, train_wall=81, gb_free=6.8, wall=186171
2022-05-22 01:07:47 - progress_bar.py[line:274] - INFO: epoch 002:   7061 / 7081 loss=-0.007, score=1.408, ntokens=895.7, nsentences=80, sample_size=895.7, wps=110.8, ups=0.12, wpb=895.7, bsz=80, num_updates=14120, lr=2.15143e-07, gnorm=1.45, clip=90, loss_scale=32, train_wall=81, gb_free=6.8, wall=186251
2022-05-22 01:09:07 - progress_bar.py[line:274] - INFO: epoch 002:   7071 / 7081 loss=-0.008, score=1.579, ntokens=879.5, nsentences=80, sample_size=879.5, wps=108.9, ups=0.12, wpb=879.5, bsz=80, num_updates=14130, lr=2.11538e-07, gnorm=1.604, clip=80, loss_scale=32, train_wall=81, gb_free=6.8, wall=186332
2022-05-22 01:10:24 - progress_bar.py[line:274] - INFO: epoch 002:   7081 / 7081 loss=-0.004, score=1.517, ntokens=839, nsentences=76, sample_size=839, wps=109.1, ups=0.13, wpb=839, bsz=76, num_updates=14140, lr=2.07932e-07, gnorm=1.757, clip=100, loss_scale=32, train_wall=77, gb_free=6.8, wall=186409
2022-05-22 01:10:24 - train.py[line:436] - INFO: begin validation on "valid" subset
slice_id 0 seek offset 0
slice_id 0 seek offset 0
slice_id 1 seek offset 2500
slice_id 1 seek offset 2500
2022-05-22 01:50:14 - progress_bar.py[line:282] - INFO: epoch 002 | valid on 'valid' subset | loss -0.005 | score 1.299 | ntokens 110.922 | nsentences 10 | sample_size 110.922 | cider 1.389 | wps 116 | wpb 110.9 | bsz 10 | num_updates 14140 | best_cider 1.394
2022-05-22 01:50:14 - checkpoint_utils.py[line:64] - INFO: Preparing to save checkpoint for epoch 2 @ 14140 updates
2022-05-22 01:50:14 - trainer.py[line:431] - INFO: Saving checkpoint to /database/jhkim/stage2_checkpoints//5e-6_2/checkpoint_last.pt
local datafile ../../dataset/caption_data/caption_stage1_train_ct2.tsv slice_id 1 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../dataset/caption_data/caption_stage1_train_ct2.tsv slice_id 1 finished initializing row_count and line_idx-to-offset mapping
file ../../dataset/caption_data/caption_stage1_train_ct2.tsv slice_id 1 row count 56643 total row count 113287
slice_id 1 seek offset 56644
2022-05-22 01:50:48 - trainer.py[line:441] - INFO: Finished saving checkpoint to /database/jhkim/stage2_checkpoints//5e-6_2/checkpoint_last.pt
2022-05-22 01:50:49 - checkpoint_utils.py[line:135] - INFO: Saved checkpoint /database/jhkim/stage2_checkpoints//5e-6_2/checkpoint_last.pt (epoch 2 @ 14140 updates, score 1.389) (writing took 34.669791883789 seconds)
2022-05-22 01:50:49 - train.py[line:323] - INFO: end of epoch 2 (average epoch stats below)
2022-05-22 01:50:49 - progress_bar.py[line:282] - INFO: epoch 002 | loss -0.006 | score 1.461 | ntokens 888.004 | nsentences 79.994 | sample_size 888.004 | wps 66.9 | ups 0.08 | wpb 888 | bsz 80 | num_updates 14140 | lr 2.07932e-07 | gnorm 1.678 | clip 85.6 | loss_scale 32 | train_wall 56977 | gb_free 6.8 | wall 188833
2022-05-22 01:50:49 - trainer.py[line:639] - INFO: loading train data for epoch 3
local datafile ../../dataset/caption_data/caption_stage1_train_ct2.tsv slice_id 0 begin to initialize row_count and line_idx-to-offset mapping
local datafile ../../dataset/caption_data/caption_stage1_train_ct2.tsv slice_id 0 finished initializing row_count and line_idx-to-offset mapping
file ../../dataset/caption_data/caption_stage1_train_ct2.tsv slice_id 0 row count 56644 total row count 113287
slice_id 0 seek offset 0
2022-05-22 01:50:52 - train.py[line:205] - INFO: done training in 188825.0 seconds
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
